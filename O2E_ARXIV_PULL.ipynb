{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use BeautifulSoup to parse xml\n",
    "url = \"http://export.arxiv.org/rss/cs/\"\n",
    "resp = requests.get(url)\n",
    "soup = BeautifulSoup(resp.content, features=\"xml\")\n",
    "items = soup.findAll('item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate against website how many items are there\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<item rdf:about=\"http://arxiv.org/abs/2102.02204\">\n",
       "<title>Parametrized Quantum Circuits of Synonymous Sentences in Quantum Natural Language Processing. (arXiv:2102.02204v1 [quant-ph])</title>\n",
       "<link>http://arxiv.org/abs/2102.02204</link>\n",
       "<description rdf:parseType=\"Literal\">&lt;p&gt;In this paper, we develop a compositional vector-based semantics of positive\n",
       "transitive sentences in quantum natural language processing for a non-English\n",
       "language, i.e. Persian, to compare the parametrized quantum circuits of two\n",
       "synonymous sentences in two languages, English and Persian. By considering\n",
       "grammar+meaning of a transitive sentence, we translate DisCoCat diagram via\n",
       "ZX-calculus into quantum circuit form. Also, we use a bigraph method to rewrite\n",
       "DisCoCat diagram and turn into quantum circuit in the semantic side.\n",
       "&lt;/p&gt;\n",
       "</description>\n",
       "<dc:creator> &lt;a href=\"http://arxiv.org/find/quant-ph/1/au:+Abbaszadeh_M/0/1/0/all/0/1\"&gt;Mina Abbaszadeh&lt;/a&gt;, &lt;a href=\"http://arxiv.org/find/quant-ph/1/au:+Mousavi_S/0/1/0/all/0/1\"&gt;S. Shahin Mousavi&lt;/a&gt;, &lt;a href=\"http://arxiv.org/find/quant-ph/1/au:+Salari_V/0/1/0/all/0/1\"&gt;Vahid Salari&lt;/a&gt;</dc:creator>\n",
       "</item>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # validate first item at position 0\n",
    "item = items[0]\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<description rdf:parseType=\"Literal\">&lt;p&gt;In this paper, we develop a compositional vector-based semantics of positive\n",
       "transitive sentences in quantum natural language processing for a non-English\n",
       "language, i.e. Persian, to compare the parametrized quantum circuits of two\n",
       "synonymous sentences in two languages, English and Persian. By considering\n",
       "grammar+meaning of a transitive sentence, we translate DisCoCat diagram via\n",
       "ZX-calculus into quantum circuit form. Also, we use a bigraph method to rewrite\n",
       "DisCoCat diagram and turn into quantum circuit in the semantic side.\n",
       "&lt;/p&gt;\n",
       "</description>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate description of item\n",
    "item.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate title, description, link into news_items\n",
    "items = soup.findAll('item')\n",
    "\n",
    "news_items = []\n",
    "\n",
    "for item in items:\n",
    "    news_item = {}\n",
    "    news_item['title'] = item.title.text\n",
    "    news_item['description'] = item.description.text\n",
    "    news_item['link'] = item.link.text\n",
    "    news_items.append(news_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Parametrized Quantum Circuits of Synonymous Sentences in Quantum Natural Language Processing. (arXiv:2102.02204v1 [quant-ph])', 'description': '<p>In this paper, we develop a compositional vector-based semantics of positive\\ntransitive sentences in quantum natural language processing for a non-English\\nlanguage, i.e. Persian, to compare the parametrized quantum circuits of two\\nsynonymous sentences in two languages, English and Persian. By considering\\ngrammar+meaning of a transitive sentence, we translate DisCoCat diagram via\\nZX-calculus into quantum circuit form. Also, we use a bigraph method to rewrite\\nDisCoCat diagram and turn into quantum circuit in the semantic side.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02204'}, {'title': 'Harvest -- An Open Source Toolkit for Extracting Posts and Post Metadata from Web Forums. (arXiv:2102.02240v1 [cs.IR])', 'description': '<p>Automatic extraction of forum posts and metadata is a crucial but challenging\\ntask since forums do not expose their content in a standardized structure.\\nContent extraction methods, therefore, often need customizations such as\\nadaptations to page templates and improvements of their extraction code before\\nthey can be deployed to new forums. Most of the current solutions are also\\nbuilt for the more general case of content extraction from web pages and lack\\nkey features important for understanding forum content such as the\\nidentification of author metadata and information on the thread structure.\\n</p>\\n<p>This paper, therefore, presents a method that determines the XPath of forum\\nposts, eliminating incorrect mergers and splits of the extracted posts that\\nwere common in systems from the previous generation. Based on the individual\\nposts further metadata such as authors, forum URL and structure are extracted.\\nWe also introduce Harvest, a new open source toolkit that implements the\\npresented methods and create a gold standard extracted from 52 different Web\\nforums for evaluating our approach. A comprehensive evaluation reveals that\\nHarvest clearly outperforms competing systems.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02240'}, {'title': 'Information-theoretic Key Encapsulation and its Application to Secure Communication. (arXiv:2102.02243v1 [cs.CR])', 'description': '<p>A hybrid encryption scheme is a public key encryption system that consists of\\na public-key part called the key encapsulation mechanism (KEM), and a\\n(symmetric) secret-key part called data encapsulation mechanism (DEM): the\\npublic-key part is used to generate a shared secret key between the two\\nparties, and the symmetric key part is used to encrypt the message. Hybrid\\nencryption schemes are widely used for secure communication over the Internet.\\nIn this paper, we initiate the study of hybrid encryption in preprocessing\\nmodel which assumes access to initial correlated variables by all the parties\\n(including the eavesdropper). We define information theoretic KEM (iKEM) that\\ntogether with a (computationally) secure DEM results in a hybrid encryption\\nscheme in preprocessing model. We define security of each building block and\\nprove a composition theorem that guarantees security of the final encryption\\nsystem. We showthat iKEM can be realized by a one-message SKA (OW-SKA)protocol\\nwith an extended security definition. Using a OW-SKA that satisfies this\\nextended definition of security effectively allows the secret key that is\\ngenerated by the OW-SKA to be used with symmetric key encryption system such as\\nAES in counter mode. We discuss our results and future work including providing\\nstronger security for the final encryption, and using information theoretic DEM\\nto construct information theoretic encryption systems.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02243'}, {'title': 'Bounds and Genericity of Sum-Rank-Metric Codes. (arXiv:2102.02244v1 [cs.IT])', 'description': '<p>We derive simplified sphere-packing and Gilbert-Varshamov bounds for codes in\\nthe sum-rank metric, which can be computed more efficently than previous\\nones.They give rise to asymptotic bounds that cover the asymptotic setting that\\nhas not yet been considered in the literature: families of sum-rank-metric\\ncodes whose block size grows in the code length. We also provide two genericity\\nresults: we show that random linear codes achieve almost the sum-rank-metric\\nGilbert-Varshamov bound with high probability. Furthermore, we derive bounds on\\nthe probability that a random linear code attains the sum-rank-metric Singleton\\nbound, showing that for large enough extension field, almost all linear codes\\nachieve it.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02244'}, {'title': 'The Forgotten Document-Oriented Database Management Systems: An Overview and Benchmark of Native XML DODBMSes in Comparison with JSON DODBMSes. (arXiv:2102.02246v1 [cs.DB])', 'description': '<p>In the current context of Big Data, a multitude of new NoSQL solutions for\\nstoring, managing, and extracting information and patterns from semi-structured\\ndata have been proposed and implemented. These solutions were developed to\\nrelieve the issue of rigid data structures present in relational databases, by\\nintroducing semi-structured and flexible schema design. As current data\\ngenerated by different sources and devices, especially from IoT sensors and\\nactuators, use either XML or JSON format, depending on the application,\\ndatabase technologies that store and query semi-structured data in XML format\\nare needed. Thus, Native XML Databases, which were initially designed to\\nmanipulate XML data using standardized querying languages, i.e., XQuery and\\nXPath, were rebranded as NoSQL Document-Oriented Databases Systems. Currently,\\nthe majority of these solutions have been replaced with the more modern JSON\\nbased Database Management Systems. However, we believe that XML-based solutions\\ncan still deliver performance in executing complex queries on heterogeneous\\ncollections. Unfortunately nowadays, research lacks a clear comparison of the\\nscalability and performance for database technologies that store and query\\ndocuments in XML versus the more modern JSON format. Moreover, to the best of\\nour knowledge, there are no Big Data-compliant benchmarks for such database\\ntechnologies. In this paper, we present a comparison for selected\\nDocument-Oriented Database Systems that either use the XML format to encode\\ndocuments, i.e., BaseX, eXist-db, and Sedna, or the JSON format, i.e., MongoDB,\\nCouchDB, and Couchbase. To underline the performance differences we also\\npropose a benchmark that uses a heterogeneous complex schema on a large DBLP\\ncorpus.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02246'}, {'title': 'Low-cost attacks on Ethereum 2.0 by sub-1/3 stakeholders. (arXiv:2102.02247v1 [cs.CR])', 'description': '<p>We outline two dishonest strategies that can be cheaply executed on the\\nEthereum 2.0 beacon chain, even by validators holding less than one-third of\\nthe total stake: malicious chain reorganizations (\"reorgs\") and finality\\ndelays. In a malicious reorg, an attacker withholds their blocks and\\nattestations before releasing them at an opportune time in order to force a\\nchain reorganization, which they can take advantage of by double-spending or\\nfront-running transactions. To execute a finality delay an attacker uses\\ndelayed block releases and withholding of attestations to increase the mean and\\nvariance of the time it takes blocks to become finalized. This impacts the\\nefficiency and predictability of the system. We provide a probabilistic and\\ncost analysis for each of these attacks, considering a validator with 30% of\\nthe total stake.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02247'}, {'title': 'Optimal Excitation Matching Strategy for Sub-Arrayed Phased Linear Arrays Generating Arbitrary-Shaped Beams. (arXiv:2102.02258v1 [eess.SY])', 'description': '<p>The design of phased arrays able to generate arbitrary-shaped beams through a\\nsub-arrayed architecture is addressed here. The synthesis problem is cast in\\nthe excitation matching framework, so as to yield clustered phased arrays\\nproviding optimal trade-offs between the complexity of the array architecture\\n(i.e., the minimum number of control points at the sub-array level) and the\\nmatching of a reference pattern. A synthesis tool based on the k-means\\nalgorithm is proposed for jointly optimizing the sub-array configuration and\\nthe complex sub-array coefficients. Selected numerical results, including\\npencil beams with sidelobe notches and asymmetric lobes as well as shaped main\\nlobes, are reported and discussed to highlight the peculiarities of the\\nproposed approach also in comparison with some extensions to complex\\nexcitations of state-of-the-art sub-array design methods.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02258'}, {'title': 'Modular Design of Hexagonal Phased Arrays Through Diamond Tiles. (arXiv:2102.02262v1 [eess.SY])', 'description': '<p>The modular design of planar phased array antennas with hexagonal apertures\\nis addressed by means of innovative diamond-shaped tiling techniques. Both\\ntiling configuration and subarray coefficients are optimized to fit\\nuser-defined power-mask constraints on the radiation pattern. Toward this end,\\nsuitable surface-tiling mathematical theorems are customized to the problem at\\nhand to guarantee optimal performance in case of low/medium-size arrays, while\\nthe computationally hard tiling of large arrays is yielded thanks to an\\neffective integer-coded GA-based exploration of the arising high-cardinality\\nsolution spaces. By considering ideal as well as real array models, a set of\\nrepresentative benchmark problems is dealt with to assess the effectiveness of\\nthe proposed architectures and tiling strategies. Moreover, comparisons with\\nalternative tiling architectures are also performed to show to the interested\\nreaders the advantages and the potentialities of the diamond subarraying of\\nhexagonal apertures.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02262'}, {'title': 'DEFT: Detection Embeddings for Tracking. (arXiv:2102.02267v1 [cs.CV])', 'description': '<p>Most modern multiple object tracking (MOT) systems follow the\\ntracking-by-detection paradigm, consisting of a detector followed by a method\\nfor associating detections into tracks. There is a long history in tracking of\\ncombining motion and appearance features to provide robustness to occlusions\\nand other challenges, but typically this comes with the trade-off of a more\\ncomplex and slower implementation. Recent successes on popular 2D tracking\\nbenchmarks indicate that top-scores can be achieved using a state-of-the-art\\ndetector and relatively simple associations relying on single-frame spatial\\noffsets -- notably outperforming contemporary methods that leverage learned\\nappearance features to help re-identify lost tracks. In this paper, we propose\\nan efficient joint detection and tracking model named DEFT, or \"Detection\\nEmbeddings for Tracking.\" Our approach relies on an appearance-based object\\nmatching network jointly-learned with an underlying object detection network.\\nAn LSTM is also added to capture motion constraints. DEFT has comparable\\naccuracy and speed to the top methods on 2D online tracking leaderboards while\\nhaving significant advantages in robustness when applied to more challenging\\ntracking data. DEFT raises the bar on the nuScenes monocular 3D tracking\\nchallenge, more than doubling the performance of the previous top method. Code\\nis publicly available.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02267'}, {'title': 'A Heuristic for Dynamic Output Predictive Control Design for Uncertain Nonlinear Systems. (arXiv:2102.02268v1 [eess.SY])', 'description': '<p>In this paper, a simple heuristic is proposed for the design of uncertainty\\naware predictive controllers for nonlinear models involving uncertain\\nparameters. The method relies on Machine Learning-based approximation of ideal\\ndeterministic MPC solutions with perfectly known parameters. An efficient\\nconstruction of the learning data set from these off-line solutions is proposed\\nin which each solution provides many samples in the learning data. This enables\\na drastic reduction of the required number of Non Linear Programming problems\\nto be solved off-line while explicitly exploiting the statistics of the\\nparameters dispersion. The learning data is then used to design a fast on-line\\noutput dynamic feedback that explicitly incorporate information of the\\nstatistics of the parameters dispersion. An example is provided to illustrate\\nthe efficiency and the relevance of the proposed framework. It is in particular\\nshown that the proposed solution recovers up to 78\\\\% of the expected advantage\\nof having a perfect knowledge of the parameters compared to nominal design.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02268'}, {'title': 'Numerical Differentiation using local Chebyshev-Approximation. (arXiv:2102.02269v1 [math.NA])', 'description': '<p>In applied mathematics, especially in optimization, functions are often only\\nprovided as so called \"Black-Boxes\" provided by software packages, or very\\ncomplex algorithms, which make automatic differentation very complicated or\\neven impossible. Hence one seeks the numerical approximation of the derivative.\\n</p>\\n<p>Unfortunately numerical differentation is a difficult task in itself, and it\\nis well known that it is numerical instable. There are many works on this\\ntopic, including the usage of (global) Chebyshev approximations. Chebyshev\\napproximations have the great property that they converge very fast, if the\\nfunction is smooth. Nevertheless those approches have several drawbacks, since\\nin practice functions are not smooth, and a global approximation needs many\\nfunction evalutions.\\n</p>\\n<p>Nevertheless there is hope. Since functions in real world applications are\\nmost times smooth except for finite points, corners or edges. This motivates to\\nuse a local Chebyshev approach, where the function is only approximated\\nlocally, and hence the Chebyshev approximations still yields a fast\\napproximation of the desired function. We will study such an approch in this\\nwork, and will provide a numerical example\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02269'}, {'title': 'Confusion2vec 2.0: Enriching Ambiguous Spoken Language Representations with Subwords. (arXiv:2102.02270v1 [cs.CL])', 'description': '<p>Word vector representations enable machines to encode human language for\\nspoken language understanding and processing. Confusion2vec, motivated from\\nhuman speech production and perception, is a word vector representation which\\nencodes ambiguities present in human spoken language in addition to semantics\\nand syntactic information. Confusion2vec provides a robust spoken language\\nrepresentation by considering inherent human language ambiguities. In this\\npaper, we propose a novel word vector space estimation by unsupervised learning\\non lattices output by an automatic speech recognition (ASR) system. We encode\\neach word in confusion2vec vector space by its constituent subword character\\nn-grams. We show the subword encoding helps better represent the acoustic\\nperceptual ambiguities in human spoken language via information modeled on\\nlattice structured ASR output. The usefulness of the proposed Confusion2vec\\nrepresentation is evaluated using semantic, syntactic and acoustic analogy and\\nword similarity tasks. We also show the benefits of subword modeling for\\nacoustic ambiguity representation on the task of spoken language intent\\ndetection. The results significantly outperform existing word vector\\nrepresentations when evaluated on erroneous ASR outputs. We demonstrate that\\nConfusion2vec subword modeling eliminates the need for retraining/adapting the\\nnatural language understanding models on ASR transcripts.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02270'}, {'title': 'Neural Recursive Belief States in Multi-Agent Reinforcement Learning. (arXiv:2102.02274v1 [cs.LG])', 'description': \"<p>In multi-agent reinforcement learning, the problem of learning to act is\\nparticularly difficult because the policies of co-players may be heavily\\nconditioned on information only observed by them. On the other hand, humans\\nreadily form beliefs about the knowledge possessed by their peers and leverage\\nbeliefs to inform decision-making. Such abilities underlie individual success\\nin a wide range of Markov games, from bluffing in Poker to conditional\\ncooperation in the Prisoner's Dilemma, to convention-building in Bridge.\\nClassical methods are usually not applicable to complex domains due to the\\nintractable nature of hierarchical beliefs (i.e. beliefs of other agents'\\nbeliefs). We propose a scalable method to approximate these belief structures\\nusing recursive deep generative models, and to use the belief models to obtain\\nrepresentations useful to acting in complex tasks. Our agents trained with\\nbelief models outperform model-free baselines with equivalent representational\\ncapacity using common training paradigms. We also show that higher-order belief\\nmodels outperform agents with lower-order models.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02274'}, {'title': 'Modelling and simulation of a wave energy converter. (arXiv:2102.02275v1 [math.AP])', 'description': '<p>In this work we present the mathematical model and simulations of a\\nparticular wave energy converter, the so-called oscillating water column. In\\nthis device, waves governed by the one-dimensional nonlinear shallow water\\nequations arrive from offshore, encounter a step in the bottom and then arrive\\ninto a chamber to change the volume of the air to activate the turbine. The\\nsystem is reformulated as two transmission problems: one is related to the wave\\nmotion over the stepped topography and the other one is related to the\\nwave-structure interaction at the entrance of the chamber. We finally use the\\ncharacteristic equations of Riemann invariants to obtain the discretized\\ntransmission conditions and we implement the Lax-Friedrichs scheme to get\\nnumerical solutions.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02275'}, {'title': 'Insiders and Outsiders in Research on Machine Learning and Society. (arXiv:2102.02279v1 [cs.CY])', 'description': '<p>A subset of machine learning research intersects with societal issues,\\nincluding fairness, accountability and transparency, as well as the use of\\nmachine learning for social good. In this work, we analyze the scholars\\ncontributing to this research at the intersection of machine learning and\\nsociety through the lens of the sociology of science. By analyzing the\\nauthorship of all machine learning papers posted to arXiv, we show that\\ncompared to researchers from overrepresented backgrounds (defined by gender and\\nrace/ethnicity), researchers from underrepresented backgrounds are more likely\\nto conduct research at this intersection than other kinds of machine learning\\nresearch. This state of affairs leads to contention between two perspectives on\\ninsiders and outsiders in the scientific enterprise: outsiders being those\\noutside the group being studied, and outsiders being those who have not\\nparticipated as researchers in an area historically. This contention manifests\\nas an epistemic question on the validity of knowledge derived from lived\\nexperience in machine learning research, and predicts boundary work that we see\\nin a real-world example.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02279'}, {'title': 'Downbeat Tracking with Tempo-Invariant Convolutional Neural Networks. (arXiv:2102.02282v1 [cs.SD])', 'description': '<p>The human ability to track musical downbeats is robust to changes in tempo,\\nand it extends to tempi never previously encountered. We propose a\\ndeterministic time-warping operation that enables this skill in a convolutional\\nneural network (CNN) by allowing the network to learn rhythmic patterns\\nindependently of tempo. Unlike conventional deep learning approaches, which\\nlearn rhythmic patterns at the tempi present in the training dataset, the\\npatterns learned in our model are tempo-invariant, leading to better tempo\\ngeneralisation and more efficient usage of the network capacity. We test the\\ngeneralisation property on a synthetic dataset created by rendering the Groove\\nMIDI Dataset using FluidSynth, split into a training set containing the\\noriginal performances and a test set containing tempo-scaled versions rendered\\nwith different SoundFonts (test-time augmentation). The proposed model\\ngeneralises nearly perfectly to unseen tempi (F-measure of 0.89 on both\\ntraining and test sets), whereas a comparable conventional CNN achieves similar\\naccuracy only for the training set (0.89) and drops to 0.54 on the test set.\\nThe generalisation advantage of the proposed model extends to real music, as\\nshown by results on the GTZAN and Ballroom datasets.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02282'}, {'title': 'HiCOPS: High Performance Computing Framework for Tera-Scale Database Search of Mass Spectrometry based Omics Data. (arXiv:2102.02286v1 [cs.DC])', 'description': '<p>Database-search algorithms, that deduce peptides from Mass Spectrometry (MS)\\ndata, have tried to improve the computational efficiency to accomplish larger,\\nand more complex systems biology studies. Existing serial, and high-performance\\ncomputing (HPC) search engines, otherwise highly successful, are known to\\nexhibit poor-scalability with increasing size of theoretical search-space\\nneeded for increased complexity of modern non-model, multi-species MS-based\\nomics analysis. Consequently, the bottleneck for computational techniques is\\nthe communication costs of moving the data between hierarchy of memory, or\\nprocessing units, and not the arithmetic operations. This post-Moore change in\\narchitecture, and demands of modern systems biology experiments have dampened\\nthe overall effectiveness of the existing HPC workflows. We present a novel\\nefficient parallel computational method, and its implementation on\\nmemory-distributed architectures for peptide identification tool called HiCOPS,\\nthat enables more than 100-fold improvement in speed over most existing HPC\\nproteome database search tools. HiCOPS empowers the supercomputing database\\nsearch concept for comprehensive identification of peptides, and all their\\nmodified forms within a reasonable time-frame. We demonstrate this by searching\\nGigabytes of experimental MS data against Terabytes of databases where HiCOPS\\ncompletes peptide identification in few minutes using 72 parallel nodes (1728\\ncores) compared to several weeks required by existing state-of-the-art tools\\nusing 1 node (24 cores); 100 minutes vs 5 weeks; 500x speedup. Finally, we\\nformulate a theoretical framework for our overhead-avoiding strategy, and\\nreport superior performance evaluation results for key metrics including\\nexecution time, CPU utilization, speedups, and I/O efficiency. We also\\ndemonstrate superior performance as compared to all existing HPC strategies.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02286'}, {'title': 'Echo-SyncNet: Self-supervised Cardiac View Synchronization in Echocardiography. (arXiv:2102.02287v1 [cs.CV])', 'description': '<p>In echocardiography (echo), an electrocardiogram (ECG) is conventionally used\\nto temporally align different cardiac views for assessing critical\\nmeasurements. However, in emergencies or point-of-care situations, acquiring an\\nECG is often not an option, hence motivating the need for alternative temporal\\nsynchronization methods. Here, we propose Echo-SyncNet, a self-supervised\\nlearning framework to synchronize various cross-sectional 2D echo series\\nwithout any external input. The proposed framework takes advantage of both\\nintra-view and inter-view self supervisions. The former relies on\\nspatiotemporal patterns found between the frames of a single echo cine and the\\nlatter on the interdependencies between multiple cines. The combined\\nsupervisions are used to learn a feature-rich embedding space where multiple\\necho cines can be temporally synchronized. We evaluate the framework with\\nmultiple experiments: 1) Using data from 998 patients, Echo-SyncNet shows\\npromising results for synchronizing Apical 2 chamber and Apical 4 chamber\\ncardiac views; 2) Using data from 3070 patients, our experiments reveal that\\nthe learned representations of Echo-SyncNet outperform a supervised deep\\nlearning method that is optimized for automatic detection of fine-grained\\ncardiac phase; 3) We show the usefulness of the learned representations in a\\none-shot learning scenario of cardiac keyframe detection. Without any\\nfine-tuning, keyframes in 1188 validation patient studies are identified by\\nsynchronizing them with only one labeled reference study. We do not make any\\nprior assumption about what specific cardiac views are used for training and\\nshow that Echo-SyncNet can accurately generalize to views not present in its\\ntraining set. Project repository: github.com/fatemehtd/Echo-SyncNet.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02287'}, {'title': 'Nearest Neighbor-based Importance Weighting. (arXiv:2102.02291v1 [cs.LG])', 'description': '<p>Importance weighting is widely applicable in machine learning in general and\\nin techniques dealing with data covariate shift problems in particular. A\\nnovel, direct approach to determine such importance weighting is presented. It\\nrelies on a nearest neighbor classification scheme and is relatively\\nstraightforward to implement. Comparative experiments on various classification\\ntasks demonstrate the effectiveness of our so-called nearest neighbor weighting\\n(NNeW) scheme. Considering its performance, our procedure can act as a simple\\nand effective baseline method for importance weighting.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02291'}, {'title': 'Predicting the probability distribution of bus travel time to move towards reliable planning of public transport services. (arXiv:2102.02292v1 [cs.LG])', 'description': \"<p>An important aspect of the quality of a public transport service is its\\nreliability, which is defined as the invariability of the service attributes.\\nPreventive measures taken during planning can reduce risks of unreliability\\nthroughout operations. In order to tackle reliability during the service\\nplanning phase, a key piece of information is the long-term prediction of the\\ndensity of the travel time, which conveys the uncertainty of travel times. We\\nintroduce a reliable approach to one of the problems of service planning in\\npublic transport, namely the Multiple Depot Vehicle Scheduling Problem (MDVSP),\\nwhich takes as input a set of trips and the probability density function\\n(p.d.f.) of the travel time of each trip in order to output delay-tolerant\\nvehicle schedules. This work empirically compares probabilistic models for the\\nprediction of the conditional p.d.f. of the travel time, as a first step\\ntowards reliable MDVSP solutions. Two types of probabilistic models, namely\\nsimilarity-based density estimation models and a smoothed Logistic Regression\\nfor probabilistic classification model, are compared on a dataset of more than\\n41,000 trips and 50 bus routes of the city of Montr\\\\'eal. The result of a vast\\nmajority of probabilistic models outperforms that of a Random Forests model,\\nwhich is not inherently probabilistic, thus highlighting the added value of\\nmodeling the conditional p.d.f. of the travel time with probabilistic models. A\\nsimilarity-based density estimation model using a $k$ Nearest Neighbors method\\nand a Kernel Density Estimation predicted the best estimate of the true\\nconditional p.d.f. on this dataset.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02292'}, {'title': 'Variational Bayes survival analysis for unemployment modelling. (arXiv:2102.02295v1 [stat.AP])', 'description': '<p>Mathematical modelling of unemployment dynamics attempts to predict the\\nprobability of a job seeker finding a job as a function of time. This is\\ntypically achieved by using information in unemployment records. These records\\nare right censored, making survival analysis a suitable approach for parameter\\nestimation. The proposed model uses a deep artificial neural network (ANN) as a\\nnon-linear hazard function. Through embedding, high-cardinality categorical\\nfeatures are analysed efficiently. The posterior distribution of the ANN\\nparameters are estimated using a variational Bayes method. The model is\\nevaluated on a time-to-employment data set spanning from 2011 to 2020 provided\\nby the Slovenian public employment service. It is used to determine the\\nemployment probability over time for each individual on the record. Similar\\nmodels could be applied to other questions with multi-dimensional,\\nhigh-cardinality categorical data including censored records. Such data is\\noften encountered in personal records, for example in medical records.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02295'}, {'title': 'Parallax estimation for push-frame satellite imagery: application to super-resolution and 3D surface modeling from Skysat products. (arXiv:2102.02301v1 [cs.CV])', 'description': '<p>Recent constellations of satellites, including the Skysat constellation, are\\nable to acquire bursts of images. This new acquisition mode allows for modern\\nimage restoration techniques, including multi-frame super-resolution. As the\\nsatellite moves during the acquisition of the burst, elevation changes in the\\nscene translate into noticeable parallax. This parallax hinders the results of\\nthe restoration. To cope with this issue, we propose a novel parallax\\nestimation method. The method is composed of a linear Plane+Parallax\\ndecomposition of the apparent motion and a multi-frame optical flow algorithm\\nthat exploits all frames simultaneously. Using SkySat L1A images, we show that\\nthe estimated per-pixel displacements are important for applying multi-frame\\nsuper-resolution on scenes containing elevation changes and that can also be\\nused to estimate a coarse 3D surface model.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02301'}, {'title': 'Cleora: A Simple, Strong and Scalable Graph Embedding Scheme. (arXiv:2102.02302v1 [cs.LG])', 'description': \"<p>The area of graph embeddings is currently dominated by contrastive learning\\nmethods, which demand formulation of an explicit objective function and\\nsampling of positive and negative examples. This creates a conceptual and\\ncomputational overhead. Simple, classic unsupervised approaches like\\nMultidimensional Scaling (MSD) or the Laplacian eigenmap skip the necessity of\\ntedious objective optimization, directly exploiting data geometry.\\nUnfortunately, their reliance on very costly operations such as matrix\\neigendecomposition make them unable to scale to large graphs that are common in\\ntoday's digital world. In this paper we present Cleora: an algorithm which gets\\nthe best of two worlds, being both unsupervised and highly scalable. We show\\nthat high quality embeddings can be produced without the popular step-wise\\nlearning framework with example sampling. An intuitive learning objective of\\nour algorithm is that a node should be similar to its neighbors, without\\nexplicitly pushing disconnected nodes apart. The objective is achieved by\\niterative weighted averaging of node neigbors' embeddings, followed by\\nnormalization across dimensions. Thanks to the averaging operation the\\nalgorithm makes rapid strides across the embedding space and usually reaches\\noptimal embeddings in just a few iterations. Cleora runs faster than other\\nstate-of-the-art CPU algorithms and produces embeddings of competitive quality\\nas measured on downstream tasks: link prediction and node classification. We\\nshow that Cleora learns a data abstraction that is similar to contrastive\\nmethods, yet at much lower computational cost. We open-source Cleora under the\\nMIT license allowing commercial use under https://github.com/Synerise/cleora.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02302'}, {'title': 'Improved Cooperation by Exploiting a Common Signal. (arXiv:2102.02304v1 [cs.MA])', 'description': '<p>Can artificial agents benefit from human conventions? Human societies manage\\nto successfully self-organize and resolve the tragedy of the commons in\\ncommon-pool resources, in spite of the bleak prediction of non-cooperative game\\ntheory. On top of that, real-world problems are inherently large-scale and of\\nlow observability. One key concept that facilitates human coordination in such\\nsettings is the use of conventions. Inspired by human behavior, we investigate\\nthe learning dynamics and emergence of temporal conventions, focusing on\\ncommon-pool resources. Extra emphasis was given in designing a realistic\\nevaluation setting: (a) environment dynamics are modeled on real-world\\nfisheries, (b) we assume decentralized learning, where agents can observe only\\ntheir own history, and (c) we run large-scale simulations (up to 64 agents).\\n</p>\\n<p>Uncoupled policies and low observability make cooperation hard to achieve; as\\nthe number of agents grow, the probability of taking a correct gradient\\ndirection decreases exponentially. By introducing an arbitrary common signal\\n(e.g., date, time, or any periodic set of numbers) as a means to couple the\\nlearning process, we show that temporal conventions can emerge and agents reach\\nsustainable harvesting strategies. The introduction of the signal consistently\\nimproves the social welfare (by 258% on average, up to 3306%), the range of\\nenvironmental parameters where sustainability can be achieved (by 46% on\\naverage, up to 300%), and the convergence speed in low abundance settings (by\\n13% on average, up to 53%).\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02304'}, {'title': 'Typing Errors in Factual Knowledge Graphs: Severity and Possible Ways Out. (arXiv:2102.02307v1 [cs.DB])', 'description': '<p>Factual knowledge graphs (KGs) such as DBpedia and Wikidata have served as\\npart of various downstream tasks and are also widely adopted by artificial\\nintelligence research communities as benchmark datasets. However, we found\\nthese KGs to be surprisingly noisy. In this study, we question the quality of\\nthese KGs, where the typing error rate is estimated to be 27% for\\ncoarse-grained types on average, and even 73% for certain fine-grained types.\\nIn pursuit of solutions, we propose an active typing error detection algorithm\\nthat maximizes the utilization of both gold and noisy labels. We also\\ncomprehensively discuss and compare unsupervised, semi-supervised, and\\nsupervised paradigms to deal with typing errors in factual KGs. The outcomes of\\nthis study provide guidelines for researchers to use noisy factual KGs. To help\\npractitioners deploy the techniques and conduct further research, we published\\nour code and data.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02307'}, {'title': 'Fuzzing Hardware Like Software. (arXiv:2102.02308v1 [cs.AR])', 'description': \"<p>Hardware flaws are permanent and potent: hardware cannot be patched once\\nfabricated, and any flaws may undermine any software executing on top.\\nConsequently, verification time dominates implementation time. The gold\\nstandard in hardware Design Verification (DV) is concentrated at two extremes:\\nrandom dynamic verification and formal verification. Both struggle to root out\\nthe subtle flaws in complex hardware that often manifest as security\\nvulnerabilities. The root problem with random verification is its undirected\\nnature, making it inefficient, while formal verification is constrained by the\\nstate-space explosion problem, making it infeasible against complex designs.\\nWhat is needed is a solution that is directed, yet under-constrained.\\n</p>\\n<p>Instead of making incremental improvements to existing DV approaches, we\\nleverage the observation that existing software fuzzers already provide such a\\nsolution, and adapt them for hardware DV. Specifically, we translate RTL\\nhardware to a software model and fuzz that model. The central challenge we\\naddress is how best to mitigate the differences between the hardware execution\\nmodel and software execution model. This includes: 1) how to represent test\\ncases, 2) what is the hardware equivalent of a crash, 3) what is an appropriate\\ncoverage metric, and 4) how to create a general-purpose fuzzing harness for\\nhardware.\\n</p>\\n<p>To evaluate our approach, we fuzz four IP blocks from Google's OpenTitan SoC.\\nOur experiments reveal a two orders-of-magnitude reduction in run time to\\nachieve Finite State Machine (FSM) coverage over traditional dynamic\\nverification schemes. Moreover, with our design-agnostic harness, we achieve\\nover 88% HDL line coverage in three out of four of our designs -- even without\\nany initial seeds.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02308'}, {'title': 'Causal Sufficiency and Actual Causation. (arXiv:2102.02311v1 [cs.AI])', 'description': \"<p>Pearl opened the door to formally defining actual causation using causal\\nmodels. His approach rests on two strategies: first, capturing the widespread\\nintuition that X=x causes Y=y iff X=x is a Necessary Element of a Sufficient\\nSet for Y=y, and second, showing that his definition gives intuitive answers on\\na wide set of problem cases. This inspired dozens of variations of his\\ndefinition of actual causation, the most prominent of which are due to Halpern\\n&amp; Pearl. Yet all of them ignore Pearl's first strategy, and the second strategy\\ntaken by itself is unable to deliver a consensus. This paper offers a way out\\nby going back to the first strategy: it offers six formal definitions of causal\\nsufficiency and two interpretations of necessity. Combining the two gives\\ntwelve new definitions of actual causation. Several interesting results about\\nthese definitions and their relation to the various Halpern &amp; Pearl definitions\\nare presented. Afterwards the second strategy is evaluated as well. In order to\\nmaximize neutrality, the paper relies mostly on the examples and intuitions of\\nHalpern &amp; Pearl. One definition comes out as being superior to all others, and\\nis therefore suggested as a new definition of actual causation.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02311'}, {'title': 'Real-Time Optimal Trajectory Planning for Autonomous Vehicles and Lap Time Simulation Using Machine Learning. (arXiv:2102.02315v1 [cs.RO])', 'description': '<p>The widespread development of driverless vehicles has led to the formation of\\nautonomous racing competitions, where the high speeds and fierce rivalry in\\nmotorsport provide a testbed to accelerate technology development. A particular\\nchallenge for an autonomous vehicle is that of identifying a target trajectory\\n- or in the case of a racing car, the ideal racing line. Many existing\\napproaches to identifying the racing line are either not the time-optimal\\nsolutions, or have solution times which are computationally expensive, thus\\nrendering them unsuitable for real-time application using on-board processing\\nhardware. This paper describes a machine learning approach to generating an\\naccurate prediction of the racing line in real-time on desktop processing\\nhardware. The proposed algorithm is a dense feed-forward neural network,\\ntrained using a dataset comprising racing lines for a large number of circuits\\ncalculated via a traditional optimal control lap time simulation. The network\\nis capable of predicting the racing line with a mean absolute error of\\n+/-0.27m, meaning that the accuracy outperforms a human driver, and is\\ncomparable to other parts of the autonomous vehicle control system. The system\\ngenerates predictions within 33ms, making it over 9,000 times faster than\\ntraditional methods of finding the optimal racing line. Results suggest that a\\ndata-driven approach may therefore be favourable for real-time generation of\\nnear-optimal racing lines than traditional computational methods.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02315'}, {'title': 'System Intelligence for UAV-Based Mission Critical with Challenging 5G/B5G Connectivity. (arXiv:2102.02318v1 [cs.NI])', 'description': \"<p>Unmanned aerial vehicles (UAVs) and communication systems are fundamental\\nelements in Mission Critical services, such as search and rescue. In this\\narticle, we introduce an architecture for managing and orchestrating 5G and\\nbeyond networks that operate over a heterogeneous infrastructure with UAVs'\\naid. UAVs are used for collecting and processing data, as well as improving\\ncommunications. The proposed System Intelligence (SI) architecture was designed\\nto comply with recent standardization works, especially the ETSI Experiential\\nNetworked Intelligence specifications. Another contribution of this article is\\nan evaluation using a testbed based on a virtualized non-standalone 5G core and\\na 4G Radio Access Network (RAN) implemented with open-source software. The\\nexperimental results indicate, for instance, that SI can substantially improve\\nthe latency of UAV-based services by splitting deep neural networks between UAV\\nand edge or cloud equipment. Other experiments explore the slicing of RAN\\nresources and efficient placement of virtual network functions to assess the\\nbenefits of incorporating intelligence in UAV-based mission-critical services.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02318'}, {'title': 'One Label, One Billion Faces: Usage and Consistency of Racial Categories in Computer Vision. (arXiv:2102.02320v1 [cs.CV])', 'description': '<p>Computer vision is widely deployed, has highly visible, society altering\\napplications, and documented problems with bias and representation. Datasets\\nare critical for benchmarking progress in fair computer vision, and often\\nemploy broad racial categories as population groups for measuring group\\nfairness. Similarly, diversity is often measured in computer vision datasets by\\nascribing and counting categorical race labels. However, racial categories are\\nill-defined, unstable temporally and geographically, and have a problematic\\nhistory of scientific use. Although the racial categories used across datasets\\nare superficially similar, the complexity of human race perception suggests the\\nracial system encoded by one dataset may be substantially inconsistent with\\nanother. Using the insight that a classifier can learn the racial system\\nencoded by a dataset, we conduct an empirical study of computer vision datasets\\nsupplying categorical race labels for face images to determine the\\ncross-dataset consistency and generalization of racial categories. We find that\\neach dataset encodes a substantially unique racial system, despite nominally\\nequivalent racial categories, and some racial categories are systemically less\\nconsistent than others across datasets. We find evidence that racial categories\\nencode stereotypes, and exclude ethnic groups from categories on the basis of\\nnonconformity to stereotypes. Representing a billion humans under one racial\\ncategory may obscure disparities and create new ones by encoding stereotypes of\\nracial systems. The difficulty of adequately converting the abstract concept of\\nrace into a tool for measuring fairness underscores the need for a method more\\nflexible and culturally aware than racial categories.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02320'}, {'title': 'Query Complexity of Least Absolute Deviation Regression via Robust Uniform Convergence. (arXiv:2102.02322v1 [cs.LG])', 'description': '<p>Consider a regression problem where the learner is given a large collection\\nof $d$-dimensional data points, but can only query a small subset of the\\nreal-valued labels. How many queries are needed to obtain a $1+\\\\epsilon$\\nrelative error approximation of the optimum? While this problem has been\\nextensively studied for least squares regression, little is known for other\\nlosses. An important example is least absolute deviation regression ($\\\\ell_1$\\nregression) which enjoys superior robustness to outliers compared to least\\nsquares. We develop a new framework for analyzing importance sampling methods\\nin regression problems, which enables us to show that the query complexity of\\nleast absolute deviation regression is $\\\\Theta(d/\\\\epsilon^2)$ up to logarithmic\\nfactors. We further extend our techniques to show the first bounds on the query\\ncomplexity for any $\\\\ell_p$ loss with $p\\\\in(1,2)$. As a key novelty in our\\nanalysis, we introduce the notion of robust uniform convergence, which is a new\\napproximation guarantee for the empirical loss. While it is inspired by uniform\\nconvergence in statistical learning, our approach additionally incorporates a\\ncorrection term to avoid unnecessary variance due to outliers. This can be\\nviewed as a new connection between statistical learning theory and variance\\nreduction techniques in stochastic optimization, which should be of independent\\ninterest.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02322'}, {'title': 'Effects of Number of Filters of Convolutional Layers on Speech Recognition Model Accuracy. (arXiv:2102.02326v1 [cs.LG])', 'description': '<p>Inspired by the progress of the End-to-End approach [1], this paper\\nsystematically studies the effects of Number of Filters of convolutional layers\\non the model prediction accuracy of CNN+RNN (Convolutional Neural Networks\\nadding to Recurrent Neural Networks) for ASR Models (Automatic Speech\\nRecognition). Experimental results show that only when the CNN Number of\\nFilters exceeds a certain threshold value is adding CNN to RNN able to improve\\nthe performance of the CNN+RNN speech recognition model, otherwise some\\nparameter ranges of CNN can render it useless to add the CNN to the RNN model.\\nOur results show a strong dependency of word accuracy on the Number of Filters\\nof convolutional layers. Based on the experimental results, the paper suggests\\na possible hypothesis of Sound-2-Vector Embedding (Convolutional Embedding) to\\nexplain the above observations.\\n</p>\\n<p>Based on this Embedding hypothesis and the optimization of parameters, the\\npaper develops an End-to-End speech recognition system which has a high word\\naccuracy but also has a light model-weight. The developed LVCSR (Large\\nVocabulary Continuous Speech Recognition) model has achieved quite a high word\\naccuracy of 90.2% only by its Acoustic Model alone, without any assistance from\\nintermediate phonetic representation and any Language Model. Its acoustic model\\ncontains only 4.4 million weight parameters, compared to the 35~68 million\\nacoustic-model weight parameters in DeepSpeech2 [2] (one of the top\\nstate-of-the-art LVCSR models) which can achieve a word accuracy of 91.5%. The\\nlight-weighted model is good for improving the transcribing computing\\nefficiency and also useful for mobile devices, Driverless Vehicles, etc. Our\\nmodel weight is reduced to ~10% the size of DeepSpeech2, but our model accuracy\\nremains close to that of DeepSpeech2. If combined with a Language Model, our\\nLVCSR system is able to achieve 91.5% word accuracy.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02326'}, {'title': 'Modeling Complex Financial Products. (arXiv:2102.02329v1 [cs.LG])', 'description': '<p>The objective of this paper is to explore how financial big data and machine\\nlearning methods can be applied to model and understand complex financial\\nproducts. We focus on residential mortgage backed securities, resMBS, that were\\nat the heart of the 2008 US financial crisis. The securities are contained\\nwithin a prospectus and have a complex payoff structure. Multiple financial\\ninstitutions form a supply chain to create the prospectuses. We provide insight\\ninto the performance of the resMBS securities through a series of increasingly\\ncomplex models. First, models at the security level directly identify salient\\nfeatures of resMBS securities that impact their performance. Second, we extend\\nthe model to include prospectus level features. We are the first to demonstrate\\nthat the composition of the prospectus is associated with the performance of\\nsecurities. Finally, to develop a deeper understanding of the role of the\\nsupply chain, we use unsupervised probabilistic methods, in particular, dynamic\\ntopics models (DTM), to understand community formation and temporal evolution\\nalong the chain. A comprehensive model provides insight into the impact of DTM\\ncommunities on the issuance and evolution of prospectuses, and eventually the\\nperformance of resMBS securities.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02329'}, {'title': 'Function Delivery Network: Extending Serverless Computing for Heterogeneous Platforms. (arXiv:2102.02330v1 [cs.DC])', 'description': \"<p>Serverless computing has rapidly grown following the launch of Amazon's\\nLambda platform. Function-as-a-Service (FaaS) a key enabler of serverless\\ncomputing allows an application to be decomposed into simple, standalone\\nfunctions that are executed on a FaaS platform. The FaaS platform is\\nresponsible for deploying and facilitating resources to the functions. Several\\nof today's cloud applications spread over heterogeneous connected computing\\nresources and are highly dynamic in their structure and resource requirements.\\nHowever, FaaS platforms are limited to homogeneous clusters and homogeneous\\nfunctions and do not account for the data access behavior of functions before\\nscheduling.\\n</p>\\n<p>We introduce an extension of FaaS to heterogeneous clusters and to support\\nheterogeneous functions through a network of distributed heterogeneous target\\nplatforms called Function Delivery Network (FDN). A target platform is a\\ncombination of a cluster of homogeneous nodes and a FaaS platform on top of it.\\nFDN provides Function-Delivery-as-a-Service (FDaaS), delivering the function to\\nthe right target platform. We showcase the opportunities such as varied target\\nplatform's characteristics, possibility of collaborative execution between\\nmultiple target platforms, and localization of data that the FDN offers in\\nfulfilling two objectives: Service Level Objective (SLO) requirements and\\nenergy efficiency when scheduling functions by evaluating over five distributed\\ntarget platforms using the FDNInspector, a tool developed by us for\\nbenchmarking distributed target platforms. Scheduling functions on an edge\\ntarget platform in our evaluation reduced the overall energy consumption by 17x\\nwithout violating the SLO requirements in comparison to scheduling on a\\nhigh-end target platform.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02330'}, {'title': 'The Enigma of Complexity. (arXiv:2102.02332v1 [cs.NE])', 'description': '<p>In this paper we examine the concept of complexity as it applies to\\ngenerative art and design. Complexity has many different, discipline specific\\ndefinitions, such as complexity in physical systems (entropy), algorithmic\\nmeasures of information complexity and the field of \"complex systems\". We apply\\na series of different complexity measures to three different generative art\\ndatasets and look at the correlations between complexity and individual\\naesthetic judgement by the artist (in the case of two datasets) or the\\nphysically measured complexity of 3D forms. Our results show that the degree of\\ncorrelation is different for each set and measure, indicating that there is no\\noverall \"better\" measure. However, specific measures do perform well on\\nindividual datasets, indicating that careful choice can increase the value of\\nusing such measures. We conclude by discussing the value of direct measures in\\ngenerative and evolutionary art, reinforcing recent findings from neuroimaging\\nand psychology which suggest human aesthetic judgement is informed by many\\nextrinsic factors beyond the measurable properties of the object being judged.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02332'}, {'title': 'Self-Supervised Claim Identification for Automated Fact Checking. (arXiv:2102.02335v1 [cs.CL])', 'description': '<p>We propose a novel, attention-based self-supervised approach to identify\\n\"claim-worthy\" sentences in a fake news article, an important first step in\\nautomated fact-checking. We leverage \"aboutness\" of headline and content using\\nattention mechanism for this task. The identified claims can be used for\\ndownstream task of claim verification for which we are releasing a benchmark\\ndataset of manually selected compelling articles with veracity labels and\\nassociated evidence. This work goes beyond stylistic analysis to identifying\\ncontent that influences reader belief. Experiments with three datasets show the\\nstrength of our model. Data and code available at\\nhttps://github.com/architapathak/Self-Supervised-ClaimIdentification\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02335'}, {'title': 'On the Approximation Power of Two-Layer Networks of Random ReLUs. (arXiv:2102.02336v1 [cs.LG])', 'description': '<p>This paper considers the following question: how well can depth-two ReLU\\nnetworks with randomly initialized bottom-level weights represent smooth\\nfunctions? We give near-matching upper- and lower-bounds for\\n$L_2$-approximation in terms of the Lipschitz constant, the desired accuracy,\\nand the dimension of the problem, as well as similar results in terms of\\nSobolev norms. Our positive results employ tools from harmonic analysis and\\nridgelet representation theory, while our lower-bounds are based on (robust\\nversions of) dimensionality arguments.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02336'}, {'title': 'Environment Predictive Coding for Embodied Agents. (arXiv:2102.02337v1 [cs.CV])', 'description': \"<p>We introduce environment predictive coding, a self-supervised approach to\\nlearn environment-level representations for embodied agents. In contrast to\\nprior work on self-supervised learning for images, we aim to jointly encode a\\nseries of images gathered by an agent as it moves about in 3D environments. We\\nlearn these representations via a zone prediction task, where we intelligently\\nmask out portions of an agent's trajectory and predict them from the unmasked\\nportions, conditioned on the agent's camera poses. By learning such\\nrepresentations on a collection of videos, we demonstrate successful transfer\\nto multiple downstream navigation-oriented tasks. Our experiments on the\\nphotorealistic 3D environments of Gibson and Matterport3D show that our method\\noutperforms the state-of-the-art on challenging tasks with only a limited\\nbudget of experience.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02337'}, {'title': 'Microscopic Patterns in the 2D Phase-Field-Crystal Model. (arXiv:2102.02338v1 [math.NA])', 'description': '<p>Using the recently developed theory of rigorously validated numerics, we\\naddress the Phase-Field-Crystal (PFC) model at the microscopic (atomistic)\\nlevel. We show the existence of critical points and local minimizers associated\\nwith \"classical\" candidates, grain boundaries, and localized patterns. We\\nfurther address the dynamical relationships between the observed patterns for\\nfixed parameters and across parameter space, then formulate several conjectures\\non the dynamical connections (or orbits) between steady states.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02338'}, {'title': 'MUFASA: Multimodal Fusion Architecture Search for Electronic Health Records. (arXiv:2102.02340v1 [cs.LG])', 'description': \"<p>One important challenge of applying deep learning to electronic health\\nrecords (EHR) is the complexity of their multimodal structure. EHR usually\\ncontains a mixture of structured (codes) and unstructured (free-text) data with\\nsparse and irregular longitudinal features -- all of which doctors utilize when\\nmaking decisions. In the deep learning regime, determining how different\\nmodality representations should be fused together is a difficult problem, which\\nis often addressed by handcrafted modeling and intuition. In this work, we\\nextend state-of-the-art neural architecture search (NAS) methods and propose\\nMUltimodal Fusion Architecture SeArch (MUFASA) to simultaneously search across\\nmultimodal fusion strategies and modality-specific architectures for the first\\ntime. We demonstrate empirically that our MUFASA method outperforms established\\nunimodal NAS on public EHR data with comparable computation costs. In addition,\\nMUFASA produces architectures that outperform Transformer and Evolved\\nTransformer. Compared with these baselines on CCS diagnosis code prediction,\\nour discovered models improve top-5 recall from 0.88 to 0.91 and demonstrate\\nthe ability to generalize to other EHR tasks. Studying our top architecture in\\ndepth, we provide empirical evidence that MUFASA's improvements are derived\\nfrom its ability to both customize modeling for each data modality and find\\neffective fusion strategies.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02340'}, {'title': 'Horizontally Fused Training Array: An Effective Hardware Utilization Squeezer for Training Novel Deep Learning Models. (arXiv:2102.02344v1 [cs.LG])', 'description': '<p>Driven by the tremendous effort in researching novel deep learning (DL)\\nalgorithms, the training cost of developing new models increases staggeringly\\nin recent years. To reduce this training cost and optimize the cluster-wide\\nhardware resource usage, we analyze GPU cluster usage statistics from a\\nwell-known research institute. Our study reveals that single-accelerator\\ntraining jobs can dominate the cluster-wide resource consumption when launched\\nrepetitively (e.g., for hyper-parameter tuning) while severely underutilizing\\nthe hardware. This is because DL researchers and practitioners often lack the\\nrequired expertise to independently optimize their own workloads. Fortunately,\\nwe observe that such workloads have the following unique characteristics: (i)\\nthe models among jobs often have the same types of operators with the same\\nshapes, and (ii) the inter-model horizontal fusion of such operators is\\nmathematically equivalent to other already well-optimized operators. Thus, to\\nhelp DL researchers and practitioners effectively and easily improve the\\nhardware utilization of their novel DL training workloads, we propose\\nHorizontally Fused Training Array (HFTA). HFTA is a new DL framework extension\\nlibrary that horizontally fuses the models from different repetitive jobs\\ndeeply down to operators, and then trains those models simultaneously on a\\nshared accelerator. On three emerging DL training workloads and\\nstate-of-the-art accelerators (GPUs and TPUs), HFTA demonstrates strong\\neffectiveness in squeezing out hardware utilization and achieves up to $15.1\\n\\\\times$ higher training throughput vs. the standard practice of running each\\njob on a separate accelerator.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02344'}, {'title': 'On Multi-Human Multi-Robot Remote Interaction: A Study of Transparency, Inter-Human Communication, and Information Loss in Remote Interaction. (arXiv:2102.02351v1 [cs.RO])', 'description': \"<p>In this paper, we investigate how to design an effective interface for remote\\nmulti-human multi-robot interaction. While significant research exists on\\ninterfaces for individual human operators, little research exists for the\\nmulti-human case. Yet, this is a critical problem to solve to make complex,\\nlarge-scale missions achievable in which direct human involvement is impossible\\nor undesirable, and robot swarms act as a semi-autonomous agents. This paper's\\ncontribution is twofold. The first contribution is an exploration of the design\\nspace of computer-based interfaces for multi-human multi-robot operations. In\\nparticular, we focus on information transparency and on the factors that affect\\ninter-human communication in ideal conditions, i.e., without communication\\nissues. Our second contribution concerns the same problem, but considering\\nincreasing degrees of information loss, defined as intermittent reception of\\ndata with noticeable gaps between individual receipts. We derived a set of\\ndesign recommendations based on two user studies involving 48 participants.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02351'}, {'title': 'Entropic Dynamics of Networks. (arXiv:2102.02355v1 [physics.soc-ph])', 'description': '<p>Here we present the entropic dynamics formalism for networks. That is, a\\nframework for the dynamics of graphs meant to represent a network derived from\\nthe principle of maximum entropy and the rate of transition is obtained taking\\ninto account the natural information geometry of probability distributions. We\\napply this framework to the Gibbs distribution of random graphs obtained with\\nconstraints on the node connectivity. The information geometry for this graph\\nensemble is calculated and the dynamical process is obtained as a diffusion\\nequation. We compare the steady state of this dynamics to degree distributions\\nfound on real-world networks.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02355'}, {'title': 'A Practical Coding Scheme for the BSC with Feedback. (arXiv:2102.02358v1 [cs.IT])', 'description': '<p>We provide a practical implementation of the rubber method of Ahlswede et al.\\nfor binary alphabets. The idea is to create the \"skeleton\" sequence therein via\\nan arithmetic decoder designed for a particular $k$-th order Markov chain. For\\nthe stochastic binary symmetric channel, we show that the scheme is nearly\\noptimal in a strong sense for certain parameters.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02358'}, {'title': 'Operational Semantics with Hierarchical Abstract Syntax Graphs. (arXiv:2102.02363v1 [cs.PL])', 'description': \"<p>This is a motivating tutorial introduction to a semantic analysis of\\nprogramming languages using a graphical language as the representation of\\nterms, and graph rewriting as a representation of reduction rules. We show how\\nthe graphical language automatically incorporates desirable features, such as\\nalpha-equivalence and how it can describe pure computation, imperative store,\\nand control features in a uniform framework. The graph semantics combines some\\nof the best features of structural operational semantics and abstract machines,\\nwhile offering powerful new methods for reasoning about contextual equivalence.\\n</p>\\n<p>All technical details are available in an extended technical report by Muroya\\nand the author and in Muroya's doctoral dissertation.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02363'}, {'title': 'On Stochastic Rewriting and Combinatorics via Rule-Algebraic Methods. (arXiv:2102.02364v1 [cs.LO])', 'description': '<p>Building upon the rule-algebraic stochastic mechanics framework, we present\\nnew results on the relationship of stochastic rewriting systems described in\\nterms of continuous-time Markov chains, their embedded discrete-time Markov\\nchains and certain types of generating function expressions in combinatorics.\\nWe introduce a number of generating function techniques that permit a novel\\nform of static analysis for rewriting systems based upon marginalizing\\ndistributions over the states of the rewriting systems via pattern-counting\\nobservables.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02364'}, {'title': 'Wind Field Reconstruction with Adaptive Random Fourier Features. (arXiv:2102.02365v1 [math.NA])', 'description': '<p>We investigate the use of spatial interpolation methods for reconstructing\\nthe horizontal near-surface wind field given a sparse set of measurements. In\\nparticular, random Fourier features is compared to a set of benchmark methods\\nincluding Kriging and Inverse distance weighting. Random Fourier features is a\\nlinear model $\\\\beta(\\\\pmb x) = \\\\sum_{k=1}^K \\\\beta_k e^{i\\\\omega_k \\\\pmb x}$\\napproximating the velocity field, with frequencies $\\\\omega_k$ randomly sampled\\nand amplitudes $\\\\beta_k$ trained to minimize a loss function. We include a\\nphysically motivated divergence penalty term $|\\\\nabla \\\\cdot \\\\beta(\\\\pmb x)|^2$,\\nas well as a penalty on the Sobolev norm. We derive a bound on the\\ngeneralization error and derive a sampling density that minimizes the bound.\\nFollowing (<a href=\"/abs/2007.10683\">arXiv:2007.10683</a> [math.NA]), we devise an adaptive\\nMetropolis-Hastings algorithm for sampling the frequencies of the optimal\\ndistribution. In our experiments, our random Fourier features model outperforms\\nthe benchmark models.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02365'}, {'title': 'Parallel Independence in Attributed Graph Rewriting. (arXiv:2102.02366v1 [cs.LO])', 'description': '<p>In order to define graph transformations by the simultaneous application of\\nconcurrent rules, we have adopted in previous work a structure of attributed\\ngraphs stable by unions. We analyze the consequences on parallel independence,\\na property that characterizes the possibility to resort to sequential\\nrewriting. This property turns out to depend not only on the left-hand side of\\nrules, as in algebraic approaches to graph rewriting, but also on their\\nright-hand side. It is then shown that, of three possible definitions of\\nparallel rewriting, only one is convenient in the light of parallel\\nindependence.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02366'}, {'title': 'Finite Difference Weerakoon-Fernando Method to solve nonlinear equations without using derivatives. (arXiv:2102.02367v1 [math.NA])', 'description': \"<p>This research was mainly conducted to explore the possibility of formulating\\nan efficient algorithm to find roots of nonlinear equations without using the\\nderivative of the function. The Weerakoon-Fernando method had been taken as the\\nbase in this project to find a new method without the derivative since\\nWeerakoon-Fernando method gives 3rd order convergence. After several\\nunsuccessful attempts we were able to formulate the Finite Difference\\nWeerakoon-Fernando Method (FDWFM) presented here. We noticed that the FDWFM\\napproaches the root faster than any other existing method in the absence of the\\nderivatives as an example, the popular nonlinear equation solver such as secant\\nmethod (order of convergence is 1.618) in the absence of the derivative. And\\nthe FDWFM had three function evaluations and secant method had two function\\nevaluations. By implementing FDWFM on nonlinear equations with complex roots\\nand also on systems of nonlinear equations, we received very encouraging\\nresults. When applying the FDWFM to systems of nonlinear equations, we resolved\\nthe involvement of the Jacobian problem by following the procedure in the\\nBroyden's method. The computational order of convergence of the FDWFM was close\\nto 2.5 for all these cases. This will undoubtedly provide scientists the\\nefficient numerical algorithm, that doesn't need the derivative of the function\\nto solve nonlinear equations, that they were searching for over centuries.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02367'}, {'title': 'Verifying Security Vulnerabilities in Large Software Systems using Multi-Core k-Induction. (arXiv:2102.02368v1 [cs.CR])', 'description': '<p>Computer-based systems have been used to solve several domain problems, such\\nas industrial, military, education, and wearable. Those systems need\\nhigh-quality software to guarantee security and safety. We advocate that\\nBounded Model Checking (BMC) techniques can detect security vulnerabilities in\\nthe early stages of development processes. However, this technique struggles to\\nscale up and verify large software commonly found on computer-based systems.\\nHere, we develop and evaluate a pragmatic approach to verify large software\\nsystems using a state-of-the-art bounded model checker. In particular, we\\npre-process the input source-code files and then guide the model checker to\\nexplore the code systematically. We also present a multi-core implementation of\\nthe k-induction proof algorithm to verify and falsify large software systems\\niteratively. Our experimental results using the Efficient SMT-based Model\\nChecker (ESBMC) show that our approach can guide ESBMC to efficiently verify\\nlarge software systems. We evaluate our approach using the PuTTY application to\\nverify 136 files and 2803 functions in less than 86 minutes, and the SlimGuard\\nallocator, where we have found real security vulnerabilities confirmed by the\\ndevelopers. We conclude that our approach can successfully guide a bounded\\nmodel checker to verify large software systems systematically.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02368'}, {'title': 'MeInGame: Create a Game Character Face from a Single Portrait. (arXiv:2102.02371v1 [cs.CV])', 'description': '<p>Many deep learning based 3D face reconstruction methods have been proposed\\nrecently, however, few of them have applications in games. Current game\\ncharacter customization systems either require players to manually adjust\\nconsiderable face attributes to obtain the desired face, or have limited\\nfreedom of facial shape and texture. In this paper, we propose an automatic\\ncharacter face creation method that predicts both facial shape and texture from\\na single portrait, and it can be integrated into most existing 3D games.\\nAlthough 3D Morphable Face Model (3DMM) based methods can restore accurate 3D\\nfaces from single images, the topology of 3DMM mesh is different from the\\nmeshes used in most games. To acquire fidelity texture, existing methods\\nrequire a large amount of face texture data for training, while building such\\ndatasets is time-consuming and laborious. Besides, such a dataset collected\\nunder laboratory conditions may not generalized well to in-the-wild situations.\\nTo tackle these problems, we propose 1) a low-cost facial texture acquisition\\nmethod, 2) a shape transfer algorithm that can transform the shape of a 3DMM\\nmesh to games, and 3) a new pipeline for training 3D game face reconstruction\\nnetworks. The proposed method not only can produce detailed and vivid game\\ncharacters similar to the input portrait, but can also eliminate the influence\\nof lighting and occlusions. Experiments show that our method outperforms\\nstate-of-the-art methods used in games.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02371'}, {'title': 'Coevolution of theoretical and applied research: a case study of graphene research by temporal and geographic analysis. (arXiv:2102.02372v1 [cs.DL])', 'description': '<p>As a part of science of science (SciSci) research, the evolution of\\nscientific disciplines has been attracting a great deal of attention recently.\\nThis kind of discipline level analysis not only give insights of one particular\\nfield but also shed light on general principles of scientific enterprise. In\\nthis paper we focus on graphene research, a fast growing field covers both\\ntheoretical and applied study. Using co-clustering method, we split graphene\\nliterature into two groups and confirm that one group is about theoretical\\nresearch (T) and another corresponds to applied research (A). We analyze the\\nproportion of T/A and found applied research becomes more and more popular\\nafter 2007. Geographical analysis demonstrated that countries have different\\npreference in terms of T/A and they reacted differently to research trend. The\\ninteraction between two groups has been analyzed and shows that T extremely\\nrelies on T and A heavily relies on A, however the situation is very stable for\\nT but changed markedly for A. No geographic difference is found for the\\ninteraction dynamics. Our results give a comprehensive picture of graphene\\nresearch evolution and also provide a general framework which is able to\\nanalyze other disciplines.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02372'}, {'title': 'Sampling in Combinatorial Spaces with SurVAE Flow Augmented MCMC. (arXiv:2102.02374v1 [cs.LG])', 'description': '<p>Hybrid Monte Carlo is a powerful Markov Chain Monte Carlo method for sampling\\nfrom complex continuous distributions. However, a major limitation of HMC is\\nits inability to be applied to discrete domains due to the lack of gradient\\nsignal. In this work, we introduce a new approach based on augmenting Monte\\nCarlo methods with SurVAE Flows to sample from discrete distributions using a\\ncombination of neural transport methods like normalizing flows and variational\\ndequantization, and the Metropolis-Hastings rule. Our method first learns a\\ncontinuous embedding of the discrete space using a surjective map and\\nsubsequently learns a bijective transformation from the continuous space to an\\napproximately Gaussian distributed latent variable. Sampling proceeds by\\nsimulating MCMC chains in the latent space and mapping these samples to the\\ntarget discrete space via the learned transformations. We demonstrate the\\nefficacy of our algorithm on a range of examples from statistics, computational\\nphysics and machine learning, and observe improvements compared to alternative\\nalgorithms.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02374'}, {'title': 'A survey of motion planning algorithms for intelligent robotics. (arXiv:2102.02376v1 [cs.RO])', 'description': '<p>We investigate and analyze principles of typical motion planning algorithms.\\nThese include traditional planning algorithms, supervised learning, optimal\\nvalue reinforcement learning, policy gradient reinforcement learning.\\nTraditional planning algorithms we investigated include graph search\\nalgorithms, sampling-based algorithms, and interpolating curve algorithms.\\nSupervised learning algorithms include MSVM, LSTM, MCTS and CNN. Optimal value\\nreinforcement learning algorithms include Q learning, DQN, double DQN, dueling\\nDQN. Policy gradient algorithms include policy gradient method, actor-critic\\nalgorithm, A3C, A2C, DPG, DDPG, TRPO and PPO. New general criteria are also\\nintroduced to evaluate performance and application of motion planning\\nalgorithms by analytical comparisons. Convergence speed and stability of\\noptimal value and policy gradient algorithms are specially analyzed. Future\\ndirections are presented analytically according to principles and analytical\\ncomparisons of motion planning algorithms. This paper provides researchers with\\na clear and comprehensive understanding about advantages, disadvantages,\\nrelationships, and future of motion planning algorithms in robotics, and paves\\nways for better motion planning algorithms.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02376'}, {'title': 'Mainstreaming of conspiracy theories and misinformation. (arXiv:2102.02382v1 [physics.soc-ph])', 'description': \"<p>Parents - particularly moms - increasingly consult social media for support\\nwhen taking decisions about their young children, and likely also when advising\\nother family members such as elderly relatives. Minimizing malignant online\\ninfluences is therefore crucial to securing their assent for policies ranging\\nfrom vaccinations, masks and social distancing against the pandemic, to\\nhousehold best practices against climate change, to acceptance of future 5G\\ntowers nearby. Here we show how a strengthening of bonds across online\\ncommunities during the pandemic, has led to non-Covid-19 conspiracy theories\\n(e.g. fluoride, chemtrails, 5G) attaining heightened access to mainstream\\nparent communities. Alternative health communities act as the critical conduits\\nbetween conspiracy theorists and parents, and make the narratives more\\npalatable to the latter. We demonstrate experimentally that these\\ninter-community bonds can perpetually generate new misinformation, irrespective\\nof any changes in factual information. Our findings show explicitly why\\nFacebook's current policies have failed to stop the mainstreaming of\\nnon-Covid-19 and Covid-19 conspiracy theories and misinformation, and why\\ntargeting the largest communities will not work. A simple yet exactly solvable\\nand empirically grounded mathematical model, shows how modest tailoring of\\nmainstream communities' couplings could prevent them from tipping against\\nestablishment guidance. Our conclusions should also apply to other social media\\nplatforms and topics.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02382'}, {'title': 'A Possible Artificial Intelligence Ecosystem Avatar: the Moorea case (IDEA). (arXiv:2102.02384v1 [cs.AI])', 'description': '<p>High-throughput data collection techniques and largescale (cloud) computing\\nare transforming our understanding of ecosystems at all scales by allowing the\\nintegration of multimodal data such as physics, chemistry, biology, ecology,\\nfishing, economics and other social sciences in a common computational\\nframework. We focus in this paper on a large scale data assimilation and\\nprediction backbone based on Deep Stacking Networks (DSN) in the frame of the\\nIDEA (Island Digital Ecosystem Avatars) project (Moorea Island), based on the\\nsubdivision of the island in watersheds and lagoon units. We also describe\\nseveral kinds of raw data that can train and constrain such an ecosystem avatar\\nmodel, as well as second level data such as ecological or physical indexes /\\nindicators.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02384'}, {'title': 'First- and Second-Moment Constrained Gaussian Channels. (arXiv:2102.02388v1 [cs.IT])', 'description': '<p>This paper studies the channel capacity of intensity-modulation\\ndirect-detection (IM/DD) visible light communication (VLC) systems under both\\noptical and electrical power constraints. Specifically, it derives the\\nasymptotic capacities in the high and low signal-to-noise ratio (SNR) regimes\\nunder peak, first-moment, and second-moment constraints. The results show that\\nfirst- and second-moment constraints are never simultaneously active in the\\nasymptotic low-SNR regime, and only in few cases in the asymptotic high-SNR\\nregime. Moreover, the second-moment constraint is more stringent in the\\nasymptotic low-SNR regime than in the high-SNR regime.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02388'}, {'title': 'A Universal Framework for Featurization of Atomistic Systems. (arXiv:2102.02390v1 [physics.chem-ph])', 'description': '<p>Molecular dynamics simulations are an invaluable tool in numerous scientific\\nfields. However, the ubiquitous classical force fields cannot describe reactive\\nsystems, and quantum molecular dynamics are too computationally demanding to\\ntreat large systems or long timescales. Reactive force fields based on physics\\nor machine learning can be used to bridge the gap in time and length scales,\\nbut these force fields require substantial effort to construct and are highly\\nspecific to given chemical composition and application. The extreme flexibility\\nof machine learning models promises to yield reactive force fields that provide\\na more general description of chemical bonding. However, a significant\\nlimitation of machine learning models is the use of element-specific features,\\nleading to models that scale poorly with the number of elements. This work\\nintroduces the Gaussian multi-pole (GMP) featurization scheme that utilizes\\nphysically-relevant multi-pole expansions of the electron density around atoms\\nto yield feature vectors that interpolate between element types and have a\\nfixed dimension regardless of the number of elements present. We combine GMP\\nwith neural networks to directly compare it to the widely-used Behler-Parinello\\nsymmetry functions for the MD17 dataset, revealing that it exhibits improved\\naccuracy and computational efficiency. Further, we demonstrate that GMP-based\\nmodels can achieve chemical accuracy for the QM9 dataset, and their accuracy\\nremains reasonable even when extrapolating to new elements. Finally, we test\\nGMP-based models for the Open Catalysis Project (OCP) dataset, revealing\\ncomparable performance and improved learning rates when compared to graph\\nconvolutional deep learning models. The results indicate that this\\nfeaturization scheme fills a critical gap in the construction of efficient and\\ntransferable reactive force fields.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02390'}, {'title': 'Refined Grey-Box Fuzzing with SIVO. (arXiv:2102.02394v1 [cs.CR])', 'description': '<p>We design and implement from scratch a new fuzzer called SIVO that refines\\nmultiple stages of grey-box fuzzing. First, SIVO refines data-flow fuzzing in\\ntwo ways: (a) it provides a new taint inference engine that requires only\\nlogarithmic in the input size number of tests to infer the dependency of all\\nprogram branches on the input bytes, and (b) it deploys a novel method for\\ninverting branches by solving directly and efficiently systems of inequalities.\\nSecond, our fuzzer refines accurate tracking and detection of code coverage\\nwith simple and easily implementable methods. Finally, SIVO refines selection\\nof parameters and strategies by parameterizing all stages of fuzzing and then\\ndynamically selecting optimal values during fuzzing. Thus the fuzzer can easily\\nadapt to a target program and rapidly increase coverage. We compare our fuzzer\\nto 11 other state-of-the-art grey-box fuzzers on 27 popular benchmarks. Our\\nevaluation shows that SIVO scores the highest both in terms of code coverage\\nand in terms of number of found vulnerabilities.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02394'}, {'title': 'Event Occurrence Model for Power Distribution System Based on Data Eigenvalue Behavior Analytic. (arXiv:2102.02395v1 [eess.SY])', 'description': '<p>This paper describes a model for power distribution network, which is hten\\nutilized for eigenvalue behavior distribution analysis. We utilized the\\ncompensation theory to model the event that occurs in the network and derived\\nthe relation between the system nodal voltage eigenvalues and the occurrence of\\nevents. The paper combines the power system model with the eigenvalue\\ndistribution analysis.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02395'}, {'title': 'Provably End-to-end Label-Noise Learning without Anchor Points. (arXiv:2102.02400v1 [cs.LG])', 'description': '<p>In label-noise learning, the transition matrix plays a key role in building\\nstatistically consistent classifiers. Existing consistent estimators for the\\ntransition matrix have been developed by exploiting anchor points. However, the\\nanchor-point assumption is not always satisfied in real scenarios. In this\\npaper, we propose an end-to-end framework for solving label-noise learning\\nwithout anchor points, in which we simultaneously minimize two objectives: the\\ndiscrepancy between the distribution learned by the neural network and the\\nnoisy class-posterior distribution, and the volume of the simplex formed by the\\ncolumns of the transition matrix. Our proposed framework can identify the\\ntransition matrix if the clean class-posterior probabilities are sufficiently\\nscattered. This is by far the mildest assumption under which the transition\\nmatrix is provably identifiable and the learned classifier is statistically\\nconsistent. Experimental results on benchmark datasets demonstrate the\\neffectiveness and robustness of the proposed method.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02400'}, {'title': 'SAFELearning: Enable Backdoor Detectability In Federated Learning With Secure Aggregation. (arXiv:2102.02402v1 [cs.CR])', 'description': '<p>For model privacy, local model parameters in federated learning shall be\\nobfuscated before sent to the remote aggregator. This technique is referred to\\nas \\\\emph{secure aggregation}. However, secure aggregation makes model poisoning\\nattacks, e.g., to insert backdoors, more convenient given existing anomaly\\ndetection methods mostly require access to plaintext local models. This paper\\nproposes SAFELearning which supports backdoor detection for secure aggregation.\\nWe achieve this through two new primitives - \\\\emph{oblivious random grouping\\n(ORG)} and \\\\emph{partial parameter disclosure (PPD)}. ORG partitions\\nparticipants into one-time random subgroups with group configurations oblivious\\nto participants; PPD allows secure partial disclosure of aggregated subgroup\\nmodels for anomaly detection without leaking individual model privacy.\\nSAFELearning is able to significantly reduce backdoor model accuracy without\\njeopardizing the main task accuracy under common backdoor strategies. Extensive\\nexperiments show SAFELearning reduces backdoor accuracy from $100\\\\%$ to $8.2\\\\%$\\nfor ResNet-18 over CIFAR-10 when $10\\\\%$ participants are malicious.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02402'}, {'title': 'Optimal Co-Designs of Communication and Control in Bandwidth-Constrained Cyber-Physical Systems. (arXiv:2102.02403v1 [math.OC])', 'description': '<p>We address the problem of sparsity-promoting optimal control of\\ncyber-physical systems (CPSs) in the presence of communication delays. The\\ndelays are categorized into two types - namely, an inter-layer delay for\\npassing state and control information between the physical layer and the cyber\\nlayer, and an intra-layer delay that operates between the computing agents,\\nreferred to here as control nodes (CNs), within the cyber-layer. Our objective\\nis to minimize the closed-loop H2-norm of the physical system by co-designing\\nan optimal combination of these two delays and a sparse state-feedback\\ncontroller while respecting a given bandwidth cost constraint. We propose a\\ntwo-loop optimization algorithm for this. Based on the alternating directions\\nmethod of multipliers (ADMM), the inner loop handles the conflicting directions\\nbetween the decreasing H2-norm and the increasing sparsity level of the\\ncontroller. The outer loop comprises a semidefinite program (SDP)-based\\nrelaxation of non-convex inequalities necessary for closed-loop stability.\\nMoreover, for CPSs where the state and control information assigned to the CNs\\nare not private, we derive an additional algorithm that further sparsifies the\\ncommunication topology by modifying the row and column structures of the\\nobtained controller, resulting in reassigning the communication map between the\\ncyber and physical layers, and determining which physical agent should send its\\nstate information to which CN. Proofs for closed-loop stability and optimality\\nare provided for both algorithms, followed by numerical simulations.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02403'}, {'title': 'An efficient optimization based microstructure reconstruction approach with multiple loss functions. (arXiv:2102.02407v1 [cond-mat.mtrl-sci])', 'description': \"<p>Stochastic microstructure reconstruction involves digital generation of\\nmicrostructures that match key statistics and characteristics of a (set of)\\ntarget microstructure(s). This process enables computational analyses on\\nensembles of microstructures without having to perform exhaustive and costly\\nexperimental characterizations. Statistical functions-based and deep\\nlearning-based methods are among the stochastic microstructure reconstruction\\napproaches applicable to a wide range of material systems. In this paper, we\\nintegrate statistical descriptors as well as feature maps from a pre-trained\\ndeep neural network into an overall loss function for an optimization based\\nreconstruction procedure. This helps us to achieve significant computational\\nefficiency in reconstructing microstructures that retain the critically\\nimportant physical properties of the target microstructure. A numerical example\\nfor the microstructure reconstruction of bi-phase random porous ceramic\\nmaterial demonstrates the efficiency of the proposed methodology. We further\\nperform a detailed finite element analysis (FEA) of the reconstructed\\nmicrostructures to calculate effective elastic modulus, effective thermal\\nconductivity and effective hydraulic conductivity, in order to analyse the\\nalgorithm's capacity to capture the variability of these material properties\\nwith respect to those of the target microstructure. This method provides an\\neconomic, efficient and easy-to-use approach for reconstructing random\\nmultiphase materials in 2D which has the potential to be extended to 3D\\nstructures.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02407'}, {'title': 'Variational Inference for Deblending Crowded Starfields. (arXiv:2102.02409v1 [astro-ph.IM])', 'description': '<p>In the image data collected by astronomical surveys, stars and galaxies often\\noverlap. Deblending is the task of distinguishing and characterizing individual\\nlight sources from survey images. We propose StarNet, a fully Bayesian method\\nto deblend sources in astronomical images of crowded star fields. StarNet\\nleverages recent advances in variational inference, including amortized\\nvariational distributions and the wake-sleep algorithm. Wake-sleep, which\\nminimizes forward KL divergence, has significant benefits compared to\\ntraditional variational inference, which minimizes a reverse KL divergence. In\\nour experiments with SDSS images of the M2 globular cluster, StarNet is\\nsubstantially more accurate than two competing methods: Probablistic Cataloging\\n(PCAT), a method that uses MCMC for inference, and a software pipeline employed\\nby SDSS for deblending (DAOPHOT). In addition, StarNet is as much as $100,000$\\ntimes faster than PCAT, exhibiting the scaling characteristics necessary to\\nperform fully Bayesian inference on modern astronomical surveys.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02409'}, {'title': 'A Local Convergence Theory for Mildly Over-Parameterized Two-Layer Neural Network. (arXiv:2102.02410v1 [cs.LG])', 'description': \"<p>While over-parameterization is widely believed to be crucial for the success\\nof optimization for the neural networks, most existing theories on\\nover-parameterization do not fully explain the reason -- they either work in\\nthe Neural Tangent Kernel regime where neurons don't move much, or require an\\nenormous number of neurons. In practice, when the data is generated using a\\nteacher neural network, even mildly over-parameterized neural networks can\\nachieve 0 loss and recover the directions of teacher neurons. In this paper we\\ndevelop a local convergence theory for mildly over-parameterized two-layer\\nneural net. We show that as long as the loss is already lower than a threshold\\n(polynomial in relevant parameters), all student neurons in an\\nover-parameterized two-layer neural network will converge to one of teacher\\nneurons, and the loss will go to 0. Our result holds for any number of student\\nneurons as long as it is at least as large as the number of teacher neurons,\\nand our convergence rate is independent of the number of student neurons. A key\\ncomponent of our analysis is the new characterization of local optimization\\nlandscape -- we show the gradient satisfies a special case of Lojasiewicz\\nproperty which is different from local strong convexity or PL conditions used\\nin previous work.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02410'}, {'title': 'On Single-User Interactive Beam Alignment in Millimeter Wave Systems: Impact of Feedback Delay. (arXiv:2102.02413v1 [cs.IT])', 'description': '<p>Narrow beams are key to wireless communications in millimeter wave frequency\\nbands. Beam alignment (BA) allows the base station (BS) to adjust the direction\\nand width of the beam used for communication. During BA, the BS transmits a\\nnumber of scanning beams covering different angular regions. The goal is to\\nminimize the expected width of the uncertainty region (UR) that includes the\\nangle of departure of the user. Conventionally, in interactive BA, it is\\nassumed that the feedback corresponding to each scanning packet is received\\nprior to transmission of the next one. However, in practice, the feedback delay\\ncould be larger because of propagation or system constraints. This paper\\ninvestigates BA strategies that operate under arbitrary fixed feedback delays.\\nThis problem is analyzed through a source coding prospective where the feedback\\nsequences are viewed as source codewords. It is shown that these codewords form\\na codebook with a particular characteristic which is used to define a new class\\nof codes called d-unimodal codes. By analyzing the properties of these codes, a\\nlower bound on the minimum achievable expected beamwidth is provided. The\\nresults reveal potential performance improvements in terms of the BA duration\\nit takes to achieve a fixed expected width of the UR over the state-of-the-art\\nBA methods which do not consider the effect of delay.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02413'}, {'title': 'Learning Noise Transition Matrix from Only Noisy Labels via Total Variation Regularization. (arXiv:2102.02414v1 [stat.ML])', 'description': '<p>Many weakly supervised classification methods employ a noise transition\\nmatrix to capture the class-conditional label corruption. To estimate the\\ntransition matrix from noisy data, existing methods often need to estimate the\\nnoisy class-posterior, which could be unreliable due to the overconfidence of\\nneural networks. In this work, we propose a theoretically grounded method that\\ncan estimate the noise transition matrix and learn a classifier simultaneously,\\nwithout relying on the error-prone noisy class-posterior estimation.\\nConcretely, inspired by the characteristics of the stochastic label corruption\\nprocess, we propose total variation regularization, which encourages the\\npredicted probabilities to be more distinguishable from each other. Under mild\\nassumptions, the proposed method yields a consistent estimator of the\\ntransition matrix. We show the effectiveness of the proposed method through\\nexperiments on benchmark and real-world datasets.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02414'}, {'title': 'New upper bounds for the forgotten index among bicyclic graphs. (arXiv:2102.02415v1 [math.CO])', 'description': '<p>The forgotten topological index of a graph $G$, denoted by $F(G)$, is defined\\nas the sum of weights $d(u)^{2}+d(v)^{2}$ over all edges $uv$ of $G$ , where\\n$d(u)$ denotes the degree of a vertex $u$. In this paper, we give sharp upper\\nbounds of the F-index (forgotten topological index) over bicyclic graphs, in\\nterms of the order and maximum degree.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02415'}, {'title': 'An end-to-end trainable hybrid classical-quantum classifier. (arXiv:2102.02416v1 [quant-ph])', 'description': '<p>We introduce a hybrid model combining a quantum-inspired tensor network and a\\nvariational quantum circuit to perform supervised learning tasks. This\\narchitecture allows for the classical and quantum parts of the model to be\\ntrained simultaneously, providing an end-to-end training framework. We show\\nthat compared to the principal component analysis, a tensor network based on\\nthe matrix product state with low bond dimensions performs better as a feature\\nextractor for the input data of the variational quantum circuit in the binary\\nand ternary classification of MNIST and Fashion-MNIST datasets. The\\narchitecture is highly adaptable and the classical-quantum boundary can be\\nadjusted according the availability of the quantum resource by exploiting the\\ncorrespondence between tensor networks and quantum circuits.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02416'}, {'title': 'Audio Adversarial Examples: Attacks Using Vocal Masks. (arXiv:2102.02417v1 [cs.SD])', 'description': '<p>We construct audio adversarial examples on automatic Speech-To-Text systems .\\nGiven any audio waveform, we produce an another by overlaying an audio vocal\\nmask generated from the original audio. We apply our audio adversarial attack\\nto five SOTA STT systems: DeepSpeech, Julius, Kaldi, wav2letter@anywhere and\\nCMUSphinx. In addition, we engaged human annotators to transcribe the\\nadversarial audio. Our experiments show that these adversarial examples fool\\nState-Of-The-Art Speech-To-Text systems, yet humans are able to consistently\\npick out the speech. The feasibility of this attack introduces a new domain to\\nstudy machine and human perception of speech.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02417'}, {'title': 'First-Passage Time Statistics on Surfaces of General Shape: Surface PDE Solvers using Generalized Moving Least Squares (GMLS). (arXiv:2102.02421v1 [math.NA])', 'description': \"<p>We develop numerical methods for computing statistics of stochastic processes\\non surfaces of general shape with drift-diffusion dynamics $d{X}_t = a({X}_t)dt\\n+ {b}({X}_t)d{W}_t$. We consider on a surface domain $\\\\Omega$ the statistics\\n$u(\\\\mathbf{x}) = \\\\mathbb{E}^{\\\\mathbf{x}}\\\\left[\\\\int_0^\\\\tau g(X_t)dt \\\\right] +\\n\\\\mathbb{E}^{\\\\mathbf{x}}\\\\left[f(X_\\\\tau)\\\\right]$ with the exit stopping time\\n$\\\\tau = \\\\inf_t \\\\{t &gt; 0 \\\\; |\\\\; X_t \\\\not\\\\in \\\\Omega\\\\}$. Using Dynkin's formula, we\\ncompute statistics by developing high-order Generalized Moving Least Squares\\n(GMLS) solvers for the associated surface PDE boundary-value problems. We focus\\nparticularly on the mean First Passage Times (FPTs) given by the special case\\n$f = 0,\\\\, g = 1$ with $u(\\\\mathbf{x}) =\\n\\\\mathbb{E}^{\\\\mathbf{x}}\\\\left[\\\\tau\\\\right]$. We perform studies for a variety of\\nshapes showing our methods converge with high-order accuracy both in capturing\\nthe geometry and the surface PDE solutions. We then perform studies showing how\\nFPTs are influenced by the surface geometry, drift dynamics, and spatially\\ndependent diffusivities.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02421'}, {'title': 'A Game-Theoretic Approach to Secure Estimation and Control for Cyber-Physical Systems with a Digital Twin. (arXiv:2102.02428v1 [eess.SY])', 'description': '<p>Cyber-Physical Systems (CPSs) play an increasingly significant role in many\\ncritical applications. These valuable applications attract various\\nsophisticated attacks. This paper considers a stealthy estimation attack, which\\naims to modify the state estimation of the CPSs. The intelligent attackers can\\nlearn defense strategies and use clandestine attack strategies to avoid\\ndetection. To address the issue, we design a Chi-square detector in a Digital\\nTwin (DT), which is an online digital model of the physical system. We use a\\nSignaling Game with Evidence (SGE) to find the optimal attack and defense\\nstrategies. Our analytical results show that the proposed defense strategies\\ncan mitigate the impact of the attack on the physical estimation and guarantee\\nthe stability of the CPSs. Finally, we use an illustrative application to\\nevaluate the performance of the proposed framework.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02428'}, {'title': 'Reconfigurable-intelligent-surface-assisted Downlink Transmission Design via Bayesian Optimization. (arXiv:2102.02430v1 [cs.IT])', 'description': '<p>This paper investigates the transmission design in the\\nreconfigurable-intelligent-surface (RIS)-assisted downlink system. The channel\\nstate information (CSI) is usually difficult to be estimated at the base\\nstation (BS) when the RIS is not equipped with radio frequency chains. In this\\npaper, we propose a downlink transmission framework with unknown CSI via\\nBayesian optimization. Since the CSI is not available at the BS, we treat the\\nunknown objective function as the black-box function and take the beamformer,\\nthe phase shift, and the receiving filter as the input. Then the objective\\nfunction is decomposed as the sum of low-dimension subfunctions to reduce the\\ncomplexity. By re-expressing the power constraint of the BS in spherical\\ncoordinates, the original constraint problem is converted into an equivalent\\nunconstrained problem. The users estimate the sum MSE of the training symbols\\nas the objective value and feed it back to the BS. We assume a Gaussian prior\\nof the feedback samples and the next query point is updated by minimizing the\\nconstructed acquisition function. Furthermore, this framework can also be\\napplied to the power transfer system and fairness problems. Simulation results\\nvalidate the effectiveness of the proposed transmission scheme in the downlink\\ndata transmission and power transfer.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02430'}, {'title': 'Graph Coding for Model Selection and Anomaly Detection in Gaussian Graphical Models. (arXiv:2102.02431v1 [cs.LG])', 'description': '<p>A classic application of description length is for model selection with the\\nminimum description length (MDL) principle. The focus of this paper is to\\nextend description length for data analysis beyond simple model selection and\\nsequences of scalars. More specifically, we extend the description length for\\ndata analysis in Gaussian graphical models. These are powerful tools to model\\ninteractions among variables in a sequence of i.i.d Gaussian data in the form\\nof a graph. Our method uses universal graph coding methods to accurately\\naccount for model complexity, and therefore provide a more rigorous approach\\nfor graph model selection. The developed method is tested with synthetic and\\nelectrocardiogram (ECG) data to find the graph model and anomaly in Gaussian\\ngraphical models. The experiments show that our method gives better performance\\ncompared to commonly used methods.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02431'}, {'title': 'The use of a time-fractional transport model for performing computational homogenisation of 2D heterogeneous media exhibiting memory effects. (arXiv:2102.02432v1 [math.NA])', 'description': '<p>In this work, a two-dimensional time-fractional subdiffusion model is\\ndeveloped to investigate the underlying transport phenomena evolving in a\\nbinary medium comprised of two sub-domains occupied by homogeneous material. We\\nutilise an unstructured mesh control volume method to validate the model\\nagainst a derived semi-analytical solution for a class of two-layered problems.\\nThis generalised transport model is then used to perform computational\\nhomogenisation on various two-dimensional heterogenous porous media. A key\\ncontribution of our work is to extend the classical homogenisation theory to\\naccommodate the new framework and show that the effective diffusivity tensor\\ncan be computed once the cell problems reach steady state at the microscopic\\nscale. We verify the theory for binary media via a series of well-known test\\nproblems and then investigate media having inclusions that exhibit a molecular\\nrelaxation (memory) effect. Finally, we apply the generalised transport model\\nto estimate the bound water diffusivity tensor on cellular structures obtained\\nfrom environmental scanning electron microscope (ESEM) images for Spruce wood\\nand Australian hardwood. A highlight of our work is that the computed\\ndiffusivity for the heterogeneous media with molecular relaxation is quite\\ndifferent from the classical diffusion cases, being dominated at steady-state\\nby the material with memory effects.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02432'}, {'title': 'Assessing Individual and Community Vulnerability to Fake News in Social Networks. (arXiv:2102.02434v1 [cs.SI])', 'description': '<p>The plague of false information, popularly called fake news has affected\\nlives of news consumers ever since the prevalence of social media. Thus\\nunderstanding the spread of false information in social networks has gained a\\nlot of attention in the literature. While most proposed models do content\\nanalysis of the information, no much work has been done by exploring the\\ncommunity structures that also play an important role in determining how people\\nget exposed to it. In this paper we base our idea on Computational Trust in\\nsocial networks to propose a novel Community Health Assessment model against\\nfake news. Based on the concepts of neighbor, boundary and core nodes of a\\ncommunity, we propose novel evaluation metrics to quantify the vulnerability of\\nnodes (individual-level) and communities (group-level) to spreading false\\ninformation. Our model hypothesizes that if the boundary nodes trust the\\nneighbor nodes of a community who are spreaders, the densely-connected core\\nnodes of the community are highly likely to become spreaders. We test our model\\nwith communities generated using three popular community detection algorithms\\nbased on two new datasets of information spreading networks collected from\\nTwitter. Our experimental results show that the proposed metrics perform\\nclearly better on the networks spreading false information than on those\\nspreading true ones, indicating our community health assessment model is\\neffective.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02434'}, {'title': 'Converse, Focus and Guess -- Towards Multi-Document Driven Dialogue. (arXiv:2102.02435v1 [cs.CL])', 'description': \"<p>We propose a novel task, Multi-Document Driven Dialogue (MD3), in which an\\nagent can guess the target document that the user is interested in by leading a\\ndialogue. To benchmark progress, we introduce a new dataset of GuessMovie,\\nwhich contains 16,881 documents, each describing a movie, and associated 13,434\\ndialogues. Further, we propose the MD3 model. Keeping guessing the target\\ndocument in mind, it converses with the user conditioned on both document\\nengagement and user feedback. In order to incorporate large-scale external\\ndocuments into the dialogue, it pretrains a document representation which is\\nsensitive to attributes it talks about an object. Then it tracks dialogue state\\nby detecting evolvement of document belief and attribute belief, and finally\\noptimizes dialogue policy in principle of entropy decreasing and reward\\nincreasing, which is expected to successfully guess the user's target in a\\nminimum number of turns. Experiments show that our method significantly\\noutperforms several strong baseline methods and is very close to human's\\nperformance.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02435'}, {'title': 'Lower Bound on the Optimal Access Bandwidth of ($K+2,K,2$)-MDS Array Code with Degraded Read Friendly. (arXiv:2102.02436v1 [cs.IT])', 'description': '<p>Accessing the data in the failed disk (degraded read) with low latency is\\ncrucial for an erasure-coded storage system. In this work, the maximum distance\\nseparable (MDS) array code with the property of degraded-read friendly (DRF) is\\ndiscussed. For the DRF MDS array code with 2 redundant nodes and the\\nsub-packetization level of 2, the lower bound of its access bandwidth is\\nderived.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02436'}, {'title': 'EUCA: A Practical Prototyping Framework towards End-User-Centered Explainable Artificial Intelligence. (arXiv:2102.02437v1 [cs.HC])', 'description': '<p>The ability to explain decisions to its end-users is a necessity to deploy AI\\nas critical decision support. Yet making AI explainable to end-users is a\\nrelatively ignored and challenging problem. To bridge the gap, we first\\nidentified twelve end-user-friendly explanatory forms that do not require\\ntechnical knowledge to comprehend, including feature-, example-, and rule-based\\nexplanations. We then instantiated the explanatory forms as prototyping cards\\nin four AI-assisted critical decision-making tasks, and conducted a user study\\nto co-design low-fidelity prototypes with 32 layperson participants. The\\nresults verified the relevance of using the explanatory forms as building\\nblocks of explanations, and identified their proprieties (pros, cons,\\napplicable explainability needs, and design implications). The explanatory\\nforms, their proprieties, and prototyping support constitute the\\nEnd-User-Centered explainable AI framework EUCA. It serves as a practical\\nprototyping toolkit for HCI/AI practitioners and researchers to build\\nend-user-centered explainable AI.\\n</p>\\n<p>The EUCA framework is available at <a href=\"http://weina.me/end-user-xai\">this http URL</a>\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02437'}, {'title': 'Towards Decentralized Human-Swarm Interaction by Means of Sequential Hand Gesture Recognition. (arXiv:2102.02439v1 [cs.RO])', 'description': '<p>In this work, we present preliminary work on a novel method for Human-Swarm\\nInteraction (HSI) that can be used to change the macroscopic behavior of a\\nswarm of robots with decentralized sensing and control. By integrating a small\\nyet capable hand gesture recognition convolutional neural network (CNN) with\\nthe next-generation Robot Operating System \\\\emph{ros2}, which enables\\ndecentralized implementation of robot software for multi-robot applications, we\\ndemonstrate the feasibility of programming a swarm of robots to recognize and\\nrespond to a sequence of hand gestures that capable of correspond to different\\ntypes of swarm behaviors. We test our approach using a sequence of gestures\\nthat modifies the target inter-robot distance in a group of three Turtlebot3\\nBurger robots in order to prevent robot collisions with obstacles. The approach\\nis validated in three different Gazebo simulation environments and in a\\nphysical testbed that reproduces one of the simulated environments.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02439'}, {'title': 'Online Sketch-based Query Optimization. (arXiv:2102.02440v1 [cs.DB])', 'description': '<p>Cost-based query optimization remains a critical task in relational databases\\neven after decades of research and industrial development. Query optimizers\\nrely on a large range of statistical synopses -- including attribute-level\\nhistograms and table-level samples -- for accurate cardinality estimation. As\\nthe complexity of selection predicates and the number of join predicates\\nincrease, two problems arise. First, statistics cannot be incrementally\\ncomposed to effectively estimate the cost of the sub-plans generated in plan\\nenumeration. Second, small errors are propagated exponentially through join\\noperators, which can lead to severely sub-optimal plans. In this paper, we\\nintroduce COMPASS, a novel query optimization paradigm for in-memory databases\\nbased on a single type of statistics -- Fast-AGMS sketches. In COMPASS, query\\noptimization and execution are intertwined. Selection predicates and sketch\\nupdates are pushed-down and evaluated online during query optimization. This\\nallows Fast-AGMS sketches to be computed only over the relevant tuples -- which\\nenhances cardinality estimation accuracy. Plan enumeration is performed over\\nthe query join graph by incrementally composing attribute-level sketches -- not\\nby building a separate sketch for every sub-plan. We prototype COMPASS in MapD\\n-- an open-source parallel database -- and perform extensive experiments over\\nthe complete JOB benchmark. The results prove that COMPASS generates better\\nexecution plans -- both in terms of cardinality and runtime -- compared to four\\nother database systems. Overall, COMPASS achieves a speedup ranging from 1.35X\\nto 11.28X in cumulative query execution time over the considered competitors.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02440'}, {'title': 'Persistent Rule-based Interactive Reinforcement Learning. (arXiv:2102.02441v1 [cs.AI])', 'description': '<p>Interactive reinforcement learning has allowed speeding up the learning\\nprocess in autonomous agents by including a human trainer providing extra\\ninformation to the agent in real-time. Current interactive reinforcement\\nlearning research has been limited to interactions that offer relevant advice\\nto the current state only. Additionally, the information provided by each\\ninteraction is not retained and instead discarded by the agent after a\\nsingle-use. In this work, we propose a persistent rule-based interactive\\nreinforcement learning approach, i.e., a method for retaining and reusing\\nprovided knowledge, allowing trainers to give general advice relevant to more\\nthan just the current state. Our experimental results show persistent advice\\nsubstantially improves the performance of the agent while reducing the number\\nof interactions required for the trainer. Moreover, rule-based advice shows\\nsimilar performance impact as state-based advice, but with a substantially\\nreduced interaction count.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02441'}, {'title': 'The Analysis from Nonlinear Distance Metric to Kernel-based Drug Prescription Prediction System. (arXiv:2102.02446v1 [cs.LG])', 'description': '<p>Distance metrics and their nonlinear variant play a crucial role in machine\\nlearning based real-world problem solving. We demonstrated how Euclidean and\\ncosine distance measures differ not only theoretically but also in real-world\\nmedical application, namely, outcome prediction of drug prescription. Euclidean\\ndistance exhibits favorable properties in the local geometry problem. To this\\nregard, Euclidean distance can be applied under short-term disease with\\nlow-variation outcome observation. Moreover, when presenting to highly variant\\nchronic disease, it is preferable to use cosine distance. These different\\ngeometric properties lead to different submanifolds in the original embedded\\nspace, and hence, to different optimizing nonlinear kernel embedding\\nframeworks. We first established the geometric properties that we needed in\\nthese frameworks. From these properties interpreted their differences in\\ncertain perspectives. Our evaluation on real-world, large-scale electronic\\nhealth records and embedding space visualization empirically validated our\\napproach.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02446'}, {'title': 'Safety during Transient Response in Direct Current Microgrids using Control Barrier Functions. (arXiv:2102.02448v1 [eess.SY])', 'description': '<p>We consider the problem of guaranteeing that the transient voltages and\\ncurrents stay within prescribed bounds in Direct Current (DC) microgrids, when\\nthe controller does not have access to accurate system dynamics due to the load\\nbeing unknown and/or time-varying. To achieve this, we propose an optimization\\nbased controller design using control barrier functions. We show that the\\nproposed controller has a decentralized structure and is robust with respect to\\nthe uncertainty in the precise values of the system parameters, such as the\\nload.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02448'}, {'title': 'Hybrid Adversarial Inverse Reinforcement Learning. (arXiv:2102.02454v1 [cs.LG])', 'description': '<p>In this paper, we investigate the problem of the inverse reinforcement\\nlearning (IRL), especially the beyond-demonstrator (BD) IRL. The BD-IRL aims to\\nnot only imitate the expert policy but also extrapolate BD policy based on\\nfinite demonstrations of the expert. Currently, most of the BD-IRL algorithms\\nare two-stage, which first infer a reward function then learn the policy via\\nreinforcement learning (RL). Because of the two separate procedures, the\\ntwo-stage algorithms have high computation complexity and lack robustness. To\\novercome these flaw, we propose a BD-IRL framework entitled hybrid adversarial\\ninverse reinforcement learning (HAIRL), which successfully integrates the\\nimitation and exploration into one procedure. The simulation results show that\\nthe HAIRL is more efficient and robust when compared with other similar\\nstate-of-the-art (SOTA) algorithms.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02454'}, {'title': 'Privacy Preserving and Resilient RPKI. (arXiv:2102.02456v1 [cs.CR])', 'description': '<p>Resource Public Key Infrastructure (RPKI) is vital to the security of\\ninter-domain routing. However, RPKI enables Regional Internet Registries (RIRs)\\nto unilaterally takedown IP prefixes - indeed, such attacks have been launched\\nby nation-state adversaries. The threat of IP prefix takedowns is one of the\\nfactors hindering RPKI adoption.\\n</p>\\n<p>In this work, we propose the first distributed RPKI system, based on\\nthreshold signatures, that requires the coordination of a number of RIRs to\\nmake changes to RPKI objects; hence, preventing unilateral prefix takedown. We\\nperform extensive evaluations using our implementation demonstrating the\\npracticality of our solution. Furthermore, we show that our system is scalable\\nand remains efficient even when RPKI is widely deployed.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02456'}, {'title': 'Deep Face Fuzzy Vault: Implementation and Performance. (arXiv:2102.02458v1 [cs.CV])', 'description': '<p>Deep convolutional neural networks have achieved remarkable improvements in\\nfacial recognition performance. Similar kinds of developments, e.g.\\ndeconvolutional neural networks, have shown impressive results for\\nreconstructing face images from their corresponding embeddings in the latent\\nspace. This poses a severe security risk which necessitates the protection of\\nstored deep face embeddings in order to prevent from misuse, e.g. identity\\nfraud.\\n</p>\\n<p>In this work, an unlinkable improved deep face fuzzy vault-based template\\nprotection scheme is presented. To this end, a feature transformation method is\\nintroduced which maps fixed-length real-valued deep face embeddings to\\ninteger-valued feature sets. As part of said feature transformation, a detailed\\nanalysis of different feature quantisation and binarisation techniques is\\nconducted using features extracted with a state-of-the-art deep convolutional\\nneural network trained with the additive angular margin loss (ArcFace). At key\\nbinding, obtained feature sets are locked in an unlinkable improved fuzzy\\nvault. For key retrieval, the efficiency of different polynomial reconstruction\\ntechniques is investigated. The proposed feature transformation method and\\ntemplate protection scheme are agnostic of the biometric characteristic and,\\nthus, can be applied to virtually any biometric features computed by a deep\\nneural network.\\n</p>\\n<p>For the best configuration, a false non-match rate below 1% at a false match\\nrate of 0.01%, is achieved in cross-database experiments on the FERET and\\nFRGCv2 face databases. On average, a security level of up to approximately 28\\nbits is obtained. This work presents the first effective face-based fuzzy vault\\nscheme providing privacy protection of facial reference data as well as digital\\nkey derivation from face.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02458'}, {'title': 'DIFFnet: Diffusion parameter mapping network generalized for input diffusion gradient schemes and bvalues. (arXiv:2102.02463v1 [eess.IV])', 'description': '<p>In MRI, deep neural networks have been proposed to reconstruct diffusion\\nmodel parameters. However, the inputs of the networks were designed for a\\nspecific diffusion gradient scheme (i.e., diffusion gradient directions and\\nnumbers) and a specific b-value that are the same as the training data. In this\\nstudy, a new deep neural network, referred to as DIFFnet, is developed to\\nfunction as a generalized reconstruction tool of the diffusion-weighted signals\\nfor various gradient schemes and b-values. For generalization, diffusion\\nsignals are normalized in a q-space and then projected and quantized, producing\\na matrix (Qmatrix) as an input for the network. To demonstrate the validity of\\nthis approach, DIFFnet is evaluated for diffusion tensor imaging (DIFFnetDTI)\\nand for neurite orientation dispersion and density imaging (DIFFnetNODDI). In\\neach model, two datasets with different gradient schemes and b-values are\\ntested. The results demonstrate accurate reconstruction of the diffusion\\nparameters at substantially reduced processing time (approximately 8.7 times\\nand 2240 times faster processing time than conventional methods in DTI and\\nNODDI, respectively; less than 4% mean normalized root-mean-square errors\\n(NRMSE) in DTI and less than 8% in NODDI). The generalization capability of the\\nnetworks was further validated using reduced numbers of diffusion signals from\\nthe datasets. Different from previously proposed deep neural networks, DIFFnet\\ndoes not require any specific gradient scheme and b-value for its input. As a\\nresult, it can be adopted as an online reconstruction tool for various complex\\ndiffusion imaging.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02463'}, {'title': 'App Developer Centric Trusted Execution Environment. (arXiv:2102.02465v1 [cs.CR])', 'description': \"<p>ARM TrustZone is the de-facto hardware TEE implementation on mobile devices\\nlike smartphones. As a vendor-centric TEE, TrustZone greatly overlooks the\\nstrong protection demands and requirements from the App developers. Several\\nsecurity solutions have been proposed to enable the TEE-assisted isolation in\\nthe Normal World of ARM, attempting to balance the security and usability.\\nHowever, they are still not full-fledged in serving Apps' needs. In this paper,\\nwe introduce LEAP, which is a lightweight App developer Centric TEE solution in\\nthe Normal World. LEAP offers the auto DevOps tool to help developers to\\nprepare the codes running on it, enables isolated codes to execute in parallel\\nand access peripheral (e.g. mobile GPUs) with ease, and dynamically manage\\nsystem resources upon Apps' requests. We implement the LEAP prototype on the\\noff-the-shelf ARM platform without any hardware change. We perform the\\ncomprehensive analyses and experiments to demonstrate that LEAP is efficient in\\ndesign, comprehensive in support, and convenient in adoption.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02465'}, {'title': 'Cumulant Expansion of Mutual Information for Quantifying Leakage of a Protected Secret. (arXiv:2102.02468v1 [cs.IT])', 'description': '<p>The information leakage of a cryptographic implementation with a given degree\\nof protection is evaluated in a typical situation when the signal-to-noise\\nratio is small. This is solved by expanding Kullback-Leibler divergence,\\nentropy, and mutual information in terms of moments/cumulants.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02468'}, {'title': 'Machine Learning-Based Generalized Model for Finite Element Analysis of Roll Deflection During the Austenitic Stainless Steel 316L Strip Rolling. (arXiv:2102.02470v1 [cs.LG])', 'description': '<p>During the strip rolling process, a considerable amount of the forces of the\\nmaterial pressure cause elastic deformation on the work-roll, i.e., the\\ndeflection process. The uncontrollable amount of the work-roll deflection leads\\nto the high deviations in the permissible thickness of the plate along its\\nwidth. In the context of the Austenitic Stainless Steels (ASS), due to the\\ninstability of the Austenite phase in a cold temperature, cold deformation\\nleads to the production of Strain-Induced Martensite (SIM), which improves the\\nmechanical properties. It leads to the hardening of the ASS 316L during the\\ncold deformation, which causes the Strain-Stress curve of the ASS 316L to\\nbehave non-linearly, which distinguishes it from other categories of steels. To\\naccount for this phenomenon, we propose to utilize a Machine Learning (ML)\\nmethod to predict more accurately the flow stress of the ASS 316L during the\\ncold rolling. Furthermore, we conduct various mechanical tensile tests in order\\nto obtain the required dataset, Stress316L, for training the neural network.\\nMoreover, instead of using a constant value of flow stress during the\\nmulti-pass rolling process, we use a Finite Difference (FD) formulation of the\\nequilibrium equation in order to account for the dynamic behavior of the flow\\nstress, which leads to the estimation of the mean pressure, which the strip\\nenforces to the rolls during deformation. Finally, using the Finite Element\\nAnalysis (FEA), the deflection of the work-roll tools will be calculated. As a\\nresult, we end up with a generalized model for the calculation of the roll\\ndeflection, specific to the ASS 316L. To the best of our knowledge, this is the\\nfirst model for ASS 316L which considers dynamic flow stress and SIM of the\\nrolled plate, using FEM and an ML approach, which could contribute to the\\nbetter design of the tolls.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02470'}, {'title': 'Transfer Learning in Bandits with Latent Continuity. (arXiv:2102.02472v1 [cs.LG])', 'description': '<p>Structured stochastic multi-armed bandits provide accelerated regret rates\\nover the standard unstructured bandit problems. Most structured bandits,\\nhowever, assume the knowledge of the structural parameter such as Lipschitz\\ncontinuity, which is often not available. To cope with the latent structural\\nparameter, we consider a transfer learning setting in which an agent must learn\\nto transfer the structural information from the prior tasks to the next task,\\nwhich is inspired by practical problems such as rate adaptation in wireless\\nlink. We propose a novel framework to provably and accurately estimate the\\nLipschitz constant based on previous tasks and fully exploit it for the new\\ntask at hand. We analyze the efficiency of the proposed framework in two folds:\\n(i) the sample complexity of our estimator matches with the\\ninformation-theoretic fundamental limit; and (ii) our regret bound on the new\\ntask is close to that of the oracle algorithm with the full knowledge of the\\nLipschitz constant under mild assumptions. Our analysis reveals a set of useful\\ninsights on transfer learning for latent Lipschitzconstants such as the\\nfundamental challenge a learner faces. Our numerical evaluations confirm our\\ntheoretical findings and show the superiority of the proposed framework\\ncompared to baselines.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02472'}, {'title': 'Error analysis of some nonlocal diffusion discretization schemes. (arXiv:2102.02476v1 [math.NA])', 'description': '<p>We study two numerical approximations of solutions of nonlocal diffusion\\nevolution problems which are inspired in algorithms for computing the bilateral\\ndenoising filtering of an image, and which are based on functional\\nrearrangements and on the Fourier transform. Apart from the usual time-space\\ndiscretization, these algorithms also use the discretization of the range of\\nthe solution (quantization). We show that the discrete approximations converge\\nto the continuous solution in suitable functional spaces, and provide error\\nestimates. Finally, we present some numerical experiments illustrating the\\nperformance of the algorithms, specially focusing in the execution time.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02476'}, {'title': 'Bangla Text Dataset and Exploratory Analysis for Online Harassment Detection. (arXiv:2102.02478v1 [cs.CL])', 'description': '<p>Being the seventh most spoken language in the world, the use of the Bangla\\nlanguage online has increased in recent times. Hence, it has become very\\nimportant to analyze Bangla text data to maintain a safe and harassment-free\\nonline place. The data that has been made accessible in this article has been\\ngathered and marked from the comments of people in public posts by celebrities,\\ngovernment officials, athletes on Facebook. The total amount of collected\\ncomments is 44001. The dataset is compiled with the aim of developing the\\nability of machines to differentiate whether a comment is a bully expression or\\nnot with the help of Natural Language Processing and to what extent it is\\nimproper if it is an inappropriate comment. The comments are labeled with\\ndifferent categories of harassment. Exploratory analysis from different\\nperspectives is also included in this paper to have a detailed overview. Due to\\nthe scarcity of data collection of categorized Bengali language comments, this\\ndataset can have a significant role for research in detecting bully words,\\nidentifying inappropriate comments, detecting different categories of Bengali\\nbullies, etc. The dataset is publicly available at\\nhttps://data.mendeley.com/datasets/9xjx8twk8p.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02478'}, {'title': 'Kernelization of Maximum Minimal Vertex Cover. (arXiv:2102.02484v1 [cs.DS])', 'description': '<p>In the Maximum Minimal Vertex Cover (MMVC) problem, we are given a graph $G$\\nand a positive integer $k$, and the objective is to decide whether $G$ contains\\na minimal vertex cover of size at least $k$. This problem has been considered\\nin several articles in the last years. We focus on its kernelization, which had\\nbeen almost unexplored so far. We prove that MMVC does not admit polynomial\\nkernels parameterized by the size of a minimum vertex cover, even on bipartite\\ngraphs, unless ${\\\\sf NP} \\\\subseteq {\\\\sf coNP} / {\\\\sf poly}$. Motivated by a\\nquestion of Boria et al. [Discret. Appl. Math. 2015] about the existence of\\nsubquadratic kernels for MMVC parameterized by $k$, we rule out their existence\\nunless $P=NP$, if we restrict the kernelization algorithms to apply only a type\\nof natural reduction rules that we call \"large optimal preserving rules\". In\\nparticular, these rules contain the typical reduction rules to obtain linear\\nkernels for Vertex Cover. On the positive side, we provide subquadratic kernels\\non $H$-free graphs for several graphs $H$, such as the bull, the paw, or the\\ncomplete graphs, by making use of the Erd\\\\H{o}s-Hajnal property in order to\\nfind an appropriate decomposition.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02484'}, {'title': 'Image Restoration by Deep Projected GSURE. (arXiv:2102.02485v1 [cs.CV])', 'description': '<p>Ill-posed inverse problems appear in many image processing applications, such\\nas deblurring and super-resolution. In recent years, solutions that are based\\non deep Convolutional Neural Networks (CNNs) have shown great promise. Yet,\\nmost of these techniques, which train CNNs using external data, are restricted\\nto the observation models that have been used in the training phase. A recent\\nalternative that does not have this drawback relies on learning the target\\nimage using internal learning. One such prominent example is the Deep Image\\nPrior (DIP) technique that trains a network directly on the input image with a\\nleast-squares loss. In this paper, we propose a new image restoration framework\\nthat is based on minimizing a loss function that includes a \"projected-version\"\\nof the Generalized SteinUnbiased Risk Estimator (GSURE) and parameterization of\\nthe latent image by a CNN. We demonstrate two ways to use our framework. In the\\nfirst one, where no explicit prior is used, we show that the proposed approach\\noutperforms other internal learning methods, such as DIP. In the second one, we\\nshow that our GSURE-based loss leads to improved performance when used within a\\nplug-and-play priors scheme.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02485'}, {'title': 'From a Point Cloud to a Simulation Model: Bayesian Segmentation and Entropy based Uncertainty Estimation for 3D Modelling. (arXiv:2102.02488v1 [stat.ML])', 'description': '<p>The 3D modelling of indoor environments and the generation of process\\nsimulations play an important role in factory and assembly planning. In\\nbrownfield planning cases existing data are often outdated and incomplete\\nespecially for older plants, which were mostly planned in 2D. Thus, current\\nenvironment models cannot be generated directly on the basis of existing data\\nand a holistic approach on how to build such a factory model in a highly\\nautomated fashion is mostly non-existent. Major steps in generating an\\nenvironment model in a production plant include data collection and\\npre-processing, object identification as well as pose estimation. In this work,\\nwe elaborate a methodical workflow, which starts with the digitalization of\\nlarge-scale indoor environments and ends with the generation of a static\\nenvironment or simulation model. The object identification step is realized\\nusing a Bayesian neural network capable of point cloud segmentation. We\\nelaborate how the information on network uncertainty generated by a Bayesian\\nsegmentation framework can be used in order to build up a more accurate\\nenvironment model. The steps of data collection and point cloud segmentation as\\nwell as the resulting model accuracy are evaluated on a real-world data set\\ncollected at the assembly line of a large-scale automotive production plant.\\nThe segmentation network is further evaluated on the publicly available\\nStanford Large-Scale 3D Indoor Spaces data set. The Bayesian segmentation\\nnetwork clearly surpasses the performance of the frequentist baseline and\\nallows us to increase the accuracy of the model placement in a simulation scene\\nconsiderably.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02488'}, {'title': 'Boundary Stabilization and Observation of an Unstable Heat Equation in a General Multi-dimensional Domain. (arXiv:2102.02492v1 [eess.SY])', 'description': '<p>In this paper, we consider the exponential stabilization and observation of\\nan unstable heat equation in a general multi-dimensional domain by combining\\nthe finite-dimensional spectral truncation technique and the recently developed\\ndynamics compensation approach. In contrast to the unstable one-dimensional\\npartial differential equation (PDE), such as the transport equation, wave\\nequation and the heat equation, that can be treated by the well-known PDE\\nbackstepping method, stabilization of unstable PDE in a general\\nmulti-dimensional domain is still a challenging problem. We treat the\\nstabilization and observation problems separately. A dynamical state feedback\\nlaw is proposed firstly to stabilize the unstable heat equation exponentially\\nand then a state observer is designed via a boundary measurement. Both the\\nstability of the closed-loop system and the well-posedness of the observer are\\nproved. Some of the theoretical results are validated by the numerical\\nsimulations.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02492'}, {'title': 'Keep it Simple: Data-efficient Learning for Controlling Complex Systems with Simple Models. (arXiv:2102.02493v1 [cs.RO])', 'description': '<p>When manipulating a novel object with complex dynamics, a state\\nrepresentation is not always available, for example for deformable objects.\\nLearning both a representation and dynamics from observations requires large\\namounts of data. We propose Learned Visual Similarity Predictive Control\\n(LVSPC), a novel method for data-efficient learning to control systems with\\ncomplex dynamics and high-dimensional state spaces from images. LVSPC leverages\\na given simple model approximation from which image observations can be\\ngenerated. We use these images to train a perception model that estimates the\\nsimple model state from observations of the complex system online. We then use\\ndata from the complex system to fit the parameters of the simple model and\\nlearn where this model is inaccurate, also online. Finally, we use Model\\nPredictive Control and bias the controller away from regions where the simple\\nmodel is inaccurate and thus where the controller is less reliable. We evaluate\\nLVSPC on two tasks; manipulating a tethered mass and a rope. We find that our\\nmethod performs comparably to state-of-the-art reinforcement learning methods\\nwith an order of magnitude less data. LVSPC also completes the rope\\nmanipulation task on a real robot with 80% success rate after only 10 trials,\\ndespite using a perception system trained only on images from simulation.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02493'}, {'title': 'Permutation-invariant quantum coding for quantum deletion channels. (arXiv:2102.02494v1 [quant-ph])', 'description': '<p>Quantum deletions, which are harder to correct than erasure errors, occur in\\nmany realistic settings. It is therefore pertinent to develop quantum coding\\nschemes for quantum deletion channels. To date, not much is known about which\\nexplicit quantum error correction codes can combat quantum deletions. We note\\nthat {\\\\em any} permutation-invariant quantum code that has a distance of $t+1$\\ncan correct $t$ quantum deletions for any positive integer $t$ in both the\\nqubit and the qudit setting. Leveraging on coding properties of\\npermutation-invariant quantum codes under erasure errors, we derive\\ncorresponding coding bounds for permutation-invariant quantum codes under\\nquantum deletions. We focus our attention on a specific family of $N$-qubit\\npermutation-invariant quantum codes, which we call shifted gnu codes, and show\\nthat their encoding and decoding algorithms can be performed in $O(N)$ and\\n$O(N^2)$.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02494'}, {'title': '3D Surface Reconstruction From Multi-Date Satellite Images. (arXiv:2102.02502v1 [cs.CV])', 'description': '<p>The reconstruction of accurate three-dimensional environment models is one of\\nthe most fundamental goals in the field of photogrammetry. Since satellite\\nimages provide suitable properties for obtaining large-scale environment\\nreconstructions, there exist a variety of Stereo Matching based methods to\\nreconstruct point clouds for satellite image pairs. Recently, the first\\nStructure from Motion (SfM) based approach has been proposed, which allows to\\nreconstruct point clouds from multiple satellite images. In this work, we\\npropose an extension of this SfM based pipeline that allows us to reconstruct\\nnot only point clouds but watertight meshes including texture information. We\\nprovide a detailed description of several steps that are mandatory to exploit\\nstate-of-the-art mesh reconstruction algorithms in the context of satellite\\nimagery. This includes a decomposition of finite projective camera calibration\\nmatrices, a skew correction of corresponding depth maps and input images as\\nwell as the recovery of real-world depth maps from reparameterized depth\\nvalues. The paper presents an extensive quantitative evaluation on multi-date\\nsatellite images demonstrating that the proposed pipeline combined with current\\nmeshing algorithms outperforms state-of-the-art point cloud reconstruction\\nalgorithms in terms of completeness and median error. We make the source code\\nof our pipeline publicly available.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02502'}, {'title': 'Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models. (arXiv:2102.02503v1 [cs.CL])', 'description': '<p>On October 14th, 2020, researchers from OpenAI, the Stanford Institute for\\nHuman-Centered Artificial Intelligence, and other universities convened to\\ndiscuss open research questions surrounding GPT-3, the largest\\npublicly-disclosed dense language model at the time. The meeting took place\\nunder Chatham House Rules. Discussants came from a variety of research\\nbackgrounds including computer science, linguistics, philosophy, political\\nscience, communications, cyber policy, and more. Broadly, the discussion\\ncentered around two main questions: 1) What are the technical capabilities and\\nlimitations of large language models? 2) What are the societal effects of\\nwidespread use of large language models? Here, we provide a detailed summary of\\nthe discussion organized by the two themes above.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02503'}, {'title': 'Meta-strategy for Learning Tuning Parameters with Guarantees. (arXiv:2102.02504v1 [stat.ML])', 'description': '<p>Online gradient methods, like the online gradient algorithm (OGA), often\\ndepend on tuning parameters that are difficult to set in practice. We consider\\nan online meta-learning scenario, and we propose a meta-strategy to learn these\\nparameters from past tasks. Our strategy is based on the minimization of a\\nregret bound. It allows to learn the initialization and the step size in OGA\\nwith guarantees. We provide a regret analysis of the strategy in the case of\\nconvex losses. It suggests that, when there are parameters\\n$\\\\theta_1,\\\\dots,\\\\theta_T$ solving well tasks $1,\\\\dots,T$ respectively and that\\nare close enough one to each other, our strategy indeed improves on learning\\neach task in isolation.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02504'}, {'title': 'Gapped Indexing for Consecutive Occurrences. (arXiv:2102.02505v1 [cs.DS])', 'description': '<p>The classic string indexing problem is to preprocess a string S into a\\ncompact data structure that supports efficient pattern matching queries.\\nTypical queries include existential queries (decide if the pattern occurs in\\nS), reporting queries (return all positions where the pattern occurs), and\\ncounting queries (return the number of occurrences of the pattern). In this\\npaper we consider a variant of string indexing, where the goal is to compactly\\nrepresent the string such that given two patterns P1 and P2 and a gap range\\n[\\\\alpha,\\\\beta] we can quickly find the consecutive occurrences of P1 and P2\\nwith distance in [\\\\alpha,\\\\beta], i.e., pairs of occurrences immediately\\nfollowing each other and with distance within the range. We present data\\nstructures that use \\\\~O(n) space and query time \\\\~O(|P1|+|P2|+n^(2/3)) for\\nexistence and counting and \\\\~O(|P1|+|P2|+n^(2/3)*occ^(1/3)) for reporting. We\\ncomplement this with a conditional lower bound based on the set intersection\\nproblem showing that any solution using \\\\~O(n) space must use\\n\\\\tilde{\\\\Omega}}(|P1|+|P2|+\\\\sqrt{n}) query time. To obtain our results we\\ndevelop new techniques and ideas of independent interest including a new suffix\\ntree decomposition and hardness of a variant of the set intersection problem.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02505'}, {'title': 'Aitken-Schwarz heterogeneous Domain Decomposition for EMT-TS Simulation. (arXiv:2102.02507v1 [math.NA])', 'description': \"<p>In this paper, a Schwarz heterogeneous domain decomposition method (DDM) is\\nused to co-simulate an RLC electrical circuit where a part of the domain is\\nmodeled with Electro-Magnetic Transients (EMT) modeling and the other part with\\ndynamic phasor (TS) modeling. Domain partitioning is not based on cutting at\\ntransmission lines which introduces a physical delay on the dynamics of the\\nsolution, as is usually done, but only on connectivity considerations. We show\\nthe convergence property of the homogeneous DDM EMT-EMT and TS-TS and of the\\nheterogeneous DDM TS-EMT, with and without overlap and we use the pure linear\\ndivergence/convergence of the method to accelerate it toward the searched\\nsolution with the Aitken's acceleration of the convergence technique.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02507'}, {'title': 'An Analysis of International Use of Robots for COVID-19. (arXiv:2102.02509v1 [cs.RO])', 'description': \"<p>This article analyses data collected on 338 instances of robots used\\nexplicitly in response to COVID-19 from 24 Jan, 2020, to 23 Jan, 2021, in 48\\ncountries. The analysis was guided by four overarching questions: 1) What were\\nrobots used for in the COVID-19 response? 2) When were they used? 3) How did\\ndifferent countries innovate? and 4) Did having a national policy on robotics\\ninfluence a country's innovation and insertion of robotics for COVID-19? The\\nfindings indicate that robots were used for six different sociotechnical work\\ndomains and 29 discrete use cases. When robots were used varied greatly on the\\ncountry; although many countries did report an increase at the beginning of\\ntheir first surge. To understand the findings of how innovation occurred, the\\ndata was examined through the lens of the technology's maturity according to\\nNASA's Technical Readiness Assessment metrics. Through this lens, findings note\\nthat existing robots were used for more than 78% of the instances; slightly\\nmodified robots made up 10%; and truly novel robots or novel use cases\\nconstituted 12% of the instances. The findings clearly indicate that countries\\nwith a national robotics initiative were more likely to use robotics more often\\nand for broader purposes. Finally, the dataset and analysis produces a broad\\nset of implications that warrant further study and investigation. The results\\nfrom this analysis are expected to be of value to the robotics and robotics\\npolicy community in preparing robots for rapid insertion into future disasters.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02509'}, {'title': 'User Interface Factors of Mobile UX: A Study with an Incident Reporting Application. (arXiv:2102.02510v1 [cs.HC])', 'description': '<p>Smartphones are now ubiquitous, yet our understanding of user interface\\nfactors that maximize mobile user experience (UX), is still limited. This work\\npresents a controlled experiment, which investigated factors that affect the\\nusability and UX of a mobile incident reporting app. The results indicate that\\nsequence of user interface elements matters while striving to increase UX, and\\nthat there is no difference between tab and scrolling as navigation modalities\\nin short forms. These findings can serve as building blocks for\\nempirically-derived guidelines for mobile incident reporting.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02510'}, {'title': 'High-Rate Quantum Private Information Retrieval with Weakly Self-Dual Star Product Codes. (arXiv:2102.02511v1 [cs.IT])', 'description': '<p>In the classical private information retrieval (PIR) setup, a user wants to\\nretrieve a file from a database or a distributed storage system (DSS) without\\nrevealing the file identity to the servers holding the data. In the quantum PIR\\n(QPIR) setting, a user privately retrieves a classical file by receiving\\nquantum information from the servers. The QPIR problem has been treated by Song\\net al. in the case of replicated servers, both with and without collusion. QPIR\\nover $[n,k]$ maximum distance separable (MDS) coded servers was recently\\nconsidered by Allaix et al., but the collusion was essentially restricted to\\n$t=n-k$ servers. In this paper, the QPIR setting is extended to account for\\nmore flexible collusion of servers satisfying $t &lt; n-k+1$. Similarly to the\\nprevious cases, the rates achieved are better than those known or conjectured\\nin the classical counterparts, as well as those of the previously proposed\\ncoded and colluding QPIR schemes. This is enabled by considering the stabilizer\\nformalism and weakly self-dual generalized Reed--Solomon (GRS) star product\\ncodes.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02511'}, {'title': 'FedAUX: Leveraging Unlabeled Auxiliary Data in Federated Learning. (arXiv:2102.02514v1 [cs.LG])', 'description': '<p>Federated Distillation (FD) is a popular novel algorithmic paradigm for\\nFederated Learning, which achieves training performance competitive to prior\\nparameter averaging based methods, while additionally allowing the clients to\\ntrain different model architectures, by distilling the client predictions on an\\nunlabeled auxiliary set of data into a student model. In this work we propose\\nFedAUX, an extension to FD, which, under the same set of assumptions,\\ndrastically improves performance by deriving maximum utility from the unlabeled\\nauxiliary data. FedAUX modifies the FD training procedure in two ways: First,\\nunsupervised pre-training on the auxiliary data is performed to find a model\\ninitialization for the distributed training. Second, $(\\\\varepsilon,\\n\\\\delta)$-differentially private certainty scoring is used to weight the\\nensemble predictions on the auxiliary data according to the certainty of each\\nclient model. Experiments on large-scale convolutional neural networks and\\ntransformer models demonstrate, that the training performance of FedAUX exceeds\\nSOTA FL baseline methods by a substantial margin in both the iid and non-iid\\nregime, further closing the gap to centralized training performance. Code is\\navailable at github.com/fedl-repo/fedaux.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02514'}, {'title': 'HYDRA: Hypergradient Data Relevance Analysis for Interpreting Deep Neural Networks. (arXiv:2102.02515v1 [cs.LG])', 'description': '<p>The behaviors of deep neural networks (DNNs) are notoriously resistant to\\nhuman interpretations. In this paper, we propose Hypergradient Data Relevance\\nAnalysis, or HYDRA, which interprets the predictions made by DNNs as effects of\\ntheir training data. Existing approaches generally estimate data contributions\\naround the final model parameters and ignore how the training data shape the\\noptimization trajectory. By unrolling the hypergradient of test loss w.r.t. the\\nweights of training data, HYDRA assesses the contribution of training data\\ntoward test data points throughout the training trajectory. In order to\\naccelerate computation, we remove the Hessian from the calculation and prove\\nthat, under moderate conditions, the approximation error is bounded.\\nCorroborating this theoretical claim, empirical results indicate the error is\\nindeed small. In addition, we quantitatively demonstrate that HYDRA outperforms\\ninfluence functions in accurately estimating data contribution and detecting\\nnoisy data labels. The source code is available at\\nhttps://github.com/cyyever/aaai_hydra_8686.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02515'}, {'title': 'Non-Symmetric Coded Caching for Location-Dependent Content Delivery. (arXiv:2102.02518v1 [cs.IT])', 'description': \"<p>Immersive viewing is emerging as the next interface evolution for\\nhuman-computer interaction. A truly wireless immersive application necessitates\\nimmense data delivery with ultra-low latency, raising stringent requirements\\nfor next-generation wireless networks. A potential solution for addressing\\nthese requirements is through the efficient usage of in-device storage and\\ncomputation capabilities. This paper proposes a novel location-based coded\\ncache placement and delivery scheme, which leverages the nested code modulation\\n(NCM) to enable multi-rate multicasting transmission. To provide a uniform\\nquality of experience in different network locations, we formulate a linear\\nprogramming cache allocation problem. Next, based on the users' spatial\\nrealizations, we adopt an NCM based coded delivery algorithm to efficiently\\nserve a distinct group of users during each transmission. Numerical results\\ndemonstrate that the proposed location-based delivery method significantly\\nincreases transmission efficiency compared to state of the art.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02518'}, {'title': 'Koopman Operator Dynamical Models: Learning, Analysis and Control. (arXiv:2102.02522v1 [eess.SY])', 'description': \"<p>The Koopman operator allows for handling nonlinear systems through a\\n(globally) linear representation. In general, the operator is\\ninfinite-dimensional - necessitating finite approximations - for which there is\\nno overarching framework. Although there are principled ways of learning such\\nfinite approximations, they are in many instances overlooked in favor of, often\\nill-posed and unstructured methods. Also, Koopman operator theory has\\nlong-standing connections to known system-theoretic and dynamical system\\nnotions that are not universally recognized. Given the former and latter\\nrealities, this work aims to bridge the gap between various concepts regarding\\nboth theory and tractable realizations. Firstly, we review data-driven\\nrepresentations (both unstructured and structured) for Koopman operator\\ndynamical models, categorizing various existing methodologies and highlighting\\ntheir differences. Furthermore, we provide concise insight into the paradigm's\\nrelation to system-theoretic notions and analyze the prospect of using the\\nparadigm for modeling control systems. Additionally, we outline the current\\nchallenges and comment on future perspectives.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02522'}, {'title': 'Efficient adaptive step size control for exponential integrators. (arXiv:2102.02524v1 [math.NA])', 'description': '<p>Traditional step size controllers make the tacit assumption that the cost of\\na time step is independent of the step size. This is reasonable for explicit\\nand implicit integrators that use direct solvers. In the context of exponential\\nintegrators, however, an iterative approach, such as Krylov methods or\\npolynomial interpolation, to compute the action of the required matrix\\nfunctions is usually employed. In this case, the assumption of constant cost is\\nnot valid. This is, in particular, a problem for higher-order exponential\\nintegrators, which are able to take relatively large time steps based on\\naccuracy considerations. In this paper, we consider an adaptive step size\\ncontroller for exponential Rosenbrock methods that determines the step size\\nbased on the premise of minimizing computational cost. The largest allowed step\\nsize, given by accuracy considerations, merely acts as a constraint. We test\\nthis approach on a range of nonlinear partial differential equations. Our\\nresults show significant improvements (up to a factor of 4 reduction in the\\ncomputational cost) over the traditional step size controller for a wide range\\nof tolerances.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02524'}, {'title': 'Improved Communication Efficiency for Distributed Mean Estimation with Side Information. (arXiv:2102.02525v1 [cs.IT])', 'description': \"<p>In this paper, we consider the distributed mean estimation problem where the\\nserver has access to some side information, e.g., its local computed mean\\nestimation or the received information sent by the distributed clients at the\\nprevious iterations. We propose a practical and efficient estimator based on an\\nr-bit Wynzer-Ziv estimator proposed by Mayekar et al., which requires no\\nprobabilistic assumption on the data. Unlike Mayekar's work which only utilizes\\nside information at the server, our scheme jointly exploits the correlation\\nbetween clients' data and server' s side information, and also between data of\\ndifferent clients. We derive an upper bound of the estimation error of the\\nproposed estimator. Based on this upper bound, we provide two algorithms on how\\nto choose input parameters for the estimator. Finally, parameter regions in\\nwhich our estimator is better than the previous one are characterized.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02525'}, {'title': 'Deep Learning for Short-Term Voltage Stability Assessment of Power Systems. (arXiv:2102.02526v1 [eess.SP])', 'description': '<p>To fully learn the latent temporal dependencies from post-disturbance system\\ndynamic trajectories, deep learning is utilized for short-term voltage\\nstability (STVS) assessment of power systems in this paper. First of all, a\\nsemi-supervised cluster algorithm is performed to obtain class labels of STVS\\ninstances due to the unavailability of reliable quantitative criteria.\\nSecondly, a long short-term memory (LSTM) based assessment model is built\\nthrough learning the time dependencies from the post-disturbance system\\ndynamics. Finally, the trained assessment model is employed to determine the\\nsystems stability status in real time. The test results on the IEEE 39-bus\\nsystem suggest that the proposed approach manages to assess the stability\\nstatus of the system accurately and timely. Furthermore, the superiority of the\\nproposed method over traditional shallow learning-based assessment methods has\\nalso been proved.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02526'}, {'title': 'FuzzSplore: Visualizing Feedback-Driven Fuzzing Techniques. (arXiv:2102.02527v1 [cs.CR])', 'description': '<p>Fuzz Testing techniques are the state of the art in software testing for\\nsecurity issues nowadays. Their great effectiveness attracted the attention of\\nresearchers and hackers and involved them in developing a lot of new techniques\\nto improve Fuzz Testing. The evaluation and the cross-comparison of these\\ntechniques is an almost open problem. In this paper, we propose a human-driven\\napproach to this problem based on information visualization. We developed a\\nprototype upon the AFL++ fuzzing framework, FuzzSplore, that an analyst can use\\nto get useful insights about different fuzzing configurations applied to a\\nspecific target in order to choose or tune the best technique during a fuzzing\\ncampaign.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02527'}, {'title': \"On the Global Optimality of Whittle's index policy for minimizing the age of information. (arXiv:2102.02528v1 [cs.IT])\", 'description': \"<p>This paper examines the average age minimization problem where only a\\nfraction of the network users can transmit simultaneously over unreliable\\nchannels. Finding the optimal scheduling scheme, in this case, is known to be\\nchallenging. Accordingly, the Whittle's index policy was proposed in the\\nliterature as a low-complexity heuristic to the problem. Although simple to\\nimplement, characterizing this policy's performance is recognized to be a\\nnotoriously tricky task. In the sequel, we provide a new mathematical approach\\nto establish its optimality in the many-users regime for specific network\\nsettings. Our novel approach is based on intricate techniques, and unlike\\nprevious works in the literature, it is free of any mathematical assumptions.\\nThese findings showcase that the Whittle's index policy has analytically\\nprovable asymptotic optimality for the AoI minimization problem. Finally, we\\nlay out numerical results that corroborate our theoretical findings and\\ndemonstrate the policy's notable performance in the many-users regime.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02528'}, {'title': 'ABCNet: Attentive Bilateral Contextual Network for Efficient Semantic Segmentation of Fine-Resolution Remote Sensing Images. (arXiv:2102.02531v1 [cs.CV])', 'description': '<p>Semantic segmentation of remotely sensed images plays a crucial role in\\nprecision agriculture, environmental protection, and economic assessment. In\\nrecent years, substantial fine-resolution remote sensing images are available\\nfor semantic segmentation. However, due to the complicated information caused\\nby the increased spatial resolution, state-of-the-art deep learning algorithms\\nnormally utilize complex network architectures for segmentation, which usually\\nincurs high computational complexity. Specifically, the high-caliber\\nperformance of the convolutional neural network (CNN) heavily relies on\\nfine-grained spatial details (fine resolution) and sufficient contextual\\ninformation (large receptive fields), both of which trigger high computational\\ncosts. This crucially impedes their practicability and availability in\\nreal-world scenarios that require real-time processing. In this paper, we\\npropose an Attentive Bilateral Contextual Network (ABCNet), a convolutional\\nneural network (CNN) with double branches, with prominently lower computational\\nconsumptions compared to the cutting-edge algorithms, while maintaining a\\ncompetitive accuracy. Code is available at https://github.com/lironui/ABCNet.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02531'}, {'title': 'Deep Learning Based Model Identification System Exploits the Modular Structure of a Bio-Inspired Posture Control Model for Humans and Humanoids. (arXiv:2102.02536v1 [cs.LG])', 'description': '<p>This work presents a system identification procedure based on Convolutional\\nNeural Networks (CNN) for human posture control using the DEC (Disturbance\\nEstimation and Compensation) parametric model. The modular structure of the\\nproposed control model inspired the design of a modular identification\\nprocedure, in the sense that the same neural network is used to identify the\\nparameters of the modules controlling different degrees of freedom. In this way\\nthe presented examples of body sway induced by external stimuli provide several\\ntraining samples at once\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02536'}, {'title': 'Accurate numerical simulation of electrodiffusion and water movement in brain tissue. (arXiv:2102.02539v1 [math.NA])', 'description': '<p>Mathematical modelling of ionic electrodiffusion and water movement is\\nemerging as a powerful avenue of investigation to provide new physiological\\ninsight into brain homeostasis. However, in order to provide solid answers and\\nresolve controversies, the accuracy of the predictions is essential. Ionic\\nelectrodiffusion models typically comprise non-trivial systems of non-linear\\nand highly coupled partial and ordinary differential equations that govern\\nphenomena on disparate time scales. Here, we study numerical challenges related\\nto approximating these systems. We consider a homogenized model for\\nelectrodiffusion and osmosis in brain tissue and present and evaluate different\\nassociated finite element-based splitting schemes in terms of their numerical\\nproperties, including accuracy, convergence, and computational efficiency for\\nboth idealized scenarios and for the physiologically relevant setting of\\ncortical spreading depression (CSD). We find that the schemes display optimal\\nconvergence rates in space for problems with smooth manufactured solutions.\\nHowever, the physiological CSD setting is challenging: we find that the\\naccurate computation of CSD wave characteristics (wave speed and wave width)\\nrequires a very fine spatial and fine temporal resolution.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02539'}, {'title': 'On Fading Channel Dependency Structures with a Positive Zero-Outage Capacity. (arXiv:2102.02541v1 [cs.IT])', 'description': '<p>With emerging technologies like 6G, many new applications like autonomous\\nsystems evolve which have strict demands on the reliability of data\\ncommunications. In this work, we consider a system with multiple slowly fading\\nchannels that constitute a diversity system. We show that the joint\\ndistribution of the fading coefficients has a tremendous impact on the outage\\nperformance of a communication system. In particular, we investigate the\\nzero-outage capacity (ZOC) and characterize the joint fading distributions with\\na strictly positive ZOC. Interestingly, the set of joint distributions, that\\nlead to positive ZOCs, is larger than a singleton in general. We also derive\\nexpressions for the maximum ZOC with respect to all possible joint\\ndistributions for selection combining (SC) as diversity combining technique at\\nthe receiver. For maximum ratio combining (MRC), we characterize the maximum\\nZOC within a finite number of bits. Finally, the results are evaluated\\nexplicitly for the special cases of Rayleigh fading and Nakagami-$m$ fading in\\norder to quantify the ZOCs for common fading models.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02541'}, {'title': 'The Importance of Models in Data Analysis with Small Human Movement Datasets -- Inspirations from Neurorobotics Applied to Posture Control of Humanoids and Humans. (arXiv:2102.02543v1 [cs.RO])', 'description': '<p>This work presents a system identification procedure based on Convolutional\\nNeural Networks (CNN) for human posture control using the DEC (Disturbance\\nEstimation and Compensation) parametric model. The modular structure of the\\nproposed control model inspired the design of a modular identification\\nprocedure, in the sense that the same neural network is used to identify the\\nparameters of the modules controlling different degrees of freedom. In this way\\nthe presented examples of body sway induced by external stimuli provide several\\ntraining samples at once.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02543'}, {'title': 'Decoding Reed-Solomon codes by solving a bilinear system with a Gr\\\\\"obner basis approach. (arXiv:2102.02544v1 [cs.IT])', 'description': '<p>Decoding a Reed-Solomon code can be modeled by a bilinear system which can be\\nsolved by Gr\\\\\"obner basis techniques. We will show that in this particular\\ncase, these techniques are much more efficient than for generic bilinear\\nsystems with the same number of unknowns and equations (where these techniques\\nhave exponential complexity). Here we show that they are able to solve the\\nproblem in polynomial time up to the Sudan radius. Moreover, beyond this radius\\nthese techniques recover automatically polynomial identities that are at the\\nheart of improvements of the power decoding approach for reaching the Johnson\\ndecoding radius. They also allow to derive new polynomial identities that can\\nbe used to derive new algebraic decoding algorithms for Reed-Solomon codes. We\\nprovide numerical evidence that this sometimes allows to correct efficiently\\nslightly more errors than the Johnson radius.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02544'}, {'title': 'CHEF: Cross-modal Hierarchical Embeddings for Food Domain Retrieval. (arXiv:2102.02547v1 [cs.CV])', 'description': '<p>Despite the abundance of multi-modal data, such as image-text pairs, there\\nhas been little effort in understanding the individual entities and their\\ndifferent roles in the construction of these data instances. In this work, we\\nendeavour to discover the entities and their corresponding importance in\\ncooking recipes automaticall} as a visual-linguistic association problem. More\\nspecifically, we introduce a novel cross-modal learning framework to jointly\\nmodel the latent representations of images and text in the food image-recipe\\nassociation and retrieval tasks. This model allows one to discover complex\\nfunctional and hierarchical relationships between images and text, and among\\ntextual parts of a recipe including title, ingredients and cooking\\ninstructions. Our experiments show that by making use of efficient\\ntree-structured Long Short-Term Memory as the text encoder in our computational\\ncross-modal retrieval framework, we are not only able to identify the main\\ningredients and cooking actions in the recipe descriptions without explicit\\nsupervision, but we can also learn more meaningful feature representations of\\nfood recipes, appropriate for challenging cross-modal retrieval and recipe\\nadaption tasks.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02547'}, {'title': 'Dual-embedding based Neural Collaborative Filtering for Recommender Systems. (arXiv:2102.02549v1 [cs.IR])', 'description': \"<p>Among various recommender techniques, collaborative filtering (CF) is the\\nmost successful one. And a key problem in CF is how to represent users and\\nitems. Previous works usually represent a user (an item) as a vector of latent\\nfactors (aka. \\\\textit{embedding}) and then model the interactions between users\\nand items based on the representations. Despite its effectiveness, we argue\\nthat it's insufficient to yield satisfactory embeddings for collaborative\\nfiltering. Inspired by the idea of SVD++ that represents users based on\\nthemselves and their interacted items, we propose a general collaborative\\nfiltering framework named DNCF, short for Dual-embedding based Neural\\nCollaborative Filtering, to utilize historical interactions to enhance the\\nrepresentation. In addition to learning the primitive embedding for a user (an\\nitem), we introduce an additional embedding from the perspective of the\\ninteracted items (users) to augment the user (item) representation. Extensive\\nexperiments on four publicly datasets demonstrated the effectiveness of our\\nproposed DNCF framework by comparing its performance with several traditional\\nmatrix factorization models and other state-of-the-art deep learning based\\nrecommender models.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02549'}, {'title': 'ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine Learning Models. (arXiv:2102.02551v1 [cs.CR])', 'description': \"<p>Inference attacks against Machine Learning (ML) models allow adversaries to\\nlearn information about training data, model parameters, etc. While researchers\\nhave studied these attacks thoroughly, they have done so in isolation. We lack\\na comprehensive picture of the risks caused by the attacks, such as the\\ndifferent scenarios they can be applied to, the common factors that influence\\ntheir performance, the relationship among them, or the effectiveness of defense\\ntechniques. In this paper, we fill this gap by presenting a first-of-its-kind\\nholistic risk assessment of different inference attacks against machine\\nlearning models. We concentrate on four attacks - namely, membership inference,\\nmodel inversion, attribute inference, and model stealing - and establish a\\nthreat model taxonomy. Our extensive experimental evaluation conducted over\\nfive model architectures and four datasets shows that the complexity of the\\ntraining dataset plays an important role with respect to the attack's\\nperformance, while the effectiveness of model stealing and membership inference\\nattacks are negatively correlated. We also show that defenses like DP-SGD and\\nKnowledge Distillation can only hope to mitigate some of the inference attacks.\\nOur analysis relies on a modular re-usable software, ML-Doctor, which enables\\nML model owners to assess the risks of deploying their models, and equally\\nserves as a benchmark tool for researchers and practitioners.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02551'}, {'title': 'Decoding of Space-Symmetric Rank Errors. (arXiv:2102.02554v1 [cs.IT])', 'description': '<p>This paper investigates the decoding of certain Gabidulin codes that were\\ntransmitted over a channel with space-symmetric errors. Space-symmetric errors\\nare additive error matrices that have the property that their column and row\\nspaces are equal. We show that for channels restricted to space-symmetric\\nerrors, with high probability errors of rank up to 2(n-k)/3 can be decoded with\\na Gabidulin code of length n and dimension k, using a weak-self orthogonal\\nbasis as code locators.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02554'}, {'title': 'Adaptive Semiparametric Language Models. (arXiv:2102.02557v1 [cs.CL])', 'description': '<p>We present a language model that combines a large parametric neural network\\n(i.e., a transformer) with a non-parametric episodic memory component in an\\nintegrated architecture. Our model uses extended short-term context by caching\\nlocal hidden states -- similar to transformer-XL -- and global long-term memory\\nby retrieving a set of nearest neighbor tokens at each timestep. We design a\\ngating function to adaptively combine multiple information sources to make a\\nprediction. This mechanism allows the model to use either local context,\\nshort-term memory, or long-term memory (or any combination of them) on an ad\\nhoc basis depending on the context. Experiments on word-based and\\ncharacter-based language modeling datasets demonstrate the efficacy of our\\nproposed method compared to strong baselines.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02557'}, {'title': 'Evolutionary Multitask Optimization: a Methodological Overview, Challenges and Future Research Directions. (arXiv:2102.02558v1 [cs.NE])', 'description': '<p>In this work we consider multitasking in the context of solving multiple\\noptimization problems simultaneously by conducting a single search process. The\\nprincipal goal when dealing with this scenario is to dynamically exploit the\\nexisting complementarities among the problems (tasks) being optimized, helping\\neach other through the exchange of valuable knowledge. Additionally, the\\nemerging paradigm of Evolutionary Multitasking tackles multitask optimization\\nscenarios by using as inspiration concepts drawn from Evolutionary Computation.\\nThe main purpose of this survey is to collect, organize and critically examine\\nthe abundant literature published so far in Evolutionary Multitasking, with an\\nemphasis on the methodological patterns followed when designing new algorithmic\\nproposals in this area (namely, multifactorial optimization and\\nmultipopulation-based multitasking). We complement our critical analysis with\\nan identification of challenges that remain open to date, along with promising\\nresearch directions that can stimulate future efforts in this topic. Our\\ndiscussions held throughout this manuscript are offered to the audience as a\\nreference of the general trajectory followed by the community working in this\\nfield in recent times, as well as a self-contained entry point for newcomers\\nand researchers interested to join this exciting research avenue.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02558'}, {'title': 'An efficient linear programming rounding-and-refinement algorithm for large-scale network slicing problem. (arXiv:2102.02563v1 [cs.NI])', 'description': '<p>In this paper, we consider the network slicing problem which attempts to map\\nmultiple customized virtual network requests (also called services) to a common\\nshared network infrastructure and allocate network resources to meet diverse\\nservice requirements, and propose an efficient two-stage algorithm for solving\\nthis NP-hard problem. In the first stage, the proposed algorithm uses an\\niterative linear programming (LP) rounding procedure to place the virtual\\nnetwork functions of all services into cloud nodes while taking traffic routing\\nof all services into consideration; in the second stage, the proposed algorithm\\nuses an iterative LP refinement procedure to obtain a solution for traffic\\nrouting of all services with their end-to-end delay constraints being\\nsatisfied. Compared with the existing algorithms which either have an\\nexponential complexity or return a low-quality solution, our proposed algorithm\\nachieves a better trade-off between solution quality and computational\\ncomplexity. In particular, the worst-case complexity of our proposed algorithm\\nis polynomial, which makes it suitable for solving large-scale problems.\\nNumerical results demonstrate the effectiveness and efficiency of our proposed\\nalgorithm.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02563'}, {'title': 'Incremental Beam Manipulation for Natural Language Generation. (arXiv:2102.02574v1 [cs.CL])', 'description': '<p>The performance of natural language generation systems has improved\\nsubstantially with modern neural networks. At test time they typically employ\\nbeam search to avoid locally optimal but globally suboptimal predictions.\\nHowever, due to model errors, a larger beam size can lead to deteriorating\\nperformance according to the evaluation metric. For this reason, it is common\\nto rerank the output of beam search, but this relies on beam search to produce\\na good set of hypotheses, which limits the potential gains. Other alternatives\\nto beam search require changes to the training of the model, which restricts\\ntheir applicability compared to beam search. This paper proposes incremental\\nbeam manipulation, i.e. reranking the hypotheses in the beam during decoding\\ninstead of only at the end. This way, hypotheses that are unlikely to lead to a\\ngood final output are discarded, and in their place hypotheses that would have\\nbeen ignored will be considered instead. Applying incremental beam manipulation\\nleads to an improvement of 1.93 and 5.82 BLEU points over vanilla beam search\\nfor the test sets of the E2E and WebNLG challenges respectively. The proposed\\nmethod also outperformed a strong reranker by 1.04 BLEU points on the E2E\\nchallenge, while being on par with it on the WebNLG dataset.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02574'}, {'title': 'Exploring Scale-Measures of Data Sets. (arXiv:2102.02576v1 [cs.AI])', 'description': '<p>Measurement is a fundamental building block of numerous scientific models and\\ntheir creation. This is in particular true for data driven science. Due to the\\nhigh complexity and size of modern data sets, the necessity for the development\\nof understandable and efficient scaling methods is at hand. A profound theory\\nfor scaling data is scale-measures, as developed in the field of formal concept\\nanalysis. Recent developments indicate that the set of all scale-measures for a\\ngiven data set constitutes a lattice and does hence allow efficient exploring\\nalgorithms. In this work we study the properties of said lattice and propose a\\nnovel scale-measure exploration algorithm that is based on the well-known and\\nproven attribute exploration approach. Our results motivate multiple\\napplications in scale recommendation, most prominently (semi-)automatic\\nscaling.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02576'}, {'title': 'Regenerating Soft Robots through Neural Cellular Automata. (arXiv:2102.02579v1 [cs.NE])', 'description': '<p>Morphological regeneration is an important feature that highlights the\\nenvironmental adaptive capacity of biological systems. Lack of this\\nregenerative capacity significantly limits the resilience of machines and the\\nenvironments they can operate in. To aid in addressing this gap, we develop an\\napproach for simulated soft robots to regrow parts of their morphology when\\nbeing damaged. Although numerical simulations using soft robots have played an\\nimportant role in their design, evolving soft robots with regenerative\\ncapabilities have so far received comparable little attention. Here we propose\\na model for soft robots that regenerate through a neural cellular automata.\\nImportantly, this approach only relies on local cell information to regrow\\ndamaged components, opening interesting possibilities for physical regenerable\\nsoft robots in the future. Our approach allows simulated soft robots that are\\ndamaged to partially regenerate their original morphology through local cell\\ninteractions alone and regain some of their ability to locomote. These results\\ntake a step towards equipping artificial systems with regenerative capacities\\nand could potentially allow for more robust operations in a variety of\\nsituations and environments. The code for the experiments in this paper is\\navailable at: \\\\url{github.com/KazuyaHoribe/RegeneratingSoftRobots}.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02579'}, {'title': 'Parallelware Tools: An Experimental Evaluation on POWER Systems. (arXiv:2102.02582v1 [cs.DC])', 'description': \"<p>Static code analysis tools are designed to aid software developers to build\\nbetter quality software in less time, by detecting defects early in the\\nsoftware development life cycle. Even the most experienced developer regularly\\nintroduces coding defects. Identifying, mitigating and resolving defects is an\\nessential part of the software development process, but frequently defects can\\ngo undetected. One defect can lead to a minor malfunction or cause serious\\nsecurity and safety issues. This is magnified in the development of the complex\\nparallel software required to exploit modern heterogeneous multicore hardware.\\nThus, there is an urgent need for new static code analysis tools to help in\\nbuilding better concurrent and parallel software. The paper reports preliminary\\nresults about the use of Appentra's Parallelware technology to address this\\nproblem from the following three perspectives: finding concurrency issues in\\nthe code, discovering new opportunities for parallelization in the code, and\\ngenerating parallel-equivalent codes that enable tasks to run faster. The paper\\nalso presents experimental results using well-known scientific codes and POWER\\nsystems.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02582'}, {'title': 'Optimizing Blockchain Based Smart Grid Auctions: A Green Revolution. (arXiv:2102.02583v1 [cs.CR])', 'description': '<p>Integrating blockchain with energy trading is a new paradigm for researchers\\nworking in the field of smart grid. In energy trading, auction theory plays an\\nimportant role to ensure truthfulness, rationality, and to balance utility of\\nparticipants. However, traditional energy auctions cannot directly be\\nintegrated in blockchain based auctions due to the decentralized nature.\\nTherefore, researches are being carried out to propose more efficient\\ndecentralized auctions for energy trading. Despite of all these advances, a\\ngreater standpoint that is not well-highlighted or discussed in majority of\\nproposed mechanisms is the integration of green aspect in these auctions.\\nSince, blockchain is a novel paradigm to ensure trust but it also comes up with\\na curse of high computation and communication complexity which eventually\\ncauses resource scarcity. Therefore, there is a need to develop and encourage\\ndevelopment of more green auctions to carry out decentralised energy trading.\\nIn this paper, we first provide a thorough motivation of decentralized auctions\\nover traditional auctions. Afterwards, we provide in-depth design requirements\\nthat can be taken into consideration while developing such auctions. After\\nthat, we analyse technical works that have developed blockchain based energy\\nauctions from green perspective. Finally, we summarize the article by providing\\nchallenges and possible future research directions of blockchain based energy\\nauction from green viewpoint.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02583'}, {'title': 'Human Values in Software Release Planning. (arXiv:2102.02584v1 [cs.SE])', 'description': '<p>Software products have become an integral part of human lives, and therefore\\nneed to account for human values such as privacy, fairness, and equality.\\nIgnoring human values in software development leads to biases and violations of\\nhuman values: racial biases in recidivism assessment and facial recognition\\nsoftware are well-known examples of such issues. One of the most critical steps\\nin software development is Software Release Planning (SRP), where decisions are\\nmade about the presence or absence of the requirements (features) in the\\nsoftware. Such decisions are primarily guided by the economic value of the\\nrequirements, ignoring their impacts on a broader range of human values. That\\nmay result in ignoring (selecting) requirements that positively (negatively)\\nimpact human values, increasing the risk of value breaches in the software. To\\naddress this, we have proposed an Integer Programming approach to considering\\nhuman values in software release planning. In this regard, an Integer Linear\\nProgramming (ILP) model has been proposed, that explicitly accounts for human\\nvalues in finding an \"optimal\" subset of the requirements. The ILP model\\nexploits the algebraic structure of fuzzy graphs to capture dependencies and\\nconflicts among the values of the requirements.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02584'}, {'title': 'One Size Does Not Fit All: Finding the Optimal N-gram Sizes for FastText Models across Languages. (arXiv:2102.02585v1 [cs.CL])', 'description': '<p>Unsupervised word representation learning from large corpora is badly needed\\nfor downstream tasks such as text classification, information retrieval, and\\nmachine translation. The representation precision of the fastText language\\nmodels is mostly due to their use of subword information. In previous work, the\\noptimization of fastText subword sizes has been largely neglected, and\\nnon-English fastText language models were trained using subword sizes optimized\\nfor English and German.\\n</p>\\n<p>In our work, we train English, German, Czech, and Italian fastText language\\nmodels on Wikipedia, and we optimize the subword sizes on the English, German,\\nCzech, and Italian word analogy tasks. We show that the optimization of subword\\nsizes results in a 5% improvement on the Czech word analogy task. We also show\\nthat computationally expensive hyperparameter optimization can be replaced with\\ncheap $n$-gram frequency analysis: subword sizes that are the closest to\\ncovering 3.76% of all unique subwords in a language are shown to be the optimal\\nfastText hyperparameters on the English, German, Czech, and Italian word\\nanalogy tasks.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02585'}, {'title': 'Temporal Cascade and Structural Modelling of EHRs for Granular Readmission Prediction. (arXiv:2102.02586v1 [cs.LG])', 'description': '<p>Predicting (1) when the next hospital admission occurs and (2) what will\\nhappen in the next admission about a patient by mining electronic health record\\n(EHR) data can provide granular readmission predictions to assist clinical\\ndecision making. Recurrent neural network (RNN) and point process models are\\nusually employed in modelling temporal sequential data. Simple RNN models\\nassume that sequences of hospital visits follow strict causal dependencies\\nbetween consecutive visits. However, in the real-world, a patient may have\\nmultiple co-existing chronic medical conditions, i.e., multimorbidity, which\\nresults in a cascade of visits where a non-immediate historical visit can be\\nmost influential to the next visit. Although a point process (e.g., Hawkes\\nprocess) is able to model a cascade temporal relationship, it strongly relies\\non a prior generative process assumption. We propose a novel model, MEDCAS, to\\naddress these challenges. MEDCAS combines the strengths of RNN-based models and\\npoint processes by integrating point processes in modelling visit types and\\ntime gaps into an attention-based sequence-to-sequence learning model, which is\\nable to capture the temporal cascade relationships. To supplement the patients\\nwith short visit sequences, a structural modelling technique with graph-based\\nmethods is used to construct the markers of the point process in MEDCAS.\\nExtensive experiments on three real-world EHR datasets have been performed and\\nthe results demonstrate that \\\\texttt{MEDCAS} outperforms state-of-the-art\\nmodels in both tasks.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02586'}, {'title': 'Lookup subnet based Spatial Graph Convolutional neural Network. (arXiv:2102.02588v1 [cs.LG])', 'description': '<p>Convolutional Neural Networks(CNNs) has achieved remarkable performance\\nbreakthrough in Euclidean structure data. Recently, aggregation-transformation\\nbased Graph Neural networks(GNNs) gradually produce a powerful performance on\\nnon-Euclidean data. In this paper, we propose a cross-correlation based graph\\nconvolution method allowing to naturally generalize CNNs to non-Euclidean\\ndomains and inherit the excellent natures of CNNs, such as local filters,\\nparameter sharing, flexible receptive field, etc. Meanwhile, it leverages\\ndynamically generated convolution kernel and cross-correlation operators to\\naddress the shortcomings of prior methods based on aggregation-transformation\\nor their approximations. Our method has achieved or matched popular\\nstate-of-the-art results across three established graph benchmarks: the Cora,\\nCiteseer, and Pubmed citation network datasets.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02588'}, {'title': 'Mean-field control variate methods for kinetic equations with uncertainties and applications to socio-economic sciences. (arXiv:2102.02589v1 [math.NA])', 'description': '<p>In this paper, we extend a recently introduced multi-fidelity control variate\\nfor the uncertainty quantification of the Boltzmann equation to the case of\\nkinetic models arising in the study of multiagent systems. For these phenomena,\\nwhere the effect of uncertainties is particularly evident, several models have\\nbeen developed whose equilibrium states are typically unknown. In particular,\\nwe aim to develop efficient numerical methods based on solving the kinetic\\nequations in the phase space by Direct Simulation Monte Carlo (DSMC) coupled to\\na Monte Carlo sampling in the random space. To this end, exploiting the\\nknowledge of the corresponding mean-field approximation we develop novel\\nmean-field Control Variate (MFCV) methods that are able to strongly reduce the\\nvariance of the standard Monte Carlo sampling method in the random space. We\\nverify these observations with several numerical examples based on classical\\nmodels , including wealth exchanges and opinion formation model for collective\\nphenomena.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02589'}, {'title': 'A Faster Algorithm for Finding Closest Pairs in Hamming Metric. (arXiv:2102.02597v1 [cs.DS])', 'description': '<p>We study the Closest Pair Problem in Hamming metric, which asks to find the\\npair with the smallest Hamming distance in a collection of binary vectors. We\\ngive a new randomized algorithm for the problem on uniformly random input\\noutperforming previous approaches whenever the dimension of input points is\\nsmall compared to the dataset size. For moderate to large dimensions, our\\nalgorithm matches the time complexity of the previously best-known locality\\nsensitive hashing based algorithms. Technically our algorithm follows similar\\ndesign principles as Dubiner (IEEE Trans. Inf. Theory 2010) and May-Ozerov\\n(Eurocrypt 2015). Besides improving the time complexity in the aforementioned\\nareas, we significantly simplify the analysis of these previous works. We give\\na modular analysis, which allows us to investigate the performance of the\\nalgorithm also on non-uniform input distributions. Furthermore, we give a proof\\nof concept implementation of our algorithm which performs well in comparison to\\na quadratic search baseline. This is the first step towards answering an open\\nquestion raised by May and Ozerov regarding the practicability of algorithms\\nfollowing these design principles.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02597'}, {'title': 'VSEGAN: Visual Speech Enhancement Generative Adversarial Network. (arXiv:2102.02599v1 [eess.AS])', 'description': '<p>Speech enhancement is an essential task of improving speech quality in noise\\nscenario. Several state-of-the-art approaches have introduced visual\\ninformation for speech enhancement,since the visual aspect of speech is\\nessentially unaffected by acoustic environment. This paper proposes a novel\\nframeworkthat involves visual information for speech enhancement, by\\nin-corporating a Generative Adversarial Network (GAN). In par-ticular, the\\nproposed visual speech enhancement GAN consistof two networks trained in\\nadversarial manner, i) a generator that adopts multi-layer feature fusion\\nconvolution network to enhance input noisy speech, and ii) a discriminator that\\nattemptsto minimize the discrepancy between the distributions of the clean\\nspeech signal and enhanced speech signal. Experiment re-sults demonstrated\\nsuperior performance of the proposed modelagainst several state-of-the-art\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02599'}, {'title': 'A formalization of Dedekind domains and class groups of global fields. (arXiv:2102.02600v1 [cs.LO])', 'description': \"<p>Dedekind domains and their class groups are notions in commutative algebra\\nthat are essential in algebraic number theory. We formalized these structures\\nand several fundamental properties, including number theoretic finiteness\\nresults for class groups, in the Lean prover as part of the mathlib\\nmathematical library. This paper describes the formalization process, noting\\nthe idioms we found useful in our development and mathlib's decentralized\\ncollaboration processes involved in this project.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02600'}, {'title': 'An Empirical Analysis of Implementing Enterprise Blockchain Protocols in Supply Chain Anti-Counterfeiting and Traceability. (arXiv:2102.02601v1 [cs.CR])', 'description': '<p>A variety of innovative software solutions, addressing product\\nanti-counterfeiting and record provenance of the wider supply chain industry,\\nhave been implemented. However, these solutions have been developed with\\ncentralized system architecture which could be susceptible to malicious\\nmodifications on states of product records and various potential security\\nattacks leading to system failure and downtime. Blockchain technology has been\\nenabling decentralized trust with a network of distributed peer nodes to\\nmaintain consistent shared states via a decentralized consensus reached, with\\nwhich an idea of developing decentralized and reliable solutions has been\\nbasing on. A Decentralized NFC-Enabled Anti-Counterfeiting System (dNAS) was\\ntherefore proposed and developed, decentralizing a legacy anti-counterfeiting\\nsystem of supply chain industry utilizing enterprise blockchain protocols and\\nenterprise consortium, to facilitate trustworthy data provenance retrieval,\\nverification and management, as well as strengthening capability of product\\nanti-counterfeiting and traceability in supply chain industry. The adoption of\\nenterprise blockchain protocols and implementations has been surging in supply\\nchain industry given its advantages in scalability, governance and\\ncompatibility with existing supply chain systems and networks, but development\\nand adoption of decentralized solutions could also impose additional\\nimplications to supply chain integrity, in terms of security, privacy and\\nconfidentiality. In this research, an empirical analysis performed against\\ndecentralized solutions, including dNAS, summarizes the effectiveness,\\nlimitations and future opportunities of developing decentralized solutions\\nbuilt around existing enterprise blockchain protocols and implementations for\\nsupply chain anti-counterfeiting and traceability.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02601'}, {'title': 'A Learning-based Stochastic Driving Model for Autonomous Vehicle Testing. (arXiv:2102.02602v1 [eess.SY])', 'description': \"<p>In the simulation-based testing and evaluation of autonomous vehicles (AVs),\\nhow background vehicles (BVs) drive directly influences the AV's driving\\nbehavior and further impacts the testing result. Existing simulation platforms\\nuse either pre-determined trajectories or deterministic driving models to model\\nthe BVs' behaviors. However, pre-determined BV trajectories can not react to\\nthe AV's maneuvers, and deterministic models are different from real human\\ndrivers due to the lack of stochastic components and errors. Both methods lead\\nto unrealistic traffic scenarios. This paper presents a learning-based\\nstochastic driving model that meets the unique needs of AV testing, i.e.\\ninteractive and human-like. The model is built based on the\\nlong-short-term-memory (LSTM) architecture. By incorporating the concept of\\nquantile-regression to the loss function of the model, the stochastic behaviors\\nare reproduced without any prior assumption of human drivers. The model is\\ntrained with the large-scale naturalistic driving data (NDD) from the Safety\\nPilot Model Deployment(SPMD) project and then compared with a stochastic\\nintelligent driving model (IDM). Analysis of individual trajectories shows that\\nthe proposed model can reproduce more similar trajectories to human drivers\\nthan IDM. To validate the ability of the proposed model in generating a\\nnaturalistic driving environment, traffic simulation experiments are\\nimplemented. The results show that the traffic flow parameters such as speed,\\nrange, and headway distribution match closely with the NDD, which is of\\nsignificant importance for AV testing and evaluation.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02602'}, {'title': 'Linear complexity of some sequences derived from hyperelliptic curves of genus 2. (arXiv:2102.02605v1 [math.NT])', 'description': '<p>For a given hyperelliptic curve $C$ over a finite field with Jacobian $J_C$,\\nwe consider the hyperelliptic analogue of the congruential generator defined by\\n$W_n=W_{n-1}+D$ for $n\\\\geq 1$ and $D,W_0\\\\in J_C$. We show that curves of genus\\n2 produce sequences with large linear complexity.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02605'}, {'title': 'Minimizing the alphabet size in codes with restricted error sets. (arXiv:2102.02608v1 [cs.IT])', 'description': '<p>This paper focuses on error-correcting codes that can handle a predefined set\\nof specific error patterns. The need for such codes arises in many settings of\\npractical interest, including wireless communication and flash memory systems.\\nIn many such settings, a smaller field size is achievable than that offered by\\nMDS and other standard codes. We establish a connection between the minimum\\nalphabet size for this generalized setting and the combinatorial properties of\\na hypergraph that represents the prespecified collection of error patterns. We\\nalso show a connection between error and erasure correcting codes in this\\nspecialized setting. This allows us to establish bounds on the minimum alphabet\\nsize and show an advantage of non-linear codes over linear codes in a\\ngeneralized setting. We also consider a variation of the problem which allows a\\nsmall probability of decoding error and relate it to an approximate version of\\nhypergraph coloring.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02608'}, {'title': 'Barrier Function-based Collaborative Control of Multiple Robots under Signal Temporal Logic Tasks. (arXiv:2102.02609v1 [eess.SY])', 'description': '<p>Motivated by the recent interest in cyber-physical and autonomous robotic\\nsystems, we study the problem of dynamically coupled multi-agent systems under\\na set of signal temporal logic tasks. In particular, the satisfaction of each\\nof these signal temporal logic tasks depends on the behavior of a distinct set\\nof agents. Instead of abstracting the agent dynamics and the temporal logic\\ntasks into a discrete domain and solving the problem therein or using\\noptimization-based methods, we derive collaborative feedback control laws.\\nThese control laws are based on a decentralized control barrier function\\ncondition that results in discontinuous control laws, as opposed to a\\ncentralized condition resembling the single-agent case. The benefits of our\\napproach are inherent robustness properties typically present in feedback\\ncontrol as well as satisfaction guarantees for continuous-time multi-agent\\nsystems. More specifically, time-varying control barrier functions are used\\nthat account for the semantics of the signal temporal logic tasks at hand. For\\na certain fragment of signal temporal logic tasks, we further propose a\\nsystematic way to construct such control barrier functions. Finally, we show\\nthe efficacy and robustness of our framework in an experiment including a group\\nof three omnidirectional robots.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02609'}, {'title': 'Strategyproof Facility Location Mechanisms on Discrete Trees. (arXiv:2102.02610v1 [cs.GT])', 'description': '<p>We address the problem of strategyproof (SP) facility location mechanisms on\\ndiscrete trees. Our main result is a full characterization of onto and SP\\nmechanisms. In particular, we prove that when a single agent significantly\\naffects the outcome, the trajectory of the facility is almost contained in the\\ntrajectory of the agent, and both move in the same direction along the common\\nedges. We show tight relations of our characterization to previous results on\\ndiscrete lines and on continuous trees. We then derive further implications of\\nthe main result for infinite discrete lines.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02610'}, {'title': 'CKConv: Continuous Kernel Convolution For Sequential Data. (arXiv:2102.02611v1 [cs.LG])', 'description': '<p>Conventional neural architectures for sequential data present important\\nlimitations. Recurrent networks suffer from exploding and vanishing gradients,\\nsmall effective memory horizons, and must be trained sequentially.\\nConvolutional networks are unable to handle sequences of unknown size and their\\nmemory horizon must be defined a priori. In this work, we show that all these\\nproblems can be solved by formulating convolutional kernels in CNNs as\\ncontinuous functions. The resulting Continuous Kernel Convolution (CKConv)\\nallows us to model arbitrarily long sequences in a parallel manner, within a\\nsingle operation, and without relying on any form of recurrence. We show that\\nContinuous Kernel Convolutional Networks (CKCNNs) obtain state-of-the-art\\nresults in multiple datasets, e.g., permuted MNIST, and, thanks to their\\ncontinuous nature, are able to handle non-uniformly sampled datasets and\\nirregularly-sampled data natively. CKCNNs match or perform better than neural\\nODEs designed for these purposes in a much faster and simpler manner.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02611'}, {'title': 'Parabolic optimal control with strongly monotone quasilinearity and its time discretization. (arXiv:2102.02616v1 [math.OC])', 'description': '<p>In this paper we discuss the optimal control of a quasilinear parabolic state\\nequation. Its form is leaned on the kind of problems arising for example when\\ncontrolling the anisotropic Allen-Cahn equation as a model for crystal growth.\\nMotivated by this application we consider the state equation as a result of a\\ngradient flow of an energy functional. The quasilinear term is strongly\\nmonotone and obeys a certain growth condition. The state equation is\\ndiscretized implicitly in time with piecewise constant functions. The existence\\nof the control-to-state operator and its Lipschitz-continuity is shown for the\\ntime discretized as well as for the time continuous problem. Latter is based on\\nthe convergence proof of the discretized solutions. Finally we present for both\\nthe existence of global minimizers. When the target function is given over the\\nwhole time horizon also convergence of a subsequence of time discrete optimal\\ncontrols to a global minimizer of the time continuous problem can be shown. Our\\nresults hold in arbitrary space dimensions.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02616'}, {'title': 'A Deep Collocation Method for the Bending Analysis of Kirchhoff Plate. (arXiv:2102.02617v1 [math.NA])', 'description': '<p>In this paper, a deep collocation method (DCM) for thin plate bending\\nproblems is proposed. This method takes advantage of computational graphs and\\nbackpropagation algorithms involved in deep learning. Besides, the proposed DCM\\nis based on a feedforward deep neural network (DNN) and differs from most\\nprevious applications of deep learning for mechanical problems. First, batches\\nof randomly distributed collocation points are initially generated inside the\\ndomain and along the boundaries. A loss function is built with the aim that the\\ngoverning partial differential equations (PDEs) of Kirchhoff plate bending\\nproblems, and the boundary/initial conditions are minimised at those\\ncollocation points. A combination of optimizers is adopted in the\\nbackpropagation process to minimize the loss function so as to obtain the\\noptimal hyperparameters. In Kirchhoff plate bending problems, the C1 continuity\\nrequirement poses significant difficulties in traditional mesh-based methods.\\nThis can be solved by the proposed DCM, which uses a deep neural network to\\napproximate the continuous transversal deflection, and is proved to be suitable\\nto the bending analysis of Kirchhoff plate of various geometries.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02617'}, {'title': 'Optimised one-class classification performance. (arXiv:2102.02618v1 [cs.LG])', 'description': '<p>We provide a thorough treatment of hyperparameter optimisation for three data\\ndescriptors with a good track-record in the literature: Support Vector Machine\\n(SVM), Nearest Neighbour Distance (NND) and Average Localised Proximity (ALP).\\nThe hyperparameters of SVM have to be optimised through cross-validation, while\\nNND and ALP allow the reuse of a single nearest-neighbour query and an\\nefficient form of leave-one-out validation. We experimentally evaluate the\\neffect of hyperparameter optimisation with 246 classification problems drawn\\nfrom 50 datasets. From a selection of optimisation algorithms, the recent\\nMalherbe-Powell proposal optimises the hyperparameters of all three data\\ndescriptors most efficiently. We calculate the increase in test AUROC and the\\namount of overfitting as a function of the number of hyperparameter\\nevaluations. After 50 evaluations, ALP and SVM both significantly outperform\\nNND. The performance of ALP and SVM is comparable, but ALP can be optimised\\nmore efficiently, while a choice between ALP and SVM based on validation AUROC\\ngives the best overall result. This distils the many variables of one-class\\nclassification with hyperparameter optimisation down to a clear choice with a\\nknown trade-off, allowing practitioners to make informed decisions.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02618'}, {'title': 'Electricity-gas integrated energy system optimal operation in typical scenario of coal district considering hydrogen heavy trucks. (arXiv:2102.02620v1 [eess.SY])', 'description': '<p>The coal industry contributes significantly to the social economy, but the\\nemission of greenhouse gases puts huge pressure on the environment in the\\nprocess of mining, transportation, and power generation. In the integrated\\nenergy system (IES), the current research about the power-to-gas (P2G)\\ntechnology mainly focuses on the injection of hydrogen generated from renewable\\nenergy electrolyzed water into natural gas pipelines, which may cause hydrogen\\nembrittlement of the pipeline and cannot be repaired. In this paper,\\nconsidering the scenario of coal districts is rich in coal and renewable\\nenergy, and sufficient hydrogen energy can be produced through P2G technology\\nand coal-to-hydrogen (C2H) of coal gasification. In order to transport the\\nmined coal to the destination, hydrogen heavy trucks have a broad space for\\ndevelopment, which can absorb hydrogen energy in time and avoid potentially\\ndangerous hydrogen injection into pipelines and relatively expensive hydrogen\\nstorage. An optimized scheduling model of electric-gas IES is proposed based on\\nsecond-order cone programming (SOCP). In the model proposed above, the closed\\nindustrial loop between coal mining, hydrogen production, truck transportation\\nof coal, and integrated energy systems has been innovatively studied, to\\nconsume renewable energy and coordinate multi-energy. Finally, an electric-gas\\nIES study case constructed by IEEE 30-node power system and Belgium 24-node\\nnatural gas network was used to analyze and verify the economy, low carbon, and\\neffectiveness of the proposed mechanism.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02620'}, {'title': 'Cryptocurrency Solutions to Enable Micro-payments in Consumer IoT. (arXiv:2102.02623v1 [cs.CR])', 'description': '<p>The successful amalgamation of cryptocurrency and consumer Internet of Things\\n(IoT) devices can pave the way for novel applications in machine-to-machine\\neconomy. However, the lack of scalability and heavy resource requirements of\\ninitial blockchain designs hinders the integration as they prioritized\\ndecentralization and security. Numerous solutions have been proposed since the\\nemergence of Bitcoin to achieve this goal. However, none of them seem to\\ndominate and thus it is unclear how consumer devices will be adopting these\\napproaches. Therefore, in this paper, we critically review the existing\\nintegration approaches and cryptocurrency designs that strive to enable\\nmicro-payments among consumer devices. We identify and discuss solutions under\\nthree main categories; direct integration, payment channel network and new\\ncryptocurrency design. The first approach utilizes a full node to interact with\\nthe payment system. Offline channel payment is suggested as a second layer\\nsolution to solve the scalability issue and enable instant payment with low\\nfee. New designs converge to semi-centralized scheme and focuson lightweight\\nconsensus protocol that does not require highcomputation power which might mean\\nloosening the initial designchoices in favor of scalability. We evaluate the\\npros and cons ofeach of these approaches and then point out future\\nresearchchallenges. Our goal is to help researchers and practitioners tobetter\\nfocus their efforts to facilitate micro-payment adoptions.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02623'}, {'title': 'The #ETH is False, #k-SAT is in Sub-Exponential Time. (arXiv:2102.02624v1 [cs.CC])', 'description': '<p>We orchestrate a randomized algorithm for #$k$-SAT which counts the exact\\nnumber of satisfying assignments in $2^{o(n)}$ time. The existence of such\\nalgorithm signifies that the #ETH is hereby refuted, and so are $\\\\oplus$ETH,\\nETH, #SETH, $\\\\oplus$SETH and SETH.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02624'}, {'title': 'Safety Case Templates for Autonomous Systems. (arXiv:2102.02625v1 [cs.SE])', 'description': '<p>This report documents safety assurance argument templates to support the\\ndeployment and operation of autonomous systems that include machine learning\\n(ML) components. The document presents example safety argument templates\\ncovering: the development of safety requirements, hazard analysis, a safety\\nmonitor architecture for an autonomous system including at least one ML\\nelement, a component with ML and the adaptation and change of the system over\\ntime. The report also presents generic templates for argument defeaters and\\nevidence confidence that can be used to strengthen, review, and adapt the\\ntemplates as necessary. This Interim Report is made available to get feedback\\non the approach and on the templates. This work is being sponsored by the UK\\nDstl under the R-cloud framework.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02625'}, {'title': 'Formalising a Turing-Complete Choreographic Language in Coq. (arXiv:2102.02627v1 [cs.LO])', 'description': \"<p>Theory of choreographic languages typically includes a number of complex\\nresults that are proved by structural induction. The high number of cases and\\nthe subtle details in some of them lead to long reviewing processes, and\\noccasionally to errors being found in published proofs. In this work, we take a\\npublished proof of Turing completeness of a choreographic language and\\nformalise it in Coq. Our development includes formalising the choreographic\\nlanguage and its basic properties, Kleene's theory of partial recursive\\nfunctions, the encoding of these functions as choreographies, and proving this\\nencoding correct.\\n</p>\\n<p>With this effort, we show that theorem proving can be a very useful tool in\\nthe field of choreographic languages: besides the added degree of confidence\\nthat we get from a mechanised proof, the formalisation process led us to a\\nsignificant simplification of the underlying theory. Our results offer a\\nfoundation for the future formal development of choreographic languages.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02627'}, {'title': 'Learning Monocular Depth in Dynamic Scenes via Instance-Aware Projection Consistency. (arXiv:2102.02629v1 [cs.CV])', 'description': '<p>We present an end-to-end joint training framework that explicitly models\\n6-DoF motion of multiple dynamic objects, ego-motion and depth in a monocular\\ncamera setup without supervision. Our technical contributions are three-fold.\\nFirst, we highlight the fundamental difference between inverse and forward\\nprojection while modeling the individual motion of each rigid object, and\\npropose a geometrically correct projection pipeline using a neural forward\\nprojection module. Second, we design a unified instance-aware photometric and\\ngeometric consistency loss that holistically imposes self-supervisory signals\\nfor every background and object region. Lastly, we introduce a general-purpose\\nauto-annotation scheme using any off-the-shelf instance segmentation and\\noptical flow models to produce video instance segmentation maps that will be\\nutilized as input to our training pipeline. These proposed elements are\\nvalidated in a detailed ablation study. Through extensive experiments conducted\\non the KITTI and Cityscapes dataset, our framework is shown to outperform the\\nstate-of-the-art depth and motion estimation methods. Our code, dataset, and\\nmodels are available at https://github.com/SeokjuLee/Insta-DM .\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02629'}, {'title': 'Universal Approximation Theorems of Fully Connected Binarized Neural Networks. (arXiv:2102.02631v1 [cs.LG])', 'description': '<p>Neural networks (NNs) are known for their high predictive accuracy in complex\\nlearning problems. Beside practical advantages, NNs also indicate favourable\\ntheoretical properties such as universal approximation (UA) theorems. Binarized\\nNeural Networks (BNNs) significantly reduce time and memory demands by\\nrestricting the weight and activation domains to two values. Despite the\\npractical advantages, theoretical guarantees based on UA theorems of BNNs are\\nrather sparse in the literature. We close this gap by providing UA theorems for\\nfully connected BNNs under the following scenarios: (1) for binarized inputs,\\nUA can be constructively achieved under one hidden layer; (2) for inputs with\\nreal numbers, UA can not be achieved under one hidden layer but can be\\nconstructively achieved under two hidden layers for Lipschitz-continuous\\nfunctions. Our results indicate that fully connected BNNs can approximate\\nfunctions universally, under certain conditions.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02631'}, {'title': 'Optimal Trajectories of a UAV Base Station Using Hamilton-Jacobi Equations. (arXiv:2102.02632v1 [math.OC])', 'description': '<p>We consider the problem of optimizing the trajectory of an Unmanned Aerial\\nVehicle (UAV). Assuming a traffic intensity map of users to be served, the UAV\\nmust travel from a given initial location to a final position within a given\\nduration and serves the traffic on its way. The problem consists in finding the\\noptimal trajectory that minimizes a certain cost depending on the velocity and\\non the amount of served traffic. We formulate the problem using the framework\\nof Lagrangian mechanics. We derive closed-form formulas for the optimal\\ntrajectory when the traffic intensity is quadratic (single-phase) using\\nHamilton-Jacobi equations. When the traffic intensity is bi-phase, i.e. made of\\ntwo quadratics, we provide necessary conditions of optimality that allow us to\\npropose a gradient-based algorithm and a new algorithm based on the linear\\ncontrol properties of the quadratic model. These two solutions are of very low\\ncomplexity because they rely on fast convergence numerical schemes and closed\\nform formulas. These two approaches return a trajectory satisfying the\\nnecessary conditions of optimality. At last, we propose a data processing\\nprocedure based on a modified K-means algorithm to derive a bi-phase model and\\nan optimal trajectory simulation from real traffic data.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02632'}, {'title': 'Deep Autoencoder-based Fuzzy C-Means for Topic Detection. (arXiv:2102.02636v1 [cs.IR])', 'description': \"<p>Topic detection is a process for determining topics from a collection of\\ntextual data. One of the topic detection methods is a clustering-based method,\\nwhich assumes that the centroids are topics. The clustering method has the\\nadvantage that it can process data with negative representations. Therefore,\\nthe clustering method allows a combination with a broader representation\\nlearning method. In this paper, we adopt deep learning for topic detection by\\nusing a deep autoencoder and fuzzy c-means called deep autoencoder-based fuzzy\\nc-means (DFCM). The encoder of the autoencoder performs a lower-dimensional\\nrepresentation learning. Fuzzy c-means groups the lower-dimensional\\nrepresentation to identify the centroids. The autoencoder's decoder transforms\\nback the centroids into the original representation to be interpreted as the\\ntopics. Our simulation shows that DFCM improves the coherence score of\\neigenspace-based fuzzy c-means (EFCM) and is comparable to the leading standard\\nmethods, i.e., nonnegative matrix factorization (NMF) or latent Dirichlet\\nallocation (LDA).\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02636'}, {'title': 'Big Data Analytics Applying the Fusion Approach of Multicriteria Decision Making with Deep Learning Algorithms. (arXiv:2102.02637v1 [cs.LG])', 'description': \"<p>Data is evolving with the rapid progress of population and communication for\\nvarious types of devices such as networks, cloud computing, Internet of Things\\n(IoT), actuators, and sensors. The increment of data and communication content\\ngoes with the equivalence of velocity, speed, size, and value to provide the\\nuseful and meaningful knowledge that helps to solve the future challenging\\ntasks and latest issues. Besides, multicriteria based decision making is one of\\nthe key issues to solve for various issues related to the alternative effects\\nin big data analysis. It tends to find a solution based on the latest machine\\nlearning techniques that include algorithms like decision making and deep\\nlearning mechanism based on multicriteria in providing insights to big data. On\\nthe other hand, the derivations are made for it to go with the approximations\\nto increase the duality of runtime and improve the entire system's potentiality\\nand efficacy. In essence, several fields, including business, agriculture,\\ninformation technology, and computer science, use deep learning and\\nmulticriteria-based decision-making problems. This paper aims to provide\\nvarious applications that involve the concepts of deep learning techniques and\\nexploiting the multicriteria approaches for issues that are facing in big data\\nanalytics by proposing new studies with the fusion approaches of data-driven\\ntechniques.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02637'}, {'title': 'Autodidactic Neurosurgeon: Collaborative Deep Inference for Mobile Edge Intelligence via Online Learning. (arXiv:2102.02638v1 [cs.LG])', 'description': '<p>Recent breakthroughs in deep learning (DL) have led to the emergence of many\\nintelligent mobile applications and services, but in the meanwhile also pose\\nunprecedented computing challenges on resource-constrained mobile devices. This\\npaper builds a collaborative deep inference system between a\\nresource-constrained mobile device and a powerful edge server, aiming at\\njoining the power of both on-device processing and computation offloading. The\\nbasic idea of this system is to partition a deep neural network (DNN) into a\\nfront-end part running on the mobile device and a back-end part running on the\\nedge server, with the key challenge being how to locate the optimal partition\\npoint to minimize the end-to-end inference delay. Unlike existing efforts on\\nDNN partitioning that rely heavily on a dedicated offline profiling stage to\\nsearch for the optimal partition point, our system has a built-in online\\nlearning module, called Autodidactic Neurosurgeon (ANS), to automatically learn\\nthe optimal partition point on-the-fly. Therefore, ANS is able to closely\\nfollow the changes of the system environment by generating new knowledge for\\nadaptive decision making. The core of ANS is a novel contextual bandit learning\\nalgorithm, called $\\\\mu$LinUCB, which not only has provable theoretical learning\\nperformance guarantee but also is ultra-lightweight for easy real-world\\nimplementation. We implement our system on a video stream object detection\\ntestbed to validate the design of ANS and evaluate its performance. The\\nexperiments show that ANS significantly outperforms state-of-the-art benchmarks\\nin terms of tracking system changes and reducing the end-to-end inference\\ndelay.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02638'}, {'title': 'Improving Reinforcement Learning with Human Assistance: An Argument for Human Subject Studies with HIPPO Gym. (arXiv:2102.02639v1 [cs.LG])', 'description': '<p>Reinforcement learning (RL) is a popular machine learning paradigm for game\\nplaying, robotics control, and other sequential decision tasks. However, RL\\nagents often have long learning times with high data requirements because they\\nbegin by acting randomly. In order to better learn in complex tasks, this\\narticle argues that an external teacher can often significantly help the RL\\nagent learn.\\n</p>\\n<p>OpenAI Gym is a common framework for RL research, including a large number of\\nstandard environments and agents, making RL research significantly more\\naccessible. This article introduces our new open-source RL framework, the Human\\nInput Parsing Platform for Openai Gym (HIPPO Gym), and the design decisions\\nthat went into its creation. The goal of this platform is to facilitate\\nhuman-RL research, again lowering the bar so that more researchers can quickly\\ninvestigate different ways that human teachers could assist RL agents,\\nincluding learning from demonstrations, learning from feedback, or curriculum\\nlearning.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02639'}, {'title': 'Low Bit-Rate Wideband Speech Coding: A Deep Generative Model based Approach. (arXiv:2102.02640v1 [cs.SD])', 'description': '<p>Traditional low bit-rate speech coding approach only handles narrowband\\nspeech at 8kHz, which limits further improvements in speech quality. Motivated\\nby recent successful exploration of deep learning methods for image and speech\\ncompression, this paper presents a new approach through vector quantization\\n(VQ) of mel-frequency cepstral coefficients (MFCCs) and using a deep generative\\nmodel called WaveGlow to provide efficient and high-quality speech coding. The\\ncoding feature is sorely an 80-dimension MFCCs vector for 16kHz wideband\\nspeech, then speech coding at the bit-rate throughout 1000-2000 bit/s could be\\nscalably implemented by applying different VQ schemes for MFCCs vector. This\\nnew deep generative network based codec works fast as the WaveGlow model\\nabandons the sample-by-sample autoregressive mechanism. We evaluated this new\\napproach over the multi-speaker TIMIT corpus, and experimental results\\ndemonstrate that it provides better speech quality compared with the\\nstate-of-the-art classic MELPe codec at lower bit-rate.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02640'}, {'title': 'Asymptotically Exact and Fast Gaussian Copula Models for Imputation of Mixed Data Types. (arXiv:2102.02642v1 [stat.ML])', 'description': '<p>Missing values with mixed data types is a common problem in a large number of\\nmachine learning applications such as processing of surveys and in different\\nmedical applications. Recently, Gaussian copula models have been suggested as a\\nmeans of performing imputation of missing values using a probabilistic\\nframework. While the present Gaussian copula models have shown to yield state\\nof the art performance, they have two limitations: they are based on an\\napproximation that is fast but may be imprecise and they do not support\\nunordered multinomial variables. We address the first limitation using direct\\nand arbitrarily precise approximations both for model estimation and imputation\\nby using randomized quasi-Monte Carlo procedures. The method we provide has\\nlower errors for the estimated model parameters and the imputed values,\\ncompared to previously proposed methods. We also extend the previous Gaussian\\ncopula models to include unordered multinomial variables in addition to the\\npresent support of ordinal, binary, and continuous variables.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02642'}, {'title': 'Pick the Right Edge Device: Towards Power and Performance Estimation of CUDA-based CNNs on GPGPUs. (arXiv:2102.02645v1 [cs.LG])', 'description': '<p>The emergence of Machine Learning (ML) as a powerful technique has been\\nhelping nearly all fields of business to increase operational efficiency or to\\ndevelop new value propositions. Besides the challenges of deploying and\\nmaintaining ML models, picking the right edge device (e.g., GPGPUs) to run\\nthese models (e.g., CNN with the massive computational process) is one of the\\nmost pressing challenges faced by organizations today. As the cost of renting\\n(on Cloud) or purchasing an edge device is directly connected to the cost of\\nfinal products or services, choosing the most efficient device is essential.\\nHowever, this decision making requires deep knowledge about performance and\\npower consumption of the ML models running on edge devices that must be\\nidentified at the early stage of ML workflow.\\n</p>\\n<p>In this paper, we present a novel ML-based approach that provides ML\\nengineers with the early estimation of both power consumption and performance\\nof CUDA-based CNNs on GPGPUs. The proposed approach empowers ML engineers to\\npick the most efficient GPGPU for a given CNN model at the early stage of\\ndevelopment.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02645'}, {'title': 'Towards a reinforcement learning de novo genome assembler. (arXiv:2102.02649v1 [q-bio.GN])', 'description': '<p>The use of reinforcement learning has proven to be very promising for solving\\ncomplex activities without human supervision during their learning process.\\nHowever, their successful applications are predominantly focused on fictional\\nand entertainment problems - such as games. Based on the above, this work aims\\nto shed light on the application of reinforcement learning to solve this\\nrelevant real-world problem, the genome assembly. By expanding the only\\napproach found in the literature that addresses this problem, we carefully\\nexplored the aspects of intelligent agent learning, performed by the Q-learning\\nalgorithm, to understand its suitability to be applied in scenarios whose\\ncharacteristics are more similar to those faced by real genome projects. The\\nimprovements proposed here include changing the previously proposed reward\\nsystem and including state space exploration optimization strategies based on\\ndynamic pruning and mutual collaboration with evolutionary computing. These\\ninvestigations were tried on 23 new environments with larger inputs than those\\nused previously. All these environments are freely available on the internet\\nfor the evolution of this research by the scientific community. The results\\nsuggest consistent performance progress using the proposed improvements,\\nhowever, they also demonstrate the limitations of them, especially related to\\nthe high dimensionality of state and action spaces. We also present, later, the\\npaths that can be traced to tackle genome assembly efficiently in real\\nscenarios considering recent, successfully reinforcement learning applications\\n- including deep reinforcement learning - from other domains dealing with\\nhigh-dimensional inputs.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02649'}, {'title': 'Triadic Exploration and Exploration with Multiple Experts. (arXiv:2102.02654v1 [cs.AI])', 'description': '<p>Formal Concept Analysis (FCA) provides a method called attribute exploration\\nwhich helps a domain expert discover structural dependencies in knowledge\\ndomains that can be represented by a formal context (a cross table of objects\\nand attributes). Triadic Concept Analysis is an extension of FCA that\\nincorporates the notion of conditions. Many extensions and variants of\\nattribute exploration have been studied but only few attempts at incorporating\\nmultiple experts have been made. In this paper we present triadic exploration\\nbased on Triadic Concept Analysis to explore conditional attribute implications\\nin a triadic domain. We then adapt this approach to formulate attribute\\nexploration with multiple experts that have different views on a domain.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02654'}, {'title': 'An Evaluation of Cryptocurrency Payment Channel Networks and Their Privacy Implications. (arXiv:2102.02659v1 [cs.CR])', 'description': \"<p>Cryptocurrencies redefined how money can be stored and transferred among\\nusers. However, independent of the amount being sent, public blockchain-based\\ncryptocurrencies suffer from high transaction waiting times and fees. These\\ndrawbacks hinder the wide use of cryptocurrencies by masses. To address these\\nchallenges, payment channel network concept is touted as the most viable\\nsolution to be used for micro-payments. The idea is exchanging the ownership of\\nmoney by keeping the state of the accounts locally. The users inform the\\nblockchain rarely, which decreases the load on the blockchain. Specifically,\\npayment channel networks can provide transaction approvals in seconds by\\ncharging a nominal fee proportional to the payment amount. Such attraction on\\npayment channel networks inspired many recent studies which focus on how to\\ndesign them and allocate channels such that the transactions will be secure and\\nefficient. However, as payment channel networks are emerging and reaching large\\nnumber of users, privacy issues are becoming more relevant that raise concerns\\nabout exposing not only individual habits but also businesses' revenues. In\\nthis paper, we first propose a categorization of the existing payment networks\\nformed on top of blockchain-backed cryptocurrencies. After discussing several\\nemerging attacks on user/business privacy in these payment channel networks, we\\nqualitatively evaluate them based on a number of privacy metrics that relate to\\nour case. Based on the discussions on the strengths and weaknesses of the\\napproaches, we offer possible directions for research for the future of privacy\\nbased payment channel networks.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02659'}, {'title': 'No-reference denoising of low-dose CT projections. (arXiv:2102.02662v1 [eess.IV])', 'description': '<p>Low-dose computed tomography (LDCT) became a clear trend in radiology with an\\naspiration to refrain from delivering excessive X-ray radiation to the\\npatients. The reduction of the radiation dose decreases the risks to the\\npatients but raises the noise level, affecting the quality of the images and\\ntheir ultimate diagnostic value. One mitigation option is to consider pairs of\\nlow-dose and high-dose CT projections to train a denoising model using deep\\nlearning algorithms; however, such pairs are rarely available in practice. In\\nthis paper, we present a new self-supervised method for CT denoising. Unlike\\nexisting self-supervised approaches, the proposed method requires only noisy CT\\nprojections and exploits the connections between adjacent images. The\\nexperiments carried out on an LDCT dataset demonstrate that our method is\\nalmost as accurate as the supervised approach, while also outperforming the\\nconsidered self-supervised denoising methods.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02662'}, {'title': 'Digital twins based on bidirectional LSTM and GAN for modelling COVID-19. (arXiv:2102.02664v1 [cs.LG])', 'description': '<p>The outbreak of the coronavirus disease 2019 (COVID-19) has now spread\\nthroughout the globe infecting over 100 million people and causing the death of\\nover 2.2 million people. Thus, there is an urgent need to study the dynamics of\\nepidemiological models to gain a better understanding of how such diseases\\nspread. While epidemiological models can be computationally expensive, recent\\nadvances in machine learning techniques have given rise to neural networks with\\nthe ability to learn and predict complex dynamics at reduced computational\\ncosts. Here we introduce two digital twins of a SEIRS model applied to an\\nidealised town. The SEIRS model has been modified to take account of spatial\\nvariation and, where possible, the model parameters are based on official virus\\nspreading data from the UK. We compare predictions from a data-corrected\\nBidirectional Long Short-Term Memory network and a predictive Generative\\nAdversarial Network. The predictions given by these two frameworks are accurate\\nwhen compared to the original SEIRS model data. Additionally, these frameworks\\nare data-agnostic and could be applied to towns, idealised or real, in the UK\\nor in other countries. Also, more compartments could be included in the SEIRS\\nmodel, in order to study more realistic epidemiological behaviour.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02664'}, {'title': 'Hybrid consistency and plausibility verification of product data according to FIC. (arXiv:2102.02665v1 [cs.LG])', 'description': \"<p>The labelling of food products in the EU is regulated by the Food Information\\nof Customers (FIC). Companies are required to provide the corresponding\\ninformation regarding nutrients and allergens among others. With the rise of\\ne-commerce more and more food products are sold online. There are often errors\\nin the online product descriptions regarding the FIC-relevant information due\\nto low data quality in the vendors' product data base. In this paper we propose\\na hybrid approach of both rule-based and machine learning to verify nutrient\\ndeclaration and allergen labelling according to FIC requirements. Special focus\\nis given to the problem of false negatives in allergen prediction since this\\nposes a significant health risk to customers. Results show that a neural net\\ntrained on a subset of the ingredients of a product is capable of predicting\\nthe allergens contained with a high reliability.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02665'}, {'title': 'The Wisdom of the Crowd and Higher-Order Beliefs. (arXiv:2102.02666v1 [econ.TH])', 'description': '<p>The classic wisdom-of-the-crowd problem asks how a principal can \"aggregate\"\\ninformation about the unknown state of the world from agents without\\nunderstanding the information structure among them. We propose a new simple\\nprocedure \"\\\\emph{population mean based aggregation}\" to achieve this goal. It\\nonly requires eliciting agents\\' beliefs about the state, and also eliciting\\nsome agents\\' expectations of the average belief in the population. We show that\\nthis procedure fully aggregates information: in an infinite population, it\\nalways infers the true state of the world. The procedure can accommodate\\ncorrelation in agents\\' information, misspecified beliefs, any finite number of\\npossible states of the world, and only requires very weak assumptions on the\\ninformation structure.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02666'}, {'title': 'Disease Prediction with a Maximum Entropy Method. (arXiv:2102.02668v1 [cs.LG])', 'description': \"<p>In this paper, we propose a maximum entropy method for predicting disease\\nrisks. It is based on a patient's medical history with diseases coded in ICD-10\\nwhich can be used in various cases. The complete algorithm with strict\\nmathematical derivation is given. We also present experimental results on a\\nmedical dataset, demonstrating that our method performs well in predicting\\nfuture disease risks and achieves an accuracy rate twice that of the\\ntraditional method. We also perform a comorbidity analysis to reveal the\\nintrinsic relation of diseases.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02668'}, {'title': 'OmiEmbed: reconstruct comprehensive phenotypic information from multi-omics data using multi-task deep learning. (arXiv:2102.02669v1 [q-bio.GN])', 'description': '<p>High-dimensional omics data contains intrinsic biomedical information that is\\ncrucial for personalised medicine. Nevertheless, it is challenging to capture\\nthem from the genome-wide data due to the large number of molecular features\\nand small number of available samples, which is also called \"the curse of\\ndimensionality\" in machine learning. To tackle this problem and pave the way\\nfor machine learning aided precision medicine, we proposed a unified multi-task\\ndeep learning framework called OmiEmbed to capture a holistic and relatively\\nprecise profile of phenotype from high-dimensional omics data. The deep\\nembedding module of OmiEmbed learnt an omics embedding that mapped multiple\\nomics data types into a latent space with lower dimensionality. Based on the\\nnew representation of multi-omics data, different downstream networks of\\nOmiEmbed were trained together with the multi-task strategy to predict the\\ncomprehensive phenotype profile of each sample. We trained the model on two\\npublicly available omics datasets to evaluate the performance of OmiEmbed. The\\nOmiEmbed model achieved promising results for multiple downstream tasks\\nincluding dimensionality reduction, tumour type classification, multi-omics\\nintegration, demographic and clinical feature reconstruction, and survival\\nprediction. Instead of training and applying different downstream networks\\nseparately, the multi-task strategy combined them together and conducted\\nmultiple tasks simultaneously and efficiently. The model achieved better\\nperformance with the multi-task strategy comparing to training them\\nindividually. OmiEmbed is a powerful tool to accurately capture comprehensive\\nphenotypic information from high-dimensional omics data and has a great\\npotential to facilitate more accurate and personalised clinical decision\\nmaking.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02669'}, {'title': 'Multimodal-Aware Weakly Supervised Metric Learning with Self-weighting Triplet Loss. (arXiv:2102.02670v1 [cs.LG])', 'description': '<p>In recent years, we have witnessed a surge of interests in learning a\\nsuitable distance metric from weakly supervised data. Most existing methods aim\\nto pull all the similar samples closer while push the dissimilar ones as far as\\npossible. However, when some classes of the dataset exhibit multimodal\\ndistribution, these goals conflict and thus can hardly be concurrently\\nsatisfied. Additionally, to ensure a valid metric, many methods require a\\nrepeated eigenvalue decomposition process, which is expensive and numerically\\nunstable. Therefore, how to learn an appropriate distance metric from weakly\\nsupervised data remains an open but challenging problem. To address this issue,\\nin this paper, we propose a novel weakly supervised metric learning algorithm,\\nnamed MultimoDal Aware weakly supervised Metric Learning (MDaML). MDaML\\npartitions the data space into several clusters and allocates the local cluster\\ncenters and weight for each sample. Then, combining it with the weighted\\ntriplet loss can further enhance the local separability, which encourages the\\nlocal dissimilar samples to keep a large distance from the local similar\\nsamples. Meanwhile, MDaML casts the metric learning problem into an\\nunconstrained optimization on the SPD manifold, which can be efficiently solved\\nby Riemannian Conjugate Gradient Descent (RCGD). Extensive experiments\\nconducted on 13 datasets validate the superiority of the proposed MDaML.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02670'}, {'title': 'Directive Explanations for Actionable Explainability in Machine Learning Applications. (arXiv:2102.02671v1 [cs.LG])', 'description': \"<p>This paper investigates the prospects of using directive explanations to\\nassist people in achieving recourse of machine learning decisions. Directive\\nexplanations list which specific actions an individual needs to take to achieve\\ntheir desired outcome. If a machine learning model makes a decision that is\\ndetrimental to an individual (e.g. denying a loan application), then it needs\\nto both explain why it made that decision and also explain how the individual\\ncould obtain their desired outcome (if possible). At present, this is often\\ndone using counterfactual explanations, but such explanations generally do not\\ntell individuals how to act. We assert that counterfactual explanations can be\\nimproved by explicitly providing people with actions they could use to achieve\\ntheir desired goal. This paper makes two contributions. First, we present the\\nresults of an online study investigating people's perception of directive\\nexplanations. Second, we propose a conceptual model to generate such\\nexplanations. Our online study showed a significant preference for directive\\nexplanations ($p&lt;0.001$). However, the participants' preferred explanation type\\nwas affected by multiple factors, such as individual preferences, social\\nfactors, and the feasibility of the directives. Our findings highlight the need\\nfor a human-centred and context-specific approach for creating directive\\nexplanations.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02671'}, {'title': 'DNN Based Beam Selection in mmW Heterogeneous Networks. (arXiv:2102.02672v1 [cs.NI])', 'description': '<p>We consider a heterogeneous cellular network wherein multiple small cell\\nmillimeter wave (mmW) base stations (BSs) coexist with legacy sub-6GHz macro\\nBSs. In the mmW band, small cells use multiple narrow beams to ensure\\nsufficient coverage and User Equipments (UEs) have to select the best small\\ncell and the best beam in order to access the network. This process usually\\nbased on exhaustive search may introduce unacceptable latency. In order to\\naddress this issue, we rely on the sub-6GHz macro BS support and propose a deep\\nneural network (DNN) architecture that utilizes basic components from the\\nChannel State Information (CSI) of sub-6GHz network as input features. The\\noutput of the DNN is the mmW BS and beam selection that can provide the best\\ncommunication performance. In the set of features, we avoid using the UE\\nlocation, which may not be readily available for every device. We formulate a\\nmmW BS selection and beam selection problem as a classification and regression\\nproblem respectively and propose a joint solution using a branched neural\\nnetwork. The numerical comparison with the conventional exhaustive search\\nresults shows that the proposed design demonstrate better performance than\\nexhaustive search in terms of latency with at least 85\\\\% accuracy.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02672'}, {'title': 'Continuous Random Variable Estimation is not Optimal for the Witsenhausen Counterexample. (arXiv:2102.02673v1 [cs.IT])', 'description': '<p>Optimal design of distributed decision policies can be a difficult task,\\nillustrated by the famous Witsenhausen counterexample. In this paper we\\ncharacterize the optimal control designs for the vector-valued setting assuming\\nthat it results in an internal state that can be described by a continuous\\nrandom variable which has a probability density function. More specifically, we\\nprovide a genie-aided outer bound that relies on our previous results for\\nempirical coordination problems. This solution turns out to be not optimal in\\ngeneral, since it consists of a time-sharing strategy between two linear\\nschemes of specific power. It follows that the optimal decision strategy for\\nthe original scalar Witsenhausen problem must lead to an internal state that\\ncannot be described by a continuous random variable which has a probability\\ndensity function.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02673'}, {'title': 'Observability of the relative motion from inertial data in kinematic chains. (arXiv:2102.02675v1 [eess.SY])', 'description': '<p>In recent years, it has been shown that the motion of kinematic chains can be\\nestimated using measurements from inertial sensors placed on segments connected\\nby rotational joints. These methods specifically avoid using magnetometer\\nmeasurements, which are known to cause issues since the magnetic field at the\\ndifferent sensor locations is typically different. They rely on the assumption\\nthat the motion of the kinematic chain is sufficiently rich to assure / yield\\nobservability of the relative pose. However, a formal investigation of this\\ncrucial requirement has not yet been presented and no specific conditions for\\nobservability have so far been given. In this work, we present an observability\\nanalysis and show that the relative pose of the body segments is indeed\\nobservable under a very mild condition on the motion. We support these results\\nby a simulation study, in which we also show the effect of stationary periods\\nin the data and of the amount of excitation on the accuracy of the estimates.\\nWe use experimental data from a human gait experiment to show that the\\nexcitation level is sufficient for obtaining accurate estimates even when the\\nsubject remains stationary for a period of 47 seconds halfway during the\\nexperiment.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02675'}, {'title': 'Certifying Differential Equation Solutions from Computer Algebra Systems in Isabelle/HOL. (arXiv:2102.02679v1 [cs.LO])', 'description': '<p>The Isabelle/HOL proof assistant has a powerful library for continuous\\nanalysis, which provides the foundation for verification of hybrid systems.\\nHowever, Isabelle lacks automated proof support for continuous artifacts, which\\nmeans that verification is often manual. In contrast, Computer Algebra Systems\\n(CAS), such as Mathematica and SageMath, contain a wealth of efficient\\nalgorithms for matrices, differential equations, and other related artifacts.\\nNevertheless, these algorithms are not verified, and thus their outputs cannot,\\nof themselves, be trusted for use in a safety critical system. In this paper we\\nintegrate two CAS systems into Isabelle, with the aim of certifying symbolic\\nsolutions to ordinary differential equations. This supports a verification\\ntechnique that is both automated and trustworthy.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02679'}, {'title': 'Hierarchical Multi-head Attentive Network for Evidence-aware Fake News Detection. (arXiv:2102.02680v1 [cs.AI])', 'description': '<p>The widespread of fake news and misinformation in various domains ranging\\nfrom politics, economics to public health has posed an urgent need to\\nautomatically fact-check information. A recent trend in fake news detection is\\nto utilize evidence from external sources. However, existing evidence-aware\\nfake news detection methods focused on either only word-level attention or\\nevidence-level attention, which may result in suboptimal performance. In this\\npaper, we propose a Hierarchical Multi-head Attentive Network to fact-check\\ntextual claims. Our model jointly combines multi-head word-level attention and\\nmulti-head document-level attention, which aid explanation in both word-level\\nand evidence-level. Experiments on two real-word datasets show that our model\\noutperforms seven state-of-the-art baselines. Improvements over baselines are\\nfrom 6\\\\% to 18\\\\%. Our source code and datasets are released at\\n\\\\texttt{\\\\url{https://github.com/nguyenvo09/EACL2021}}.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02680'}, {'title': 'Force-Directed Layout of Order Diagrams using Dimensional Reduction. (arXiv:2102.02684v1 [cs.CG])', 'description': '<p>Order diagrams allow human analysts to understand and analyze structural\\nproperties of ordered data. While an experienced expert can create easily\\nreadable order diagrams, the automatic generation of those remains a hard task.\\nIn this work, we adapt force-directed approaches, which are known to generate\\naesthetically-pleasing drawings of graphs, to the realm of order diagrams. Our\\nalgorithm ReDraw thereby embeds the order in a high dimension and then\\niteratively reduces the dimension until a two-dimensional drawing is achieved.\\nTo improve aesthetics, this reduction is equipped with two force-directed steps\\nwhere one optimizes on distances of nodes and the other on distances of lines\\nin order to satisfy a set of a priori fixed conditions. By respecting an\\ninvariant about the vertical position of the elements in each step of our\\nalgorithm we ensure that the resulting drawings satisfy all necessary\\nproperties of order diagrams. Finally, we present the results of a user study\\nto demonstrate that our algorithm outperforms comparable approaches on drawings\\nof lattices with a high degree of distributivity.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02684'}, {'title': 'Impossibility of Partial Recovery in the Graph Alignment Problem. (arXiv:2102.02685v1 [stat.ML])', 'description': '<p>Random graph alignment refers to recovering the underlying vertex\\ncorrespondence between two random graphs with correlated edges. This can be\\nviewed as an average-case and noisy version of the well-known NP-hard graph\\nisomorphism problem. For the correlated Erd\\\\\"os-R\\\\\\'enyi model, we prove an\\nimpossibility result for partial recovery in the sparse regime, with constant\\naverage degree and correlation, as well as a general bound on the maximal\\nreachable overlap. Our bound is tight in the noiseless case (the graph\\nisomorphism problem) and we conjecture that it is still tight with noise. Our\\nproof technique relies on a careful application of the probabilistic method to\\nbuild automorphisms between tree components of a subcritical Erd\\\\\"os-R\\\\\\'enyi\\ngraph.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02685'}, {'title': 'TricycleGAN: Unsupervised Image Synthesis and Segmentation Based on Shape Priors. (arXiv:2102.02690v1 [eess.IV])', 'description': '<p>Medical image segmentation is routinely performed to isolate regions of\\ninterest, such as organs and lesions. Currently, deep learning is the state of\\nthe art for automatic segmentation, but is usually limited by the need for\\nsupervised training with large datasets that have been manually segmented by\\ntrained clinicians. The goal of semi-superised and unsupervised image\\nsegmentation is to greatly reduce, or even eliminate, the need for training\\ndata and therefore to minimze the burden on clinicians when training\\nsegmentation models. To this end we introduce a novel network architecture for\\ncapable of unsupervised and semi-supervised image segmentation called\\nTricycleGAN. This approach uses three generative models to learn translations\\nbetween medical images and segmentation maps using edge maps as an intermediate\\nstep. Distinct from other approaches based on generative networks, TricycleGAN\\nrelies on shape priors rather than colour and texture priors. As such, it is\\nparticularly well-suited for several domains of medical imaging, such as\\nultrasound imaging, where commonly used visual cues may be absent. We present\\nexperiments with TricycleGAN on a clinical dataset of kidney ultrasound images\\nand the benchmark ISIC 2018 skin lesion dataset.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02690'}, {'title': 'HMC, an Algorithms in Data Mining, the Functional Analysis approach. (arXiv:2102.02691v1 [stat.CO])', 'description': '<p>The main purpose of this paper is to facilitate the communication between the\\nAnalytic, Probabilistic and Algorithmic communities.\\n</p>\\n<p>We present a proof of convergence of the Hamiltonian (Hybrid) Monte Carlo\\nalgorithm from the point of view of the\\n</p>\\n<p>Dynamical Systems, where the evolving objects are densities of probability\\ndistributions and the tool are derived from the Functional Analysis.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02691'}, {'title': 'Invertible DenseNets with Concatenated LipSwish. (arXiv:2102.02694v1 [stat.ML])', 'description': '<p>We introduce Invertible Dense Networks (i-DenseNets), a more parameter\\nefficient alternative to Residual Flows. The method relies on an analysis of\\nthe Lipschitz continuity of the concatenation in DenseNets, where we enforce\\ninvertibility of the network by satisfying the Lipschitz constant. We extend\\nthis method by proposing a learnable concatenation, which not only improves the\\nmodel performance but also indicates the importance of the concatenated\\nrepresentation. Additionally, we introduce the Concatenated LipSwish as\\nactivation function, for which we show how to enforce the Lipschitz condition\\nand which boosts performance. The new architecture, i-DenseNet, out-performs\\nResidual Flow and other flow-based models on density estimation evaluated in\\nbits per dimension, where we utilize an equal parameter budget. Moreover, we\\nshow that the proposed model out-performs Residual Flows when trained as a\\nhybrid model where the model is both a generative and a discriminative model.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02694'}, {'title': 'Active Boundary Loss for Semantic Segmentation. (arXiv:2102.02696v1 [cs.CV])', 'description': '<p>This paper proposes a novel active boundary loss for semantic segmentation.\\nIt can progressively encourage the alignment between predicted boundaries and\\nground-truth boundaries during end-to-end training, which is not explicitly\\nenforced in commonly used cross-entropy loss. Based on the predicted boundaries\\ndetected from the segmentation results using current network parameters, we\\nformulate the boundary alignment problem as a differentiable direction vector\\nprediction problem to guide the movement of predicted boundaries in each\\niteration. Our loss is model-agnostic and can be plugged into the training of\\nsegmentation networks to improve the boundary details. Experimental results\\nshow that training with the active boundary loss can effectively improve the\\nboundary F-score and mean Intersection-over-Union on challenging image and\\nvideo object segmentation datasets.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02696'}, {'title': 'Additive Average Schwarz Method for Elliptic Mortar Finite Element Problems with Highly Heterogeneous Coefficients. (arXiv:2102.02700v1 [math.NA])', 'description': '<p>In this paper, we extend the additive average Schwarz method to solve second\\norder elliptic boundary value problems with heterogeneous coefficients inside\\nthe subdomains and across subdomain interfaces by the mortar technique, where\\nthe mortar finite element discretization is on nonmatching meshes. In this\\ntwo-level method, we enrich the coarse space in two different ways, i.e., by\\nadding eigenfunctions of two variants of the generalized eigenvalue problems.\\nWe prove that the condition number for the system of algebraic equations\\nresulting from the extended additive average Schwarz method, corresponding to\\nboth coarse spaces, is of the order O(H/h) and independent of jumps of the\\ncoefficients, where H and h are the mesh parameters.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02700'}, {'title': 'EFloat: Entropy-coded Floating Point Format for Deep Learning. (arXiv:2102.02705v1 [cs.LG])', 'description': '<p>We describe the EFloat floating-point number format with 4 to 6 additional\\nbits of precision and a wider exponent range than the existing floating point\\n(FP) formats of any width including FP32, BFloat16, IEEE-Half precision,\\nDLFloat, TensorFloat, and 8-bit floats. In a large class of deep learning\\nmodels we observe that FP exponent values tend to cluster around few unique\\nvalues which presents entropy encoding opportunities. The EFloat format encodes\\nfrequent exponent values and signs with Huffman codes to minimize the average\\nexponent field width. Saved bits then become available to the mantissa\\nincreasing the EFloat numeric precision on average by 4 to 6 bits compared to\\nother FP formats of equal width. The proposed encoding concept may be\\nbeneficial to low-precision formats including 8-bit floats. Training deep\\nlearning models with low precision arithmetic is challenging. EFloat, with its\\nincreased precision may provide an opportunity for those tasks as well. We\\ncurrently use the EFloat format for compressing and saving memory used in large\\nNLP deep learning models. A potential hardware implementation for improving\\nPCIe and memory bandwidth limitations of AI accelerators is also discussed.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02705'}, {'title': 'ProxyFAUG: Proximity-based Fingerprint Augmentation. (arXiv:2102.02706v1 [cs.CV])', 'description': '<p>The proliferation of data-demanding machine learning methods has brought to\\nlight the necessity for methodologies which can enlarge the size of training\\ndatasets, with simple, rule-based methods. In-line with this concept, the\\nfingerprint augmentation scheme proposed in this work aims to augment\\nfingerprint datasets which are used to train positioning models. The proposed\\nmethod utilizes fingerprints which are recorded in spacial proximity, in order\\nto perform fingerprint augmentation, creating new fingerprints which combine\\nthe features of the original ones. The proposed method of composing the new,\\naugmented fingerprints is inspired by the crossover and mutation operators of\\ngenetic algorithms. The ProxyFAUG method aims to improve the achievable\\npositioning accuracy of fingerprint datasets, by introducing a rule-based,\\nstochastic, proximity-based method of fingerprint augmentation. The performance\\nof ProxyFAUG is evaluated in an outdoor Sigfox setting using a public dataset.\\nThe best performing published positioning method on this dataset is improved by\\n40% in terms of median error and 6% in terms of mean error, with the use of the\\naugmented dataset. The analysis of the results indicate a systematic and\\nsignificant performance improvement at the lower error quartiles, as indicated\\nby the impressive improvement of the median error.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02706'}, {'title': 'Fractionally Log-Concave and Sector-Stable Polynomials: Counting Planar Matchings and More. (arXiv:2102.02708v1 [cs.DS])', 'description': '<p>We show fully polynomial time randomized approximation schemes (FPRAS) for\\ncounting matchings of a given size, or more generally sampling/counting\\nmonomer-dimer systems in planar, not-necessarily-bipartite, graphs. While\\nperfect matchings on planar graphs can be counted exactly in polynomial time,\\ncounting non-perfect matchings was shown by [Jer87] to be #P-hard, who also\\nraised the question of whether efficient approximate counting is possible. We\\nanswer this affirmatively by showing that the multi-site Glauber dynamics on\\nthe set of monomers in a monomer-dimer system always mixes rapidly, and that\\nthis dynamics can be implemented efficiently on downward-closed families of\\ngraphs where counting perfect matchings is tractable. As further applications\\nof our results, we show how to sample efficiently using multi-site Glauber\\ndynamics from partition-constrained strongly Rayleigh distributions, and\\nnonsymmetric determinantal point processes.\\n</p>\\n<p>In order to analyze mixing properties of the multi-site Glauber dynamics, we\\nestablish two notions for generating polynomials of discrete set-valued\\ndistributions: sector-stability and fractional log-concavity. These notions\\ngeneralize well-studied properties like real-stability and log-concavity, but\\nunlike them robustly degrade under useful transformations applied to the\\ndistribution. We relate these notions to pairwise correlations in the\\nunderlying distribution and the notion of spectral independence introduced by\\n[ALO20], providing a new tool for establishing spectral independence based on\\ngeometry of polynomials. As a byproduct of our techniques, we show that\\npolynomials avoiding roots in a sector of the complex plane must satisfy what\\nwe call fractional log-concavity; this generalizes a classic result established\\nby [Gar59] who showed homogeneous polynomials that have no roots in a\\nhalf-plane must be log-concave over the positive orthant.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02708'}, {'title': 'Matching Impatient and Heterogeneous Demand and Supply. (arXiv:2102.02710v1 [math.OC])', 'description': '<p>Service platforms must determine rules for matching heterogeneous demand\\n(customers) and supply (workers) that arrive randomly over time and may be lost\\nif forced to wait too long for a match. We show how to balance the trade-off\\nbetween making a less good match quickly and waiting for a better match, at the\\nrisk of losing impatient customers and/or workers. When the objective is to\\nmaximize the cumulative value of matches over a finite-time horizon, we propose\\ndiscrete-review matching policies, both for the case in which the platform has\\naccess to arrival rate parameter information and the case in which the platform\\ndoes not. We show that both the blind and nonblind policies are asymptotically\\noptimal in a high-volume setting. However, the blind policy requires frequent\\nre-solving of a linear program. For that reason, we also investigate a blind\\npolicy that makes decisions in a greedy manner, and we are able to establish an\\nasymptotic lower bound for the greedy, blind policy that depends on the\\nmatching values and is always higher than half of the value of an optimal\\npolicy. Next, we develop a fluid model that approximates the evolution of the\\nstochastic model and captures explicitly the nonlinear dependence between the\\namount of demand and supply waiting and the distribution of their patience\\ntimes. We use the fluid model to propose a policy for a more general objective\\nthat additionally penalizes queue build-up. We run numerous simulations to\\ninvestigate the performance of the aforementioned proposed matching policies.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02710'}, {'title': 'Fine-tuning deep learning model parameters for improved super-resolution of dynamic MRI with prior-knowledge. (arXiv:2102.02711v1 [eess.IV])', 'description': '<p>Dynamic imaging is a beneficial tool for interventions to assess\\nphysiological changes. Nonetheless during dynamic MRI, while achieving a high\\ntemporal resolution, the spatial resolution is compromised. To overcome this\\nspatio-temporal trade-off, this research presents a super-resolution (SR) MRI\\nreconstruction with prior knowledge based fine-tuning to maximise spatial\\ninformation while preserving high temporal resolution of dynamic MRI. An U-Net\\nbased network with perceptual loss is trained on a benchmark dataset and\\nfine-tuned using one subject-specific static high resolution MRI as prior\\nknowledge to obtain high resolution dynamic images during the inference stage.\\n3D dynamic data for three subjects were acquired with different parameters to\\ntest the generalisation capabilities of the network. The method was tested for\\ndifferent levels of in-plane undersampling for dynamic MRI. The reconstructed\\ndynamic SR results showed higher similarity with the high resolution\\nground-truth after fine-tuning. The average SSIM of the lowest resolution\\nexperimented during this research (6.25~\\\\% of the k-space) before and after\\nfine-tuning were 0.939 $\\\\pm$ 0.008 and 0.957 $\\\\pm$ 0.006 respectively. This\\ncould theoretically result in an acceleration factor of 16, which can\\npotentially be acquired in less than half a second. The proposed approach shows\\nthat the super-resolution MRI reconstruction with prior-information can\\nalleviate the spatio-temporal trade-off in dynamic MRI, even for high\\nacceleration factors.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02711'}, {'title': 'RoI Tanh-polar Transformer Network for Face Parsing in the Wild. (arXiv:2102.02717v1 [cs.CV])', 'description': '<p>Face parsing aims to predict pixel-wise labels for facial components of a\\ntarget face in an image. Existing approaches usually crop the target face from\\nthe input image with respect to a bounding box calculated during\\npre-processing, and thus can only parse inner facial Regions of Interest\\n(RoIs). Peripheral regions like hair are ignored and nearby faces that are\\npartially included in the bounding box can cause distractions. Moreover, these\\nmethods are only trained and evaluated on near-frontal portrait images and thus\\ntheir performance for in-the-wild cases were unexplored. To address these\\nissues, this paper makes three contributions. First, we introduce iBugMask\\ndataset for face parsing in the wild containing 1,000 manually annotated images\\nwith large variations in sizes, poses, expressions and background, and\\nHelen-LP, a large-pose training set containing 21,866 images generated using\\nhead pose augmentation. Second, we propose RoI Tanh-polar transform that warps\\nthe whole image to a Tanh-polar representation with a fixed ratio between the\\nface area and the context, guided by the target bounding box. The new\\nrepresentation contains all information in the original image, and allows for\\nrotation equivariance in the convolutional neural networks (CNNs). Third, we\\npropose a hybrid residual representation learning block, coined HybridBlock,\\nthat contains convolutional layers in both the Tanh-polar space and the\\nTanh-Cartesian space, allowing for receptive fields of different shapes in\\nCNNs. Through extensive experiments, we show that the proposed method\\nsignificantly improves the state-of-the-art for face parsing in the wild.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02717'}, {'title': 'Edge Computing: A Systematic Mapping Study. (arXiv:2102.02720v1 [cs.NI])', 'description': '<p>Edge computing is a novel computing paradigm which extends cloud computing\\nstorage and computation resources at the edge of network and closer to the\\nend-users in order to tackle the problem of communication latency in\\nlatency-sensitive applications. For the last decades, there have been many\\nresearch efforts dedicated to this field. However, there are still many\\noperational challenges. The dramatic growth in researches, large volume of\\npublished studies, and the attention of researchers in this field in recent\\nyears have made it necessary to conduct a Systematic Mapping Study in this\\nfield. we need a comprehensive guide to enable researchers to do more effective\\nsearches on each scope of edge computing. An important part of the methodology\\nis to use the appropriate search method using a three-tier strategy. In this\\nmethod, we defined some quality criteria to extract search spaces and studies\\nwith the highest quality for reading and analysis. In a separate phase, we\\nevaluated the extraction process of related studies in terms of accuracy. using\\nthis comprehensive methodology, we select the number of 112 search spaces out\\nof all 805 ones and by search in these search spaces we select 1440\\nhigh-quality studies out of 8725. In our Systematic Mapping Study, 8 research\\nquestions have been designed to achieve goals such as identifying the main\\ntopics, architectures, techniques, and so on in the field of edge computing. We\\naim this paper can serve as a guideline for researchers interested in this\\nfield.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02720'}, {'title': 'Data-to-text Generation with Macro Planning. (arXiv:2102.02723v1 [cs.CL])', 'description': '<p>Recent approaches to data-to-text generation have adopted the very successful\\nencoder-decoder architecture or variants thereof. These models generate text\\nwhich is fluent (but often imprecise) and perform quite poorly at selecting\\nappropriate content and ordering it coherently. To overcome some of these\\nissues, we propose a neural model with a macro planning stage followed by a\\ngeneration stage reminiscent of traditional methods which embrace separate\\nmodules for planning and surface realization. Macro plans represent high level\\norganization of important content such as entities, events and their\\ninteractions; they are learnt from data and given as input to the generator.\\nExtensive experiments on two data-to-text benchmarks (RotoWire and MLB) show\\nthat our approach outperforms competitive baselines in terms of automatic and\\nhuman evaluation.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02723'}, {'title': 'Multiple Criss-Cross Deletion-Correcting Codes. (arXiv:2102.02727v1 [cs.IT])', 'description': '<p>This paper investigates the problem of correcting multiple criss-cross\\ndeletions in arrays. More precisely, we study the unique recovery of $n \\\\times\\nn$ arrays affected by any combination of $t_\\\\mathrm{r}$ row and $t_\\\\mathrm{c}$\\ncolumn deletions such that $t_\\\\mathrm{r} + t_\\\\mathrm{c} = t$ for a given $t$.\\nWe refer to these type of deletions as $t$-criss-cross deletions. We show that\\na code capable of correcting $t$-criss-cross deletions has redundancy at least\\n$tn + t \\\\log n - \\\\log(t!)$. Then, we present an existential construction of a\\ncode capable of correcting $t$-criss-cross deletions where its redundancy is\\nbounded from above by $tn + \\\\mathcal{O}(t^2 \\\\log^2 n)$. The main ingredients of\\nthe presented code are systematic binary $t$-deletion correcting codes and\\nGabidulin codes. The first ingredient helps locating the indices of the deleted\\nrows and columns, thus transforming the deletion-correction problem into an\\nerasure-correction problem which is then solved using the second ingredient.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02727'}, {'title': 'Minimum-Complexity Failure Correction in Linear Arrays via Compressive Processing. (arXiv:2102.02728v1 [eess.SY])', 'description': '<p>Given an array with defective elements, failure correction (FC) aims at\\nfinding a new set of weights for the working elements so that the properties of\\nthe original pattern can be recovered. Unlike several FC techniques available\\nin the literature, which update all the working excitations, the\\nMinimum-Complexity Failure Correction (MCFC) problem is addressed in this\\npaper. By properly reformulating the FC problem, the minimum number of\\ncorrections of the whole excitations of the array is determined by means of an\\ninnovative Compressive Processing (CP) technique in order to afford a pattern\\nas close as possible to the original one (i.e., the array without failures).\\nSelected examples, from a wide set of numerical test cases, are discussed to\\nassess the effectiveness of the proposed approach as well as to compare its\\nperformance with other competitive state-of-the-art techniques in terms of both\\npattern features and number of corrections.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02728'}, {'title': 'Adversarial Attacks and Defenses in Physiological Computing: A Systematic Review. (arXiv:2102.02729v1 [cs.LG])', 'description': '<p>Physiological computing uses human physiological data as system inputs in\\nreal time. It includes, or significantly overlaps with, brain-computer\\ninterfaces, affective computing, adaptive automation, health informatics, and\\nphysiological signal based biometrics. Physiological computing increases the\\ncommunication bandwidth from the user to the computer, but is also subject to\\nvarious types of adversarial attacks, in which the attacker deliberately\\nmanipulates the training and/or test examples to hijack the machine learning\\nalgorithm output, leading to possibly user confusion, frustration, injury, or\\neven death. However, the vulnerability of physiological computing systems has\\nnot been paid enough attention to, and there does not exist a comprehensive\\nreview on adversarial attacks to it. This paper fills this gap, by providing a\\nsystematic review on the main research areas of physiological computing,\\ndifferent types of adversarial attacks and their applications to physiological\\ncomputing, and the corresponding defense strategies. We hope this review will\\nattract more research interests on the vulnerability of physiological computing\\nsystems, and more importantly, defense strategies to make them more secure.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02729'}, {'title': 'Feedback Capacity of Parallel ACGN Channels and Kalman Filter: Power Allocation with Feedback. (arXiv:2102.02730v1 [cs.IT])', 'description': '<p>In this paper, we relate the feedback capacity of parallel additive colored\\nGaussian noise (ACGN) channels to a variant of the Kalman filter. By doing so,\\nwe obtain lower bounds on the feedback capacity of such channels, as well as\\nthe corresponding feedback (recursive) coding schemes, which are essentially\\npower allocation policies with feedback, to achieve the bounds. The results are\\nseen to reduce to existing lower bounds in the case of a single ACGN feedback\\nchannel, whereas when it comes to parallel additive white Gaussian noise (AWGN)\\nchannels with feedback, the recursive coding scheme reduces to a \"feedback\\nwater-filling\" power allocation policy.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02730'}, {'title': 'Computational identification of significant actors in paintings through symbols and attributes. (arXiv:2102.02732v1 [cs.CV])', 'description': '<p>The automatic analysis of fine art paintings presents a number of novel\\ntechnical challenges to artificial intelligence, computer vision, machine\\nlearning, and knowledge representation quite distinct from those arising in the\\nanalysis of traditional photographs. The most important difference is that many\\nrealist paintings depict stories or episodes in order to convey a lesson,\\nmoral, or meaning. One early step in automatic interpretation and extraction of\\nmeaning in artworks is the identifications of figures (actors). In Christian\\nart, specifically, one must identify the actors in order to identify the\\nBiblical episode or story depicted, an important step in understanding the\\nartwork. We designed an automatic system based on deep convolutional neural\\nnetworks and simple knowledge database to identify saints throughout six\\ncenturies of Christian art based in large part upon saints symbols or\\nattributes. Our work represents initial steps in the broad task of automatic\\nsemantic interpretation of messages and meaning in fine art.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02732'}, {'title': 'Deep learning-based synthetic-CT generation in radiotherapy and PET: a review. (arXiv:2102.02734v1 [physics.med-ph])', 'description': \"<p>Recently, deep learning (DL)-based methods for the generation of synthetic\\ncomputed tomography (sCT) have received significant research attention as an\\nalternative to classical ones. We present here a systematic review of these\\nmethods by grouping them into three categories, according to their clinical\\napplications: I) to replace CT in magnetic resonance (MR)-based treatment\\nplanning, II) facilitate cone-beam computed tomography (CBCT)-based\\nimage-guided adaptive radiotherapy, and III) derive attenuation maps for the\\ncorrection of Positron Emission Tomography (PET). Appropriate database\\nsearching was performed on journal articles published between January 2014 and\\nDecember 2020. The DL methods' key characteristics were extracted from each\\neligible study, and a comprehensive comparison among network architectures and\\nmetrics was reported. A detailed review of each category was given,\\nhighlighting essential contributions, identifying specific challenges, and\\nsummarising the achievements. Lastly, the statistics of all the cited works\\nfrom various aspects were analysed, revealing the popularity and future trends,\\nand the potential of DL-based sCT generation. The current status of DL-based\\nsCT generation was evaluated, assessing the clinical readiness of the presented\\nmethods.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02734'}, {'title': 'Hawkes Processes on Graphons. (arXiv:2102.02741v1 [cs.LG])', 'description': '<p>We propose a novel framework for modeling multiple multivariate point\\nprocesses, each with heterogeneous event types that share an underlying space\\nand obey the same generative mechanism. Focusing on Hawkes processes and their\\nvariants that are associated with Granger causality graphs, our model leverages\\nan uncountable event type space and samples the graphs with different sizes\\nfrom a nonparametric model called {\\\\it graphon}. Given those graphs, we can\\ngenerate the corresponding Hawkes processes and simulate event sequences.\\nLearning this graphon-based Hawkes process model helps to 1) infer the\\nunderlying relations shared by different Hawkes processes; and 2) simulate\\nevent sequences with different event types but similar dynamics. We learn the\\nproposed model by minimizing the hierarchical optimal transport distance\\nbetween the generated event sequences and the observed ones, leading to a novel\\nreward-augmented maximum likelihood estimation method. We analyze the\\nproperties of our model in-depth and demonstrate its rationality and\\neffectiveness in both theory and experiments.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02741'}, {'title': 'Sovereign Smartphone: To Enjoy Freedom We Have to Control Our Phones. (arXiv:2102.02743v1 [cs.CR])', 'description': '<p>The majority of smartphones either run iOS or Android operating systems. This\\nhas created two distinct ecosystems largely controlled by Apple and Google -\\nthey dictate which applications can run, how they run, and what kind of phone\\nresources they can access. Barring some exceptions in Android where different\\nphone manufacturers may have influence, users, developers, and governments are\\nleft with little to no choice. Specifically, users need to entrust their\\nsecurity and privacy to OS vendors and accept the functionality constraints\\nthey impose. Given the wide use of Android and iOS, immediately leaving these\\necosystems is not practical, except in niche application areas. In this work,\\nwe draw attention to the magnitude of this problem and why it is an undesirable\\nsituation. As an alternative, we advocate the development of a new smartphone\\narchitecture that securely transfers the control back to the users while\\nmaintaining compatibility with the rich existing smartphone ecosystems. We\\npropose and analyze one such design based on advances in trusted execution\\nenvironments for ARM and RISC-V.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02743'}, {'title': 'Semi-Supervised Action Recognition with Temporal Contrastive Learning. (arXiv:2102.02751v1 [cs.CV])', 'description': \"<p>Learning to recognize actions from only a handful of labeled videos is a\\nchallenging problem due to the scarcity of tediously collected activity labels.\\nWe approach this problem by learning a two-pathway temporal contrastive model\\nusing unlabeled videos at two different speeds leveraging the fact that\\nchanging video speed does not change an action. Specifically, we propose to\\nmaximize the similarity between encoded representations of the same video at\\ntwo different speeds as well as minimize the similarity between different\\nvideos played at different speeds. This way we use the rich supervisory\\ninformation in terms of 'time' that is present in otherwise unsupervised pool\\nof videos. With this simple yet effective strategy of manipulating video\\nplayback rates, we considerably outperform video extensions of sophisticated\\nstate-of-the-art semi-supervised image recognition methods across multiple\\ndiverse benchmark datasets and network architectures. Interestingly, our\\nproposed approach benefits from out-of-domain unlabeled videos showing\\ngeneralization and robustness. We also perform rigorous ablations and analysis\\nto validate our approach.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02751'}, {'title': 'Materializing Knowledge Bases via Trigger Graphs. (arXiv:2102.02753v1 [cs.DB])', 'description': '<p>The chase is a well-established family of algorithms used to materialize\\nKnowledge Bases (KBs), like Knowledge Graphs (KGs), to tackle important tasks\\nlike query answering under dependencies or data cleaning. A general problem of\\nchase algorithms is that they might perform redundant computations. To counter\\nthis problem, we introduce the notion of Trigger Graphs (TGs), which guide the\\nexecution of the rules avoiding redundant computations. We present the results\\nof an extensive theoretical and empirical study that seeks to answer when and\\nhow TGs can be computed and what are the benefits of TGs when applied over\\nreal-world KBs. Our results include introducing algorithms that compute\\n(minimal) TGs. We implemented our approach in a new engine, and our experiments\\nshow that it can be significantly more efficient than the chase enabling us to\\nmaterialize KBs with 17B facts in less than 40 min on commodity machines.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02753'}, {'title': 'Only a Matter of Style: Age Transformation Using a Style-Based Regression Model. (arXiv:2102.02754v1 [cs.CV])', 'description': \"<p>The task of age transformation illustrates the change of an individual's\\nappearance over time. Accurately modeling this complex transformation over an\\ninput facial image is extremely challenging as it requires making convincing\\nand possibly large changes to facial features and head shape, while still\\npreserving the input identity. In this work, we present an image-to-image\\ntranslation method that learns to directly encode real facial images into the\\nlatent space of a pre-trained unconditional GAN (e.g., StyleGAN) subject to a\\ngiven aging shift. We employ a pre-trained age regression network used to\\nexplicitly guide the encoder in generating the latent codes corresponding to\\nthe desired age. In this formulation, our method approaches the continuous\\naging process as a regression task between the input age and desired target\\nage, providing fine-grained control over the generated image. Moreover, unlike\\nother approaches that operate solely in the latent space using a prior on the\\npath controlling age, our method learns a more disentangled, non-linear path.\\nFinally, we demonstrate that the end-to-end nature of our approach, coupled\\nwith the rich semantic latent space of StyleGAN, allows for further editing of\\nthe generated images. Qualitative and quantitative evaluations show the\\nadvantages of our method compared to state-of-the-art approaches.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02754'}, {'title': 'Instance-based learning using the Half-Space Proximal Graph. (arXiv:2102.02755v1 [cs.LG])', 'description': '<p>The primary example of instance-based learning is the $k$-nearest neighbor\\nrule (kNN), praised for its simplicity and the capacity to adapt to new unseen\\ndata and toss away old data. The main disadvantages often mentioned are the\\nclassification complexity, which is $O(n)$, and the estimation of the parameter\\n$k$, the number of nearest neighbors to be used. The use of indexes at\\nclassification time lifts the former disadvantage, while there is no conclusive\\nmethod for the latter.\\n</p>\\n<p>This paper presents a parameter-free instance-based learning algorithm using\\nthe {\\\\em Half-Space Proximal} (HSP) graph. The HSP neighbors simultaneously\\npossess proximity and variety concerning the center node. To classify a given\\nquery, we compute its HSP neighbors and apply a simple majority rule over them.\\nIn our experiments, the resulting classifier bettered $KNN$ for any $k$ in a\\nbattery of datasets. This improvement sticks even when applying weighted\\nmajority rules to both kNN and HSP classifiers.\\n</p>\\n<p>Surprisingly, when using a probabilistic index to approximate the HSP graph\\nand consequently speeding-up the classification task, our method could {\\\\em\\nimprove} its accuracy in stark contrast with the kNN classifier, which worsens\\nwith a probabilistic index.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02755'}, {'title': 'On the computational and statistical complexity of over-parameterized matrix sensing. (arXiv:2102.02756v1 [cs.LG])', 'description': '<p>We consider solving the low rank matrix sensing problem with Factorized\\nGradient Descend (FGD) method when the true rank is unknown and over-specified,\\nwhich we refer to as over-parameterized matrix sensing. If the ground truth\\nsignal $\\\\mathbf{X}^* \\\\in \\\\mathbb{R}^{d*d}$ is of rank $r$, but we try to\\nrecover it using $\\\\mathbf{F} \\\\mathbf{F}^\\\\top$ where $\\\\mathbf{F} \\\\in\\n\\\\mathbb{R}^{d*k}$ and $k&gt;r$, the existing statistical analysis falls short, due\\nto a flat local curvature of the loss function around the global maxima. By\\ndecomposing the factorized matrix $\\\\mathbf{F}$ into separate column spaces to\\ncapture the effect of extra ranks, we show that $\\\\|\\\\mathbf{F}_t \\\\mathbf{F}_t -\\n\\\\mathbf{X}^*\\\\|_{F}^2$ converges to a statistical error of $\\\\tilde{\\\\mathcal{O}}\\n({k d \\\\sigma^2/n})$ after\\n$\\\\tilde{\\\\mathcal{O}}(\\\\frac{\\\\sigma_{r}}{\\\\sigma}\\\\sqrt{\\\\frac{n}{d}})$ number of\\niterations where $\\\\mathbf{F}_t$ is the output of FGD after $t$ iterations,\\n$\\\\sigma^2$ is the variance of the observation noise, $\\\\sigma_{r}$ is the $r$-th\\nlargest eigenvalue of $\\\\mathbf{X}^*$, and $n$ is the number of sample. Our\\nresults, therefore, offer a comprehensive picture of the statistical and\\ncomputational complexity of FGD for the over-parameterized matrix sensing\\nproblem.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02756'}, {'title': 'A 5 \\\\mu W Standard Cell Memory-based Configurable Hyperdimensional Computing Accelerator for Always-on Smart Sensing. (arXiv:2102.02758v1 [eess.SP])', 'description': '<p>Hyperdimensional computing (HDC) is a brain-inspired computing paradigm based\\non high-dimensional holistic representations of vectors. It recently gained\\nattention for embedded smart sensing due to its inherent error-resiliency and\\nsuitability to highly parallel hardware implementations. In this work, we\\npropose a programmable all-digital CMOS implementation of a fully autonomous\\nHDC accelerator for always-on classification in energy-constrained sensor\\nnodes. By using energy-efficient standard cell memory (SCM), the design is\\neasily cross-technology mappable. It achieves extremely low power, 5 $\\\\mu W$ in\\ntypical applications, and an energy-efficiency improvement over the\\nstate-of-the-art (SoA) digital architectures of up to 3$\\\\times$ in post-layout\\nsimulations for always-on wearable tasks such as EMG gesture recognition. As\\npart of the accelerator\\'s architecture, we introduce novel hardware-friendly\\nembodiments of common HDC-algorithmic primitives, which results in 3.3$\\\\times$\\ntechnology scaled area reduction over the SoA, achieving the same accuracy\\nlevels in all examined targets. The proposed architecture also has a fully\\nconfigurable datapath using microcode optimized for HDC stored on an integrated\\nSCM based configuration memory, making the design \"general-purpose\" in terms of\\nHDC algorithm flexibility. This flexibility allows usage of the accelerator\\nacross novel HDC tasks, for instance, a newly designed HDC applied to the task\\nof ball bearing fault detection.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02758'}, {'title': 'Online Discrepancy Minimization via Persistent Self-Balancing Walks. (arXiv:2102.02765v1 [cs.DS])', 'description': '<p>We study the online discrepancy minimization problem for vectors in\\n$\\\\mathbb{R}^d$ in the oblivious setting where an adversary is allowed fix the\\nvectors $x_1, x_2, \\\\ldots, x_n$ in arbitrary order ahead of time. We give an\\nalgorithm that maintains $O(\\\\sqrt{\\\\log(nd/\\\\delta)})$ discrepancy with\\nprobability $1-\\\\delta$, matching the lower bound given in [Bansal et al. 2020]\\nup to an $O(\\\\sqrt{\\\\log \\\\log n})$ factor in the high-probability regime. We also\\nprovide results for the weighted and multi-color versions of the problem.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02765'}, {'title': 'Designing an Encoder for StyleGAN Image Manipulation. (arXiv:2102.02766v1 [cs.CV])', 'description': '<p>Recently, there has been a surge of diverse methods for performing image\\nediting by employing pre-trained unconditional generators. Applying these\\nmethods on real images, however, remains a challenge, as it necessarily\\nrequires the inversion of the images into their latent space. To successfully\\ninvert a real image, one needs to find a latent code that reconstructs the\\ninput image accurately, and more importantly, allows for its meaningful\\nmanipulation. In this paper, we carefully study the latent space of StyleGAN,\\nthe state-of-the-art unconditional generator. We identify and analyze the\\nexistence of a distortion-editability tradeoff and a distortion-perception\\ntradeoff within the StyleGAN latent space. We then suggest two principles for\\ndesigning encoders in a manner that allows one to control the proximity of the\\ninversions to regions that StyleGAN was originally trained on. We present an\\nencoder based on our two principles that is specifically designed for\\nfacilitating editing on real images by balancing these tradeoffs. By evaluating\\nits performance qualitatively and quantitatively on numerous challenging\\ndomains, including cars and horses, we show that our inversion method, followed\\nby common editing techniques, achieves superior real-image editing quality,\\nwith only a small reconstruction accuracy drop.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02766'}, {'title': 'PHASER: a Robust and Correspondence-free Global Pointcloud Registration. (arXiv:2102.02767v1 [cs.RO])', 'description': \"<p>We propose PHASER, a correspondence-free global registration of\\nsensor-centric pointclouds that is robust to noise, sparsity, and partial\\noverlaps. Our method can seamlessly handle multimodal information and does not\\nrely on keypoint nor descriptor preprocessing modules. By exploiting properties\\nof Fourier analysis, PHASER operates directly on the sensor's signal, fusing\\nthe spectra of multiple channels and computing the 6-DoF transformation based\\non correlation. Our registration pipeline starts by finding the most likely\\nrotation followed by computing the most likely translation. Both estimates are\\ndistributed according to a probability distribution that takes the underlying\\nmanifold into account, i.e., a Bingham and Gaussian distribution, respectively.\\nThis further allows our approach to consider the periodic-nature of rotations\\nand naturally represent its uncertainty. We extensively compare PHASER against\\nseveral well-known registration algorithms on both simulated datasets, and\\nreal-world data acquired using different sensor configurations. Our results\\nshow that PHASER can globally align pointclouds in less than 100ms with an\\naverage accuracy of 2cm and 0.5deg, is resilient against noise, and can handle\\npartial overlap.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.02767'}, {'title': 'A survey on modelling of infectious disease spread and control on social contact networks. (arXiv:2102.02768v1 [physics.soc-ph])', 'description': '<p>Infectious diseases are a significant threat to human society which was over\\nsighted before the incidence of COVID-19, although according to the report of\\nthe World Health Organisation (WHO) about 4.2 million people die annually due\\nto infectious disease. Due to recent COVID-19 pandemic, more than 2 million\\npeople died during 2020 and 96.2 million people got affected by this\\ndevastating disease. Recent research shows that applying individual\\ninteractions and movements data could help managing the pandemic though\\nmodelling the spread of infectious diseases on social contact networks.\\nInfectious disease spreading can be explained with the theories and methods of\\ndiffusion processes where a dynamic phenomena evolves on networked systems. In\\nthe modelling of diffusion process, it is assumed that contagious items spread\\nout in the networked system through the inter-node interactions. This resembles\\nspreading of infectious virus, e.g. spread of COVID-19, within a population\\nthrough individual social interactions. The evolution behaviours of the\\ndiffusion process are strongly influenced by the characteristics of the\\nunderlying system and the mechanism of the diffusion process itself. Thus,\\nspreading of infectious disease can be explained how people interact with each\\nother and by the characteristics of the disease itself. This paper presenters\\nthe relevant theories and methodologies of diffusion process that can be used\\nto model the spread of infectious diseases.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02768'}, {'title': 'A Living Review of Machine Learning for Particle Physics. (arXiv:2102.02770v1 [hep-ph])', 'description': '<p>Modern machine learning techniques, including deep learning, are rapidly\\nbeing applied, adapted, and developed for high energy physics. Given the fast\\npace of this research, we have created a living review with the goal of\\nproviding a nearly comprehensive list of citations for those developing and\\napplying these approaches to experimental, phenomenological, or theoretical\\nanalyses. As a living document, it will be updated as often as possible to\\nincorporate the latest developments. A list of proper (unchanging) reviews can\\nbe found within. Papers are grouped into a small set of topics to be as useful\\nas possible. Suggestions and contributions are most welcome, and we provide\\ninstructions for participating.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02770'}, {'title': 'Mask guided attention for fine-grained patchy image classification. (arXiv:2102.02771v1 [cs.CV])', 'description': '<p>In this work, we present a novel mask guided attention (MGA) method for\\nfine-grained patchy image classification. The key challenge of fine-grained\\npatchy image classification lies in two folds, ultra-fine-grained\\ninter-category variances among objects and very few data available for\\ntraining. This motivates us to consider employing more useful supervision\\nsignal to train a discriminative model within limited training samples.\\nSpecifically, the proposed MGA integrates a pre-trained semantic segmentation\\nmodel that produces auxiliary supervision signal, i.e., patchy attention mask,\\nenabling a discriminative representation learning. The patchy attention mask\\ndrives the classifier to filter out the insignificant parts of images (e.g.,\\ncommon features between different categories), which enhances the robustness of\\nMGA for the fine-grained patchy image classification. We verify the\\neffectiveness of our method on three publicly available patchy image datasets.\\nExperimental results demonstrate that our MGA method achieves superior\\nperformance on three datasets compared with the state-of-the-art methods. In\\naddition, our ablation study shows that MGA improves the accuracy by 2.25% and\\n2% on the SoyCultivarVein and BtfPIS datasets, indicating its practicality\\ntowards solving the fine-grained patchy image classification.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02771'}, {'title': 'DLpN: Single-Shell NODDI Using Deep Learner Estimated Isotropic Volume Fraction. (arXiv:2102.02772v1 [physics.med-ph])', 'description': '<p>Neurite orientation dispersion and density imaging (NODDI) enables assessment\\nof intracellular, extracellular and free water signals from multi-shell\\ndiffusion MRI data. It is an insightful approach to characterize the brain\\ntissue microstructure. Single-shell reconstruction for NODDI parameters has\\nbeen discouraged in previous literature based on failure when fitting\\nespecially for the neurite density index (NDI). Here, we investigated the\\npossibility to create robust NODDI parameter maps with single-shell data, using\\nisotropic volume fraction (f_{ISO}) as prior. We made the prior estimation\\nindependent of NODDI model constraint using a dictionary based deep learning\\napproach. First, we proposed a stochastic sparse dictionary-based network,\\nDictNet in predicting f_{ISO} . In single-shell cases, fractional anisotropy\\n(FA) and T2 signal without diffusion weighting ( S_0 ) were incorporated in the\\ndictionary for f_{ISO} estimation. Then, NODDI framework was used in a prior\\nsetting to estimate the NDI and orientation dispersion index (ODI). Using both\\nsynthetic data simulation and human data collected on a 3T scanner, we compared\\nthe performance of our dictionary based deep learning prior NODDI (DLpN) with\\noriginal NODDI method for both single-shell and multi-shell data. Our results\\nsuggest that DLpN derived NDI and ODI parameters for single-shell protocols are\\ncomparable with original multi-shell NODDI, and protocol with b=2000 s/mm 2\\nperforms the best (error ~2% in white matter and ~4% in grey matter). This may\\nallow NODDI evaluation of retrospective studies on single-shell data by\\nadditional scanning of two subjects for DictNet f_{ISO} training.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02772'}, {'title': 'Recursive Prime Factorizations: Dyck Words as Numbers. (arXiv:2102.02777v1 [cs.FL])', 'description': '<p>I propose a class of numeral systems where numbers are represented by Dyck\\nwords, with the systems arising from a generalization of prime factorization.\\nAfter describing two proper subsets of the Dyck language capable of uniquely\\nrepresenting all natural and rational numbers respectively, I consider\\n\"Dyck-complete\" languages, in which every member of the Dyck language\\nrepresents a number. I conclude by suggesting possible research directions.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02777'}, {'title': 'Unifying Vision-and-Language Tasks via Text Generation. (arXiv:2102.02779v1 [cs.CL])', 'description': '<p>Existing methods for vision-and-language learning typically require designing\\ntask-specific architectures and objectives for each task. For example, a\\nmulti-label answer classifier for visual question answering, a region scorer\\nfor referring expression comprehension, and a language decoder for image\\ncaptioning, etc. To alleviate these hassles, in this work, we propose a unified\\nframework that learns different tasks in a single architecture with the same\\nlanguage modeling objective, i.e., multimodal conditional text generation,\\nwhere our models learn to generate labels in text based on the visual and\\ntextual inputs. On 7 popular vision-and-language benchmarks, including visual\\nquestion answering, referring expression comprehension, visual commonsense\\nreasoning, most of which have been previously modeled as discriminative tasks,\\nour generative approach (with a single unified architecture) reaches comparable\\nperformance to recent task-specific state-of-the-art vision-and-language\\nmodels. Moreover, our generative approach shows better generalization ability\\non answering questions that have rare answers. In addition, we show that our\\nframework allows multi-task learning in a single architecture with a single set\\nof parameters, which achieves similar performance to separately optimized\\nsingle-task models. Our code will be publicly available at:\\nhttps://github.com/j-min/VL-T5\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02779'}, {'title': 'Comparing State-of-the-Art and Emerging Augmented Reality Interfaces for Autonomous Vehicle-to-Pedestrian Communication. (arXiv:2102.02783v1 [cs.HC])', 'description': '<p>Providing pedestrians and other vulnerable road users with a clear indication\\nabout a fully autonomous vehicle status and intentions is crucial to make them\\ncoexist. In the last few years, a variety of external interfaces have been\\nproposed, leveraging different paradigms and technologies including\\nvehicle-mounted devices (like LED panels), short-range on-road projections, and\\nroad infrastructure interfaces (e.g., special asphalts with embedded displays).\\nThese designs were experimented in different settings, using mockups, specially\\nprepared vehicles, or virtual environments, with heterogeneous evaluation\\nmetrics. Promising interfaces based on Augmented Reality (AR) have been\\nproposed too, but their usability and effectiveness have not been tested yet.\\nThis paper aims to complement such body of literature by presenting a\\ncomparison of state-of-the-art interfaces and new designs under common\\nconditions. To this aim, an immersive Virtual Reality-based simulation was\\ndeveloped, recreating a well-known scenario represented by pedestrians crossing\\nin urban environments under non-regulated conditions. A user study was then\\nperformed to investigate the various dimensions of vehicle-to-pedestrian\\ninteraction leveraging objective and subjective metrics. Even though no\\ninterface clearly stood out over all the considered dimensions, one of the AR\\ndesigns achieved state-of-the-art results in terms of safety and trust, at the\\ncost of higher cognitive effort and lower intuitiveness compared to LED panels\\nshowing anthropomorphic features. Together with rankings on the various\\ndimensions, indications about advantages and drawbacks of the various\\nalternatives that emerged from this study could provide important information\\nfor next developments in the field.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02783'}, {'title': 'Egalitarian Judgment Aggregation. (arXiv:2102.02785v1 [cs.AI])', 'description': '<p>Egalitarian considerations play a central role in many areas of social choice\\ntheory. Applications of egalitarian principles range from ensuring everyone\\ngets an equal share of a cake when deciding how to divide it, to guaranteeing\\nbalance with respect to gender or ethnicity in committee elections. Yet, the\\negalitarian approach has received little attention in judgment aggregation -- a\\npowerful framework for aggregating logically interconnected issues. We make the\\nfirst steps towards filling that gap. We introduce axioms capturing two\\nclassical interpretations of egalitarianism in judgment aggregation and situate\\nthese within the context of existing axioms in the pertinent framework of\\nbelief merging. We then explore the relationship between these axioms and\\nseveral notions of strategyproofness from social choice theory at large.\\nFinally, a novel egalitarian judgment aggregation rule stems from our analysis;\\nwe present complexity results concerning both outcome determination and\\nstrategic manipulation for that rule.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02785'}, {'title': 'Disambiguation of weak supervision with exponential convergence rates. (arXiv:2102.02789v1 [cs.LG])', 'description': '<p>Machine learning approached through supervised learning requires expensive\\nannotation of data. This motivates weakly supervised learning, where data are\\nannotated with incomplete yet discriminative information. In this paper, we\\nfocus on partial labelling, an instance of weak supervision where, from a given\\ninput, we are given a set of potential targets. We review a disambiguation\\nprinciple to recover full supervision from weak supervision, and propose an\\nempirical disambiguation algorithm. We prove exponential convergence rates of\\nour algorithm under classical learnability assumptions, and we illustrate the\\nusefulness of our method on practical examples.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02789'}, {'title': 'RECol: Reconstruction Error Columns for Outlier Detection. (arXiv:2102.02791v1 [cs.LG])', 'description': '<p>Detecting outliers or anomalies is a common data analysis task. As a\\nsub-field of unsupervised machine learning, a large variety of approaches\\nexist, but the vast majority treats the input features as independent and often\\nfails to recognize even simple (linear) relationships in the input feature\\nspace. Hence, we introduce RECol, a generic data pre-processing approach to\\ngenerate additional columns in a leave-one-out-fashion: For each column, we try\\nto predict its values based on the other columns, generating reconstruction\\nerror columns. We run experiments across a large variety of common baseline\\napproaches and benchmark datasets with and without our RECol pre-processing\\nmethod and show that the generated reconstruction error feature space generally\\nseems to support common outlier detection methods and often considerably\\nimproves their ROC-AUC and PR-AUC values.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02791'}, {'title': 'Im2Vec: Synthesizing Vector Graphics without Vector Supervision. (arXiv:2102.02798v1 [cs.CV])', 'description': '<p>Vector graphics are widely used to represent fonts, logos, digital artworks,\\nand graphic designs. But, while a vast body of work has focused on generative\\nalgorithms for raster images, only a handful of options exists for vector\\ngraphics. One can always rasterize the input graphic and resort to image-based\\ngenerative approaches, but this negates the advantages of the vector\\nrepresentation. The current alternative is to use specialized models that\\nrequire explicit supervision on the vector graphics representation at training\\ntime. This is not ideal because large-scale high quality vector-graphics\\ndatasets are difficult to obtain. Furthermore, the vector representation for a\\ngiven design is not unique, so models that supervise on the vector\\nrepresentation are unnecessarily constrained. Instead, we propose a new neural\\nnetwork that can generate complex vector graphics with varying topologies, and\\nonly requires indirect supervision from readily-available raster training\\nimages (i.e., with no vector counterparts). To enable this, we use a\\ndifferentiable rasterization pipeline that renders the generated vector shapes\\nand composites them together onto a raster canvas. We demonstrate our method on\\na range of datasets, and provide comparison with state-of-the-art SVG-VAE and\\nDeepSVG, both of which require explicit vector graphics supervision. Finally,\\nwe also demonstrate our approach on the MNIST dataset, for which no groundtruth\\nvector representation is available. Source code, datasets, and more results are\\navailable at <a href=\"http://geometry.cs.ucl.ac.uk/projects/2020/Im2Vec/\">this http URL</a>\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02798'}, {'title': 'Federated mmWave Beam Selection Utilizing LIDAR Data. (arXiv:2102.02802v1 [cs.IT])', 'description': '<p>Efficient link configuration in millimeter wave (mmWave) communication\\nsystems is a crucial yet challenging task due to the overhead imposed by beam\\nselection on the network performance. For vehicle-to-infrastructure (V2I)\\nnetworks, side information from LIDAR sensors mounted on the vehicles has been\\nleveraged to reduce the beam search overhead. In this letter, we propose\\ndistributed LIDAR aided beam selection for V2I mmWave communication systems\\nutilizing federated training. In the proposed scheme, connected vehicles\\ncollaborate to train a shared neural network (NN) on their locally available\\nLIDAR data during normal operation of the system. We also propose an\\nalternative reduced-complexity convolutional NN (CNN) architecture and LIDAR\\npreprocessing, which significantly outperforms previous works in terms of both\\nthe performance and the complexity.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02802'}, {'title': 'A Deeper Look into Convolutions via Pruning. (arXiv:2102.02804v1 [cs.CV])', 'description': '<p>Convolutional neural networks (CNNs) are able to attain better visual\\nrecognition performance than fully connected neural networks despite having\\nmuch less parameters due to their parameter sharing principle. Hence, modern\\narchitectures are designed to contain a very small number of fully-connected\\nlayers, often at the end, after multiple layers of convolutions. It is\\ninteresting to observe that we can replace large fully-connected layers with\\nrelatively small groups of tiny matrices applied on the entire image. Moreover,\\nalthough this strategy already reduces the number of parameters, most of the\\nconvolutions can be eliminated as well, without suffering any loss in\\nrecognition performance. However, there is no solid recipe to detect this\\nhidden subset of convolutional neurons that is responsible for the majority of\\nthe recognition work. Hence, in this work, we use the matrix characteristics\\nbased on eigenvalues in addition to the classical weight-based importance\\nassignment approach for pruning to shed light on the internal mechanisms of a\\nwidely used family of CNNs, namely residual neural networks (ResNets), for the\\nimage classification problem using CIFAR-10, CIFAR-100 and Tiny ImageNet\\ndatasets.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02804'}, {'title': 'Rethinking Quadratic Regularizers: Explicit Movement Regularization for Continual Learning. (arXiv:2102.02805v1 [cs.LG])', 'description': '<p>Quadratic regularizers are often used for mitigating catastrophic forgetting\\nin deep neural networks (DNNs), but are unable to compete with recent continual\\nlearning methods. To understand this behavior, we analyze parameter updates\\nunder quadratic regularization and demonstrate such regularizers prevent\\nforgetting of past tasks by implicitly performing a weighted average between\\ncurrent and previous values of model parameters. Our analysis shows the\\ninferior performance of quadratic regularizers arises from (a) dependence of\\nweighted averaging on training hyperparameters, which often results in unstable\\ntraining and (b) assignment of lower importance to deeper layers, which are\\ngenerally the cause for forgetting in DNNs. To address these limitations, we\\npropose Explicit Movement Regularization (EMR), a continual learning algorithm\\nthat modifies quadratic regularization to remove the dependence of weighted\\naveraging on training hyperparameters and uses a relative measure for\\nimportance to avoid problems caused by lower importance assignment to deeper\\nlayers. Compared to quadratic regularization, EMR achieves 6.2% higher average\\naccuracy and 4.5% lower average forgetting.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02805'}, {'title': 'Multi-Stage Progressive Image Restoration. (arXiv:2102.02808v1 [cs.CV])', 'description': '<p>Image restoration tasks demand a complex balance between spatial details and\\nhigh-level contextualized information while recovering images. In this paper,\\nwe propose a novel synergistic design that can optimally balance these\\ncompeting goals. Our main proposal is a multi-stage architecture, that\\nprogressively learns restoration functions for the degraded inputs, thereby\\nbreaking down the overall recovery process into more manageable steps.\\nSpecifically, our model first learns the contextualized features using\\nencoder-decoder architectures and later combines them with a high-resolution\\nbranch that retains local information. At each stage, we introduce a novel\\nper-pixel adaptive design that leverages in-situ supervised attention to\\nreweight the local features. A key ingredient in such a multi-stage\\narchitecture is the information exchange between different stages. To this end,\\nwe propose a two-faceted approach where the information is not only exchanged\\nsequentially from early to late stages, but lateral connections between feature\\nprocessing blocks also exist to avoid any loss of information. The resulting\\ntightly interlinked multi-stage architecture, named as MPRNet, delivers strong\\nperformance gains on ten datasets across a range of tasks including image\\nderaining, deblurring, and denoising. For example, on the Rain100L, GoPro and\\nDND datasets, we obtain PSNR gains of 4 dB, 0.81 dB and 0.21 dB, respectively,\\ncompared to the state-of-the-art. The source code and pre-trained models are\\navailable at https://github.com/swz30/MPRNet.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02808'}, {'title': 'Controlling Hallucinations at Word Level in Data-to-Text Generation. (arXiv:2102.02810v1 [cs.CL])', 'description': '<p>Data-to-Text Generation (DTG) is a subfield of Natural Language Generation\\naiming at transcribing structured data in natural language descriptions. The\\nfield has been recently boosted by the use of neural-based generators which\\nexhibit on one side great syntactic skills without the need of hand-crafted\\npipelines; on the other side, the quality of the generated text reflects the\\nquality of the training data, which in realistic settings only offer\\nimperfectly aligned structure-text pairs. Consequently, state-of-art neural\\nmodels include misleading statements - usually called hallucinations - in their\\noutputs. The control of this phenomenon is today a major challenge for DTG, and\\nis the problem addressed in the paper.\\n</p>\\n<p>Previous work deal with this issue at the instance level: using an alignment\\nscore for each table-reference pair. In contrast, we propose a finer-grained\\napproach, arguing that hallucinations should rather be treated at the word\\nlevel. Specifically, we propose a Multi-Branch Decoder which is able to\\nleverage word-level labels to learn the relevant parts of each training\\ninstance. These labels are obtained following a simple and efficient scoring\\nprocedure based on co-occurrence analysis and dependency parsing. Extensive\\nevaluations, via automated metrics and human judgment on the standard WikiBio\\nbenchmark, show the accuracy of our alignment labels and the effectiveness of\\nthe proposed Multi-Branch Decoder. Our model is able to reduce and control\\nhallucinations, while keeping fluency and coherence in generated texts. Further\\nexperiments on a degraded version of ToTTo show that our model could be\\nsuccessfully used on very noisy settings.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02810'}, {'title': 'SelfNorm and CrossNorm for Out-of-Distribution Robustness. (arXiv:2102.02811v1 [cs.CV])', 'description': '<p>Normalization techniques are crucial in stabilizing and accelerating the\\ntraining of deep neural networks. However, they are mainly designed for the\\nindependent and identically distributed (IID) data, not satisfying many\\nreal-world out-of-distribution (OOD) situations. Unlike most previous works,\\nthis paper presents two normalization methods, SelfNorm and CrossNorm, to\\npromote OOD generalization. SelfNorm uses attention to recalibrate statistics\\n(channel-wise mean and variance), while CrossNorm exchanges the statistics\\nbetween feature maps. SelfNorm and CrossNorm can complement each other in OOD\\ngeneralization, though exploring different directions in statistics usage.\\nExtensive experiments on different domains (vision and language), tasks\\n(classification and segmentation), and settings (supervised and\\nsemi-supervised) show their effectiveness.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02811'}, {'title': 'Proximal Navigation Graphs and t-spanners. (arXiv:1404.1646v2 [cs.CG] UPDATED)', 'description': '<p>Let $(X,\\\\mathbf{d})$ be a metric space, $V\\\\subseteq X$ a finite set, and $E\\n\\\\subseteq V \\\\times V$. We call the graph $G(E,V)$ a {\\\\em metric} graph if each\\nedge $(u,v) \\\\in E$ has weight $d(u,v)$. In particular edge $(u,u)$ is in the\\ngraph and have distance $0$. We call $G$ a {\\\\em proximal navigation graph} or\\n$PN$-graph if for each edge $(u,v) \\\\in E$ either $u=v$ or there is a node $u_1$\\nsuch that $(u,u_1) \\\\in E$ and $\\\\mathbf{d}(u,v) &gt; \\\\mathbf{d}(u_1,v)$. In such\\ngraph it is possible to navigate greedily from an arbitrary source node to an\\narbitrary target node by reducing the distance between the current node and the\\ntarget node in each step. The complete graph, the Delaunay triangulation and\\nthe Half Space Proximal (HSP) graph (defined below in the paper) are examples\\nof $PN$-graphs.\\n</p>\\n<p>In this paper we study the relationship between $PN$-graphs and $t$-spanners\\nand prove that there are $PN$-graphs that are not $t$-spanners for any $t$. On\\nthe positive side we give sufficient conditions for a $PN$-graph to be a\\n$t$-spanner and prove that any $PN$-graph over $\\\\mathbb{R}^n$ under the\\neuclidean distance is a $t$-spanner.\\n</p>\\n', 'link': 'http://arxiv.org/abs/1404.1646'}, {'title': 'FLAME: A Fast Large-scale Almost Matching Exactly Approach to Causal Inference. (arXiv:1707.06315v9 [stat.ML] UPDATED)', 'description': '<p>A classical problem in causal inference is that of matching, where treatment\\nunits need to be matched to control units based on covariate information. In\\nthis work, we propose a method that computes high quality almost-exact matches\\nfor high-dimensional categorical datasets. This method, called FLAME (Fast\\nLarge-scale Almost Matching Exactly), learns a distance metric for matching\\nusing a hold-out training data set. In order to perform matching efficiently\\nfor large datasets, FLAME leverages techniques that are natural for query\\nprocessing in the area of database management, and two implementations of FLAME\\nare provided: the first uses SQL queries and the second uses bit-vector\\ntechniques. The algorithm starts by constructing matches of the highest quality\\n(exact matches on all covariates), and successively eliminates variables in\\norder to match exactly on as many variables as possible, while still\\nmaintaining interpretable high-quality matches and balance between treatment\\nand control groups. We leverage these high quality matches to estimate\\nconditional average treatment effects (CATEs). Our experiments show that FLAME\\nscales to huge datasets with millions of observations where existing\\nstate-of-the-art methods fail, and that it achieves significantly better\\nperformance than other matching methods.\\n</p>\\n', 'link': 'http://arxiv.org/abs/1707.06315'}, {'title': 'A New Approach To Estimate The Collision Probability For Automotive Applications. (arXiv:1711.07060v9 [eess.SY] UPDATED)', 'description': '<p>We revisit the computation of probability of collision in the context of\\nautomotive collision avoidance (the estimation of a potential collision is also\\nreferred to as conflict detection in other contexts). After reviewing existing\\napproaches to the definition and computation of a collision probability we\\nargue that the question \"What is the probability of collision within the next\\nthree seconds?\" can be answered on the basis of a collision probability rate.\\n</p>\\n<p>Using results on level crossings for vector stochastic processes we derive a\\ngeneral expression for the upper bound of the distribution of the collision\\nprobability rate. This expression is valid for arbitrary prediction models\\nincluding process noise.\\n</p>\\n<p>We demonstrate in several examples that distributions obtained by large-scale\\nMonte-Carlo simulations obey this bound and in many cases approximately\\nsaturate the bound. We derive an approximation for the distribution of the\\ncollision probability rate that can be computed on an embedded platform. An\\nupper bound of the probability of collision is then obtained by one-dimensional\\nnumerical integration over the time period of interest.\\n</p>\\n<p>A straightforward application of this method applies to the collision of an\\nextended object with a second point-like object. Using an abstraction of the\\nsecond object by salient points of its boundary we propose an application of\\nthis method to two extended objects with arbitrary orientation.\\n</p>\\n<p>Finally, the distribution of the collision probability rate is identified as\\nthe distribution of the time-to-collision.\\n</p>\\n', 'link': 'http://arxiv.org/abs/1711.07060'}, {'title': 'Spatial Deep Learning for Wireless Scheduling. (arXiv:1808.01486v3 [eess.SP] UPDATED)', 'description': '<p>The optimal scheduling of interfering links in a dense wireless network with\\nfull frequency reuse is a challenging task. The traditional method involves\\nfirst estimating all the interfering channel strengths then optimizing the\\nscheduling based on the model. This model-based method is however resource\\nintensive and computationally hard because channel estimation is expensive in\\ndense networks; furthermore, finding even a locally optimal solution of the\\nresulting optimization problem may be computationally complex. This paper shows\\nthat by using a deep learning approach, it is possible to bypass the channel\\nestimation and to schedule links efficiently based solely on the geographic\\nlocations of the transmitters and the receivers, due to the fact that in many\\npropagation environments, the wireless channel strength is largely a function\\nof the distance dependent path-loss. This is accomplished by unsupervised\\ntraining over randomly deployed networks, and by using a novel neural network\\narchitecture that computes the geographic spatial convolutions of the\\ninterfering or interfered neighboring nodes along with subsequent multiple\\nfeedback stages to learn the optimum solution. The resulting neural network\\ngives near-optimal performance for sum-rate maximization and is capable of\\ngeneralizing to larger deployment areas and to deployments of different link\\ndensities. Moreover, to provide fairness, this paper proposes a novel\\nscheduling approach that utilizes the sum-rate optimal scheduling algorithm\\nover judiciously chosen subsets of links for maximizing a proportional fairness\\nobjective over the network. The proposed approach shows highly competitive and\\ngeneralizable network utility maximization results.\\n</p>\\n', 'link': 'http://arxiv.org/abs/1808.01486'}, {'title': 'Improving the accuracy of nearest-neighbor classification using principled construction and stochastic sampling of training-set centroids. (arXiv:1809.02599v3 [cs.LG] UPDATED)', 'description': '<p>A conceptually simple way to classify images is to directly compare test-set\\ndata and training-set data. The accuracy of this approach is limited by the\\nmethod of comparison used, and by the extent to which the training-set data\\ncover configuration space. Here we show that this coverage can be substantially\\nincreased using coarse graining (replacing groups of images by their centroids)\\nand stochastic sampling (using distinct sets of centroids in combination). We\\nuse the MNIST and Fashion-MNIST data sets to show that a principled\\ncoarse-graining algorithm can convert training images into fewer image\\ncentroids without loss of accuracy of classification of test-set images by\\nnearest-neighbor classification. Distinct batches of centroids can be used in\\ncombination as a means of stochastically sampling configuration space, and can\\nclassify test-set data more accurately than can the unaltered training set. On\\nthe MNIST and Fashion-MNIST data sets this approach converts nearest-neighbor\\nclassification from a mid-ranking- to an upper-ranking member of the set of\\nclassical machine-learning techniques.\\n</p>\\n', 'link': 'http://arxiv.org/abs/1809.02599'}, {'title': 'How many matchings cover the nodes of a graph?. (arXiv:1811.07327v2 [math.CO] UPDATED)', 'description': \"<p>Given an undirected graph, are there $k$ matchings whose union covers all of\\nits nodes, that is, a matching-$k$-cover? A first, easy polynomial solution\\nfrom matroid union is possible, as already observed by Wang, Song and Yuan\\n(Mathematical Programming, 2014). However, it was not satisfactory neither from\\nthe algorithmic viewpoint nor for proving graphic theorems, since the\\ncorresponding matroid ignores the edges of the graph.\\n</p>\\n<p>We prove here, simply and algorithmically: all nodes of a graph can be\\ncovered with $k\\\\ge 2$ matchings if and only if for every stable set $S$ we have\\n$|S|\\\\le k\\\\cdot|N(S)|$. When $k=1$, an exception occurs: this condition is not\\nenough to guarantee the existence of a matching-$1$-cover, that is, the\\nexistence of a perfect matching, in this case Tutte's famous matching theorem\\n(J. London Math. Soc., 1947) provides the right `good' characterization. The\\ncondition above then guarantees only that a perfect $2$-matching exists, as\\nknown from another theorem of Tutte (Proc. Amer. Math. Soc., 1953).\\n</p>\\n<p>Some results are then deduced as consequences with surprisingly simple\\nproofs, using only the level of difficulty of bipartite matchings. We give some\\ngeneralizations, as well as a solution for minimization if the edge-weights are\\nnon-negative, while the edge-cardinality maximization of matching-$2$-covers\\nturns out to be already NP-hard.\\n</p>\\n<p>We have arrived at this problem as the line graph special case of a model\\narising for manufacturing integrated circuits with the technology called\\n`Directed Self Assembly'.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/1811.07327'}, {'title': 'First-order Newton-type Estimator for Distributed Estimation and Inference. (arXiv:1811.11368v2 [stat.ML] UPDATED)', 'description': '<p>This paper studies distributed estimation and inference for a general\\nstatistical problem with a convex loss that could be non-differentiable. For\\nthe purpose of efficient computation, we restrict ourselves to stochastic\\nfirst-order optimization, which enjoys low per-iteration complexity. To\\nmotivate the proposed method, we first investigate the theoretical properties\\nof a straightforward Divide-and-Conquer Stochastic Gradient Descent (DC-SGD)\\napproach. Our theory shows that there is a restriction on the number of\\nmachines and this restriction becomes more stringent when the dimension $p$ is\\nlarge. To overcome this limitation, this paper proposes a new multi-round\\ndistributed estimation procedure that approximates the Newton step only using\\nstochastic subgradient. The key component in our method is the proposal of a\\ncomputationally efficient estimator of $\\\\Sigma^{-1} w$, where $\\\\Sigma$ is the\\npopulation Hessian matrix and $w$ is any given vector. Instead of estimating\\n$\\\\Sigma$ (or $\\\\Sigma^{-1}$) that usually requires the second-order\\ndifferentiability of the loss, the proposed First-Order Newton-type Estimator\\n(FONE) directly estimates the vector of interest $\\\\Sigma^{-1} w$ as a whole and\\nis applicable to non-differentiable losses. Our estimator also facilitates the\\ninference for the empirical risk minimizer. It turns out that the key term in\\nthe limiting covariance has the form of $\\\\Sigma^{-1} w$, which can be estimated\\nby FONE.\\n</p>\\n', 'link': 'http://arxiv.org/abs/1811.11368'}, {'title': 'Complexity-Theoretic Aspects of Expanding Cellular Automata. (arXiv:1902.05487v3 [cs.CC] UPDATED)', 'description': '<p>The expanding cellular automata (XCA) variant of cellular automata is\\ninvestigated and characterized from a complexity-theoretical standpoint. An XCA\\nis a one-dimensional cellular automaton which can dynamically create new cells\\nbetween existing ones. The respective polynomial-time complexity class is shown\\nto coincide with ${\\\\le_{tt}^p}(\\\\mathsf{NP})$, that is, the class of decision\\nproblems polynomial-time truth-table reducible to problems in $\\\\mathsf{NP}$. An\\nalternative characterization based on a variant of non-deterministic Turing\\nmachines is also given. In addition, corollaries on select XCA variants are\\nproven: XCAs with multiple accept and reject states are shown to be\\npolynomial-time equivalent to the original XCA model. Finally, XCAs with\\nalternative acceptance conditions are considered and classified in terms of\\n${\\\\le_{tt}^p}(\\\\mathsf{NP})$ and the Turing machine polynomial-time class\\n$\\\\mathsf{P}$.\\n</p>\\n', 'link': 'http://arxiv.org/abs/1902.05487'}, {'title': 'Memory Augmented Neural Network Adaptive Controllers: Performance and Stability. (arXiv:1905.02832v13 [cs.SY] UPDATED)', 'description': '<p>In this paper, we propose a novel control architecture, inspired from\\nneuroscience, for adaptive control of continuous-time systems. A key objective\\nexplored in this paper is to design control architectures and algorithms that\\ncan {\\\\it learn and adapt quickly to changes that are even abrupt}. The proposed\\narchitecture, in the setting of standard neural network (NN) based adaptive\\ncontrol, augments an {\\\\it external working memory} to the NN. The controller\\nthrough a write operation, writes the hidden layer feature vector of the NN to\\nthe external working memory and can also update this information with the\\nobserved error in the output. The controller through a read operation retrieves\\ninformation from the working memory to modify the final control signal.\\nPrimarily, the use of external working memory is aimed at improving the context\\nthereby inducing the learning system to search in a particular direction. This\\ndirected learning allows the learning system to find a good approximation of\\nthe unknown function even after abrupt changes quickly. We consider a model\\nreference NN adaptive controller for linear systems with matched uncertainty\\nfor concrete development of our ideas. We prove that the resulting controller\\nleads to Uniformly Bounded (UB) stable closed loop system. Through extensive\\nsimulations and specific metrics we show that memory augmentation improves\\nlearning significantly even when the system undergoes sudden changes.\\n</p>\\n', 'link': 'http://arxiv.org/abs/1905.02832'}, {'title': 'Variational Federated Multi-Task Learning. (arXiv:1906.06268v2 [cs.LG] UPDATED)', 'description': '<p>In federated learning, a central server coordinates the training of a single\\nmodel on a massively distributed network of devices. This setting can be\\nnaturally extended to a multi-task learning framework, to handle real-world\\nfederated datasets that typically show strong statistical heterogeneity among\\ndevices. Despite federated multi-task learning being shown to be an effective\\nparadigm for real-world datasets, it has been applied only on convex models. In\\nthis work, we introduce VIRTUAL, an algorithm for federated multi-task learning\\nfor general non-convex models. In VIRTUAL the federated network of the server\\nand the clients is treated as a star-shaped Bayesian network, and learning is\\nperformed on the network using approximated variational inference. We show that\\nthis method is effective on real-world federated datasets, outperforming the\\ncurrent state-of-the-art for federated learning, and concurrently allowing\\nsparser gradient updates.\\n</p>\\n', 'link': 'http://arxiv.org/abs/1906.06268'}, {'title': 'On linear convergence of two decentralized algorithms. (arXiv:1906.07225v2 [math.OC] UPDATED)', 'description': '<p>Decentralized algorithms solve multi-agent problems over a connected network,\\nwhere the information can only be exchanged with the accessible neighbors.\\nThough there exist several decentralized optimization algorithms, there are\\nstill gaps in convergence conditions and rates between decentralized and\\ncentralized algorithms. In this paper, we fill some gaps by considering two\\ndecentralized algorithms: EXTRA and NIDS. They both converge linearly with\\nstrongly convex objective functions. We will answer two questions regarding\\nthem. What are the optimal upper bounds for their stepsizes? Do decentralized\\nalgorithms require more properties on the functions for linear convergence than\\ncentralized ones? More specifically, we relax the required conditions for\\nlinear convergence of both algorithms. For EXTRA, we show that the stepsize is\\ncomparable to that of centralized algorithms. For NIDS, the upper bound of the\\nstepsize is shown to be exactly the same as the centralized ones. In addition,\\nwe relax the requirement for the objective functions and the mixing matrices.\\nWe provide the linear convergence results for both algorithms under the weakest\\nconditions.\\n</p>\\n', 'link': 'http://arxiv.org/abs/1906.07225'}, {'title': 'Lags in the Release, Adoption, and Propagation of npm Vulnerability Fixes. (arXiv:1907.03407v4 [cs.SE] UPDATED)', 'description': '<p>Security vulnerability in third-party dependencies is a growing concern not\\nonly for developers of the affected software, but for the risks it poses to an\\nentire software ecosystem, e.g., Heartbleed vulnerability. Recent studies show\\nthat developers are slow to respond to the threat of vulnerability, sometimes\\ntaking four to eleven months to act. To ensure quick adoption and propagation\\nof a release that contains the fix (fixing release), we conduct an empirical\\ninvestigation to identify lags that may occur between the vulnerable release\\nand its fixing release (package-side fixing release). Through a preliminary\\nstudy of 231 package-side fixing release of npm projects on GitHub, we observe\\nthat a fixing release is rarely released on its own, with up to 85.72% of the\\nbundled commits being unrelated to a fix. We then compare the package-side\\nfixing release with changes on a client-side (client-side fixing release).\\nThrough an empirical study of the adoption and propagation tendencies of 1,290\\npackage-side fixing releases that impact throughout a network of 1,553,325\\nreleases of npm packages, we find that stale clients require additional\\nmigration effort, even if the package-side fixing release was quick (i.e.,\\npackage patch landing). Furthermore, we show the influence of factors such as\\nthe branch that the package-side fixing release lands on and the severity of\\nvulnerability on its propagation. In addition to these lags we identify and\\ncharacterize, this paper lays the groundwork for future research on how to\\nmitigate lags in an ecosystem.\\n</p>\\n', 'link': 'http://arxiv.org/abs/1907.03407'}, {'title': 'On the Optimality of Reconfigurable Intelligent Surfaces (RISs): Passive Beamforming, Modulation, and Resource Allocation. (arXiv:1910.00968v2 [cs.IT] UPDATED)', 'description': '<p>Reconfigurable intelligent surfaces (RISs) have recently emerged as a\\npromising technology that can achieve high spectrum and energy efficiency for\\nfuture wireless networks by integrating a massive number of low-cost and\\npassive reflecting elements. An RIS can manipulate the properties of an\\nincident wave, such as the frequency, amplitude, and phase, and, then, reflect\\nthis manipulated wave to a desired destination, without the need for complex\\nsignal processing. In this paper, the asymptotic optimality of achievable rate\\nin a downlink RIS system is analyzed under a practical RIS environment with its\\nassociated limitations. In particular, a passive beamformer that can achieve\\nthe asymptotic optimal performance by controlling the incident wave properties\\nis designed, under a limited RIS control link and practical reflection\\ncoefficients. In order to increase the achievable system sum-rate, a modulation\\nscheme that can be used in an RIS without interfering with existing users is\\nproposed and its average symbol error ratio is asymptotically derived.\\nMoreover, a new resource allocation algorithm that jointly considers user\\nscheduling and power control is designed, under consideration of the proposed\\npassive beamforming and modulation schemes. Simulation results show that the\\nproposed schemes are in close agreement with their upper bounds in presence of\\na large number of RIS reflecting elements thereby verifying that the achievable\\nrate in practical RISs satisfies the asymptotic optimality.\\n</p>\\n', 'link': 'http://arxiv.org/abs/1910.00968'}, {'title': 'Stochastic Optimal Control of HVAC system for Energy-efficient Buildings. (arXiv:1911.00840v3 [eess.SY] UPDATED)', 'description': '<p>The heating, ventilation and air-conditioning (HVAC) system accounts for\\nsubstantial energy use in buildings, whereas a large group of occupants are\\nstill not actually feeling comfortable staying inside. This poses the issue of\\ndeveloping energy-efficient HVAC control, i.e., reduce energy use (cost) while\\nsimultaneously enhancing human comfort. This paper pursues the objective and\\nstudies the stochastic optimal HVAC control subject to uncertain thermal demand\\n(i.e., the weather and occupancy etc). Particularly, we involve the elaborate\\npredicted mean vote (PMV) thermal comfort model in the optimization. The\\nproblem is computationally challenging due to the non-linear and non-analytical\\nconstraints imposed by the system dynamics and PMV model. We make the following\\ncontributions to address it. First, we formulate the problem as a Markov\\ndecision process (MDP) which is a desirable modeling technique capable of\\nhandling the complexities. Second, we propose a gradient-based learning (GB-L)\\nmethod for progressively learning a stochastic control policy off-line and\\nstore it for on-line execution. Third, we prove the learning method converge to\\nthe optimal policies theoretically, and its performance (i.e., energy cost,\\nthermal comfort and on-line computation) for HVAC control via simulations. The\\ncomparisons with the existing model predictive control based relaxation (MPC-R)\\nmethod which is assumed with accurate future information and supposed to\\nprovide the near-optimal bounds, show that though there exists some performance\\nloss in energy cost reduction (i.e., 6.5%), the proposed method can enable\\nefficient on-line implementation (less than 1 second) and provide high\\nprobability of thermal comfort under uncertainties.\\n</p>\\n', 'link': 'http://arxiv.org/abs/1911.00840'}, {'title': 'Space-time multilevel Monte Carlo methods and their application to cardiac electrophysiology. (arXiv:1911.06066v2 [cs.CE] UPDATED)', 'description': '<p>We present a novel approach aimed at high-performance uncertainty\\nquantification for time-dependent problems governed by partial differential\\nequations. In particular, we consider input uncertainties described by a\\nKarhunen-Loeeve expansion and compute statistics of high-dimensional\\nquantities-of-interest, such as the cardiac activation potential. Our\\nmethodology relies on a close integration of multilevel Monte Carlo methods,\\nparallel iterative solvers, and a space-time discretization. This combination\\nallows for space-time adaptivity, time-changing domains, and to take advantage\\nof past samples to initialize the space-time solution. The resulting sequence\\nof problems is distributed using a multilevel parallelization strategy,\\nallocating batches of samples having different sizes to a different number of\\nprocessors. We assess the performance of the proposed framework by showing in\\ndetail its application to the solution of nonlinear equations arising from\\ncardiac electrophysiology. Specifically, we study the effect of\\nspatially-correlated perturbations of the heart fibers conductivities on the\\nmean and variance of the resulting activation map. As shown by the experiments,\\nthe theoretical rates of convergence of multilevel Monte Carlo are achieved.\\nMoreover, the total computational work for a prescribed accuracy is reduced by\\nan order of magnitude with respect to standard Monte Carlo methods.\\n</p>\\n', 'link': 'http://arxiv.org/abs/1911.06066'}, {'title': 'Semantic Segmentation for Compound figures. (arXiv:1912.07142v3 [cs.CV] UPDATED)', 'description': '<p>Scientific literature contains large volumes of unstructured data,with over\\n30\\\\% of figures constructed as a combination of multiple images, these compound\\nfigures cannot be analyzed directly with existing information retrieval tools.\\nIn this paper, we propose a semantic segmentation approach for compound figure\\nseparation, decomposing the compound figures into \"master images\". Each master\\nimage is one part of a compound figure governed by a subfigure label (typically\\n\"(a), (b), (c), etc\"). In this way, the separated subfigures can be easily\\nassociated with the description information in the caption. In particular, we\\npropose an anchor-based master image detection algorithm, which leverages the\\ncorrelation between master images and subfigure labels and locates the master\\nimages in a two-step manner. First, a subfigure label detector is built to\\nextract the global layout information of the compound figure. Second, the\\nlayout information is combined with local features to locate the master images.\\nWe validate the effectiveness of proposed method on our labeled testing dataset\\nboth quantitatively and qualitatively.\\n</p>\\n', 'link': 'http://arxiv.org/abs/1912.07142'}, {'title': 'In Nomine Function: Naming Functions in Stripped Binaries with Neural Networks. (arXiv:1912.07946v3 [cs.LG] UPDATED)', 'description': '<p>In this paper we investigate the problem of automatically naming pieces of\\nassembly code. Where by naming we mean assigning to an assembly function a\\nstring of words that would likely be assigned by a human reverse engineer. We\\nformally and precisely define the framework in which our investigation takes\\nplace. That is we define the problem, we provide reasonable justifications for\\nthe choices that we made for the design of training and the tests. We performed\\nan analysis on a large real-world corpora constituted by nearly 9 millions of\\nfunctions taken from more than 22k softwares. In such framework we test\\nbaselines coming from the field of Natural Language Processing (e.g., Seq2Seq\\nnetworks and Transformer). Interestingly, our evaluation shows promising\\nresults beating the state-of-the-art and reaching good performance. We\\ninvestigate the applicability of tine-tuning (i.e., taking a model already\\ntrained on a large generic corpora and retraining it for a specific task). Such\\ntechnique is popular and well-known in the NLP field. Our results confirm that\\nfine-tuning is effective even when neural networks are applied to binaries. We\\nshow that a model, pre-trained on the aforementioned corpora, when fine-tuned\\nhas higher performances on specific domains (such as predicting names in system\\nutilites, malware, etc).\\n</p>\\n', 'link': 'http://arxiv.org/abs/1912.07946'}, {'title': 'A Theory of Trotter Error. (arXiv:1912.08854v3 [quant-ph] UPDATED)', 'description': '<p>The Lie-Trotter formula, together with its higher-order generalizations,\\nprovides a direct approach to decomposing the exponential of a sum of\\noperators. Despite significant effort, the error scaling of such product\\nformulas remains poorly understood. We develop a theory of Trotter error that\\novercomes the limitations of prior approaches based on truncating the\\nBaker-Campbell-Hausdorff expansion. Our analysis directly exploits the\\ncommutativity of operator summands, producing tighter error bounds for both\\nreal- and imaginary-time evolutions. Whereas previous work achieves similar\\ngoals for systems with geometric locality or Lie-algebraic structure, our\\napproach holds in general. We give a host of improved algorithms for digital\\nquantum simulation and quantum Monte Carlo methods, including simulations of\\nsecond-quantized plane-wave electronic structure, $k$-local Hamiltonians,\\nrapidly decaying power-law interactions, clustered Hamiltonians, the transverse\\nfield Ising model, and quantum ferromagnets, nearly matching or even\\noutperforming the best previous results. We obtain further speedups using the\\nfact that product formulas can preserve the locality of the simulated system.\\nSpecifically, we show that local observables can be simulated with complexity\\nindependent of the system size for power-law interacting systems, which implies\\na Lieb-Robinson bound as a byproduct. Our analysis reproduces known tight\\nbounds for first- and second-order formulas. Our higher-order bound\\noverestimates the complexity of simulating a one-dimensional Heisenberg model\\nwith an even-odd ordering of terms by only a factor of $5$, and is close to\\ntight for power-law interactions and other orderings of terms. This suggests\\nthat our theory can accurately characterize Trotter error in terms of both\\nasymptotic scaling and constant prefactor.\\n</p>\\n', 'link': 'http://arxiv.org/abs/1912.08854'}, {'title': 'A Deep Learning Algorithm for High-Dimensional Exploratory Item Factor Analysis. (arXiv:2001.07859v4 [stat.ME] UPDATED)', 'description': \"<p>Marginal maximum likelihood (MML) estimation is the preferred approach to\\nfitting item response theory models in psychometrics due to the MML estimator's\\nconsistency, normality, and efficiency as the sample size tends to infinity.\\nHowever, state-of-the-art MML estimation procedures such as the\\nMetropolis-Hastings Robbins-Monro (MH-RM) algorithm as well as approximate MML\\nestimation procedures such as variational inference (VI) are computationally\\ntime-consuming when the sample size and the number of latent factors are very\\nlarge. In this work, we investigate a deep learning-based VI algorithm for\\nexploratory item factor analysis (IFA) that is computationally fast even in\\nlarge data sets with many latent factors. The proposed approach applies a deep\\nartificial neural network model called an importance-weighted autoencoder\\n(IWAE) for exploratory IFA. The IWAE approximates the MML estimator using an\\nimportance sampling technique wherein increasing the number of\\nimportance-weighted (IW) samples drawn during fitting improves the\\napproximation, typically at the cost of decreased computational efficiency. We\\nprovide a real data application that recovers results aligning with\\npsychological theory across random starts. Via simulation studies, we show that\\nthe IWAE yields more accurate estimates as either the sample size or the number\\nof IW samples increases (although factor correlation and intercepts estimates\\nexhibit some bias) and obtains similar results to MH-RM in less time. Our\\nsimulations also suggest that the proposed approach performs similarly to and\\nis potentially faster than constrained joint maximum likelihood estimation, a\\nfast procedure that is consistent when the sample size and the number of items\\nsimultaneously tend to infinity.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2001.07859'}, {'title': 'Simultaneous State and Unknown Input Set-Valued Observers for Some Classes of Nonlinear Dynamical Systems. (arXiv:2001.10125v2 [eess.SY] UPDATED)', 'description': '<p>In this paper, we propose fixed-order set-valued (in the form of l2-norm\\nhyperballs) observers for some classes of nonlinear bounded-error dynamical\\nsystems with unknown input signals that simultaneously find bounded hyperballs\\nof states and unknown inputs that include the true states and inputs. Necessary\\nand sufficient conditions in the form of Linear Matrix Inequalities (LMIs) for\\nthe stability (in the sense of quadratic stability) of the proposed observers\\nare derived for ($\\\\mathcal{M},\\\\gamma$)- Quadratically Constrained\\n(($\\\\mathcal{M},\\\\gamma$)-QC) systems, which includes several classes of\\nnonlinear systems: (I) Lipschitz continuous, (II) ($\\\\mathcal{A},\\\\gamma$)-QC*\\nand (III) Linear Parameter-Varying (LPV) systems. This new quadratic constraint\\nproperty is at least as general as the incremental quadratic constraint\\nproperty for nonlinear systems and is proven in the paper to embody a broad\\nrange of nonlinearities. In addition, we design the optimal\\n$\\\\mathcal{H}_{\\\\infty}$ observer among those that satisfy the quadratic\\nstability conditions and show that the design results in Uniformly\\nBounded-Input Bounded-State (UBIBS) estimate radii/error dynamics and uniformly\\nbounded sequences of the estimate radii. Furthermore, we provide closed-form\\nupper bound sequences for the estimate radii and sufficient condition for their\\nconvergence to steady state. Finally, the effectiveness of the proposed\\nset-valued observers is demonstrated through illustrative examples, where we\\ncompare the performance of our observers with some existing observers.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2001.10125'}, {'title': 'Zeta Functions and the (Linear) Logic of Markov Processes. (arXiv:2001.11906v3 [cs.LO] UPDATED)', 'description': '<p>In a series of papers, the author introduced models of linear logic known as\\n\"Interaction Graphs\". These models generalise Girard\\'s various geometry of\\ninteraction constructions, providing a unifying framework for those. In this\\nwork, we exhibit how these models can be understood mathematically through a\\ncocycle property satisfied by zeta functions of dynamical systems. Focussing on\\nprobabilistic models, we then explain how the notion of graphings used in the\\nmodels captures a natural class of Markov processes. We further extend previous\\nconstructions to provide a model of second-order linear logic as a type system\\nover the set of all (discrete-time) sub-Markov processes.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2001.11906'}, {'title': 'Bidirectional Trajectory Computation for Odometer-Aided Visual-Inertial SLAM. (arXiv:2002.00195v2 [cs.RO] UPDATED)', 'description': '<p>Odometer-aided visual-inertial SLAM systems typically have a good performance\\nfor navigation of wheeled platforms, while they usually suffer from degenerate\\ncases before the first turning. In this paper, firstly we perform an\\nobservability analysis w.r.t. the extrinsic parameters before the first\\nturning, which is a complement of the existing results of observability\\nanalyses. Secondly, inspired by the above observability analyses, we propose a\\nbidirectional trajectory computation method, by which the poses before the\\nfirst turning are refined in the backward computation thread, and the real-time\\ntrajectory is adjusted accordingly. Experimental results prove that our\\nproposed method not only solves the problem of the unobservability of\\naccelerometer bias and extrinsic parameters before the first turning, but also\\nresults in more accurate trajectories in comparison with the state-of-the-art\\napproaches.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2002.00195'}, {'title': 'Lower bounds for algebraic machines, semantically. (arXiv:2002.10888v2 [cs.CC] UPDATED)', 'description': '<p>This paper presents a new semantic method for proving lower bounds in\\ncomputational complexity. We use it to prove that maxflow, a PTIME complete\\nproblem, is not computable in polylogarithmic time on parallel random access\\nmachines (PRAMs) working with integers, showing that NCZ \\\\neq PTIME, where NCZ\\nis the complexity class defined by such machines, and PTIME is the standard\\nclass of polynomial time computable problems (on, say, a Turing machine). On\\ntop of showing this new separation result, we show our method captures previous\\nlower bounds results from the literature: Steele and Yao\\'s lower bounds for\\nalgebraic decision trees, Ben-Or\\'s lower bounds for algebraic computation\\ntrees, Cucker\\'s proof that NC is not equal to PTIME on the reals, and\\nMulmuley\\'s lower bounds for \"PRAMs without bit operations\".\\n</p>\\n', 'link': 'http://arxiv.org/abs/2002.10888'}, {'title': 'Fast Linear Convergence of Randomized BFGS. (arXiv:2002.11337v4 [math.OC] UPDATED)', 'description': \"<p>Since the late 1950's when quasi-Newton methods first appeared, they have\\nbecome one of the most widely used and efficient algorithmic paradigms for\\nunconstrained optimization. Despite their immense practical success, there is\\nlittle theory that shows why these methods are so efficient. We provide a\\nsemi-local rate of convergence for the randomized BFGS method which can be\\nsignificantly better than that of gradient descent, finally giving theoretical\\nevidence supporting the superior empirical performance of the method.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2002.11337'}, {'title': 'Pursuing Sources of Heterogeneity in Modeling Clustered Population. (arXiv:2003.04787v2 [stat.ME] UPDATED)', 'description': \"<p>Researchers often have to deal with heterogeneous population with mixed\\nregression relationships, increasingly so in the era of data explosion. In such\\nproblems, when there are many candidate predictors, it is not only of interest\\nto identify the predictors that are associated with the outcome, but also to\\ndistinguish the true sources of heterogeneity, i.e., to identify the predictors\\nthat have different effects among the clusters and thus are the true\\ncontributors to the formation of the clusters. We clarify the concepts of the\\nsource of heterogeneity that account for potential scale differences of the\\nclusters and propose a regularized finite mixture effects regression to achieve\\nheterogeneity pursuit and feature selection simultaneously. As the name\\nsuggests, the problem is formulated under an effects-model parameterization, in\\nwhich the cluster labels are missing and the effect of each predictor on the\\noutcome is decomposed to a common effect term and a set of cluster-specific\\nterms. A constrained sparse estimation of these effects leads to the\\nidentification of both the variables with common effects and those with\\nheterogeneous effects. We propose an efficient algorithm and show that our\\napproach can achieve both estimation and selection consistency. Simulation\\nstudies further demonstrate the effectiveness of our method under various\\npractical scenarios. Three applications are presented, namely, an imaging\\ngenetics study for linking genetic factors and brain neuroimaging traits in\\nAlzheimer's disease, a public health study for exploring the association\\nbetween suicide risk among adolescents and their school district\\ncharacteristics, and a sport analytics study for understanding how the salary\\nlevels of baseball players are associated with their performance and\\ncontractual status.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2003.04787'}, {'title': 'Answering Complex Queries in Knowledge Graphs with Bidirectional Sequence Encoders. (arXiv:2004.02596v4 [cs.AI] UPDATED)', 'description': '<p>Representation learning for knowledge graphs (KGs) has focused on the problem\\nof answering simple link prediction queries. In this work we address the more\\nambitious challenge of predicting the answers of conjunctive queries with\\nmultiple missing entities. We propose Bi-Directional Query Embedding (BIQE), a\\nmethod that embeds conjunctive queries with models based on bi-directional\\nattention mechanisms. Contrary to prior work, bidirectional self-attention can\\ncapture interactions among all the elements of a query graph. We introduce a\\nnew dataset for predicting the answer of conjunctive query and conduct\\nexperiments that show BIQE significantly outperforming state of the art\\nbaselines.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2004.02596'}, {'title': 'A Fair and Privacy-Aware EV Discharging Strategy using Decentralized Whale Optimization Algorithm for Minimizing Cost of EVs and the EV Aggregator. (arXiv:2004.05280v2 [eess.SY] UPDATED)', 'description': '<p>A key motivation to fasten roll-out of electric vehicles (EVs) to the market\\nis to implement Vehicle-to-Grid (V2G) functionalities. With V2G in place, EV\\nowners can have extra freedom to interact their battery energy with power\\ngrids, namely by selling their energy to the grid when their EVs are not in\\nuse. On the other hand, EV aggregators and utility companies can leverage the\\nflexibility of the collected energy to implement various ancillary services to\\nthe grids, which may significantly reduce costs of, for instance, running\\nspinning reserve of traditional power plants on the grid side. However, this\\nextra freedom also poses practical challenges in terms of how to devise a\\ndischarging strategy for a group of EVs that is fair and in some sense optimal.\\nIn this paper, we present a new design of EV discharging strategy in a typical\\nV2G energy trading framework whilst leveraging the whale optimization algorithm\\nin a decentralized manner, a metaheuristic algorithm that has been shown\\neffective in solving large-scale centralized optimization problems. We\\ndemonstrate that by using simple ideas of data shuffling and aggregation, one\\ncan design an EV discharging strategy in a fair, optimal and privacy-aware\\nmanner, where the privacy refers to the fact that no critical information of\\nEVs should be exchanged with the EV aggregator, and vice versa. The fairness\\nimplies that a common discharge rate needs to be sought for all EVs so that no\\none gets better benefits than others in the same V2G programme. Simulation\\nresults are presented to illustrate the efficacy of our proposed system.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2004.05280'}, {'title': 'Cross-lingual Contextualized Topic Models with Zero-shot Learning. (arXiv:2004.07737v2 [cs.CL] UPDATED)', 'description': '<p>Many data sets (e.g., reviews, forums, news, etc.) exist parallelly in\\nmultiple languages. They all cover the same content, but the linguistic\\ndifferences make it impossible to use traditional, bag-of-word-based topic\\nmodels. Models have to be either single-language or suffer from a huge, but\\nextremely sparse vocabulary. Both issues can be addressed by transfer learning.\\nIn this paper, we introduce a zero-shot cross-lingual topic model. Our model\\nlearns topics on one language (here, English), and predicts them for unseen\\ndocuments in different languages (here, Italian, French, German, and\\nPortuguese). We evaluate the quality of the topic predictions for the same\\ndocument in different languages. Our results show that the transferred topics\\nare coherent and stable across languages, which suggests exciting future\\nresearch directions.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2004.07737'}, {'title': 'Elastic weight consolidation for better bias inoculation. (arXiv:2004.14366v2 [cs.CL] UPDATED)', 'description': '<p>The biases present in training datasets have been shown to affect models for\\nsentence pair classification tasks such as natural language inference (NLI) and\\nfact verification. While fine-tuning models on additional data has been used to\\nmitigate them, a common issue is that of catastrophic forgetting of the\\noriginal training dataset. In this paper, we show that elastic weight\\nconsolidation (EWC) allows fine-tuning of models to mitigate biases while being\\nless susceptible to catastrophic forgetting. In our evaluation on fact\\nverification and NLI stress tests, we show that fine-tuning with EWC dominates\\nstandard fine-tuning, yielding models with lower levels of forgetting on the\\noriginal (biased) dataset for equivalent gains in accuracy on the fine-tuning\\n(unbiased) dataset.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2004.14366'}, {'title': 'IsoBN: Fine-Tuning BERT with Isotropic Batch Normalization. (arXiv:2005.02178v2 [cs.CL] UPDATED)', 'description': '<p>Fine-tuning pre-trained language models (PTLMs), such as BERT and its better\\nvariant RoBERTa, has been a common practice for advancing performance in\\nnatural language understanding (NLU) tasks. Recent advance in representation\\nlearning shows that isotropic (i.e., unit-variance and uncorrelated) embeddings\\ncan significantly improve performance on downstream tasks with faster\\nconvergence and better generalization. The isotropy of the pre-trained\\nembeddings in PTLMs, however, is relatively under-explored. In this paper, we\\nanalyze the isotropy of the pre-trained [CLS] embeddings of PTLMs with\\nstraightforward visualization, and point out two major issues: high variance in\\ntheir standard deviation, and high correlation between different dimensions. We\\nalso propose a new network regularization method, isotropic batch normalization\\n(IsoBN) to address the issues, towards learning more isotropic representations\\nin fine-tuning by dynamically penalizing dominating principal components. This\\nsimple yet effective fine-tuning method yields about 1.0 absolute increment on\\nthe average of seven NLU tasks.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2005.02178'}, {'title': 'From industry-wide parameters to aircraft-centric on-flight inference: improving aeronautics performance prediction with machine learning. (arXiv:2005.05286v3 [stat.AP] UPDATED)', 'description': '<p>Aircraft performance models play a key role in airline operations, especially\\nin planning a fuel-efficient flight. In practice, manufacturers provide\\nguidelines which are slightly modified throughout the aircraft life cycle via\\nthe tuning of a single factor, enabling better fuel predictions. However this\\nhas limitations, in particular they do not reflect the evolution of each\\nfeature impacting the aircraft performance. Our goal here is to overcome this\\nlimitation. The key contribution of the present article is to foster the use of\\nmachine learning to leverage the massive amounts of data continuously recorded\\nduring flights performed by an aircraft and provide models reflecting its\\nactual and individual performance. We illustrate our approach by focusing on\\nthe estimation of the drag and lift coefficients from recorded flight data. As\\nthese coefficients are not directly recorded, we resort to aerodynamics\\napproximations. As a safety check, we provide bounds to assess the accuracy of\\nboth the aerodynamics approximation and the statistical performance of our\\napproach. We provide numerical results on a collection of machine learning\\nalgorithms. We report excellent accuracy on real-life data and exhibit\\nempirical evidence to support our modelling, in coherence with aerodynamics\\nprinciples.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2005.05286'}, {'title': 'Increasing-Margin Adversarial (IMA) Training to Improve Adversarial Robustness of Neural Networks. (arXiv:2005.09147v3 [cs.CV] UPDATED)', 'description': '<p>Convolutional neural network (CNN) has surpassed traditional methods for\\nmed-ical image classification. However, CNN is vulnerable to adversarial\\nattacks which may lead to disastrous consequences in medical applications.\\nAlthough adversarial noises are usually generated by attack algorithms,\\nwhite-noise-induced adversarial samples can exist, and therefore the threats\\nare real. In this study, we propose a novel training method, named IMA, to\\nimprove the robust-ness of CNN against adversarial noises. During training, the\\nIMA method in-creases the margins of training samples in the input space, i.e.,\\nmoving CNN de-cision boundaries far away from the training samples to improve\\nrobustness. The IMA method is evaluated on four publicly available datasets\\nunder strong 100-PGD white-box adversarial attacks, and the results show that\\nthe proposed meth-od significantly improved CNN classification accuracy on\\nnoisy data while keep-ing a relatively high accuracy on clean data. We hope our\\napproach may facilitate the development of robust applications in medical\\nfield.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2005.09147'}, {'title': 'Analyzing the Impact of Covid-19 Control Policies on Campus Occupancy and Mobility via Passive WiFi Sensing. (arXiv:2005.12050v3 [cs.CY] UPDATED)', 'description': \"<p>Mobile sensing has played a key role in providing digital solutions to aid\\nwith COVID-19 containment policies. These solutions include, among other\\nefforts, enforcing social distancing and monitoring crowd movements in indoor\\nspaces. However, such solutions may not be effective without mass adoption. As\\nmore and more countries reopen from lockdowns, there remains a pressing need to\\nminimize crowd movements and interactions, particularly in enclosed spaces.\\nThis paper conjectures that analyzing user occupancy and mobility via deployed\\nWiFi infrastructure can help institutions monitor and maintain safety\\ncompliance according to the public health guidelines. Using smartphones as a\\nproxy for user location, our analysis demonstrates how coarse-grained WiFi data\\ncan sufficiently reflect indoor occupancy spectrum when different COVID-19\\npolicies were enacted. Our work analyzes staff and students' mobility data from\\nthree different university campuses. Two of these campuses are in Singapore,\\nand the third is in the Northeastern United States. Our results show that\\nonline learning, split-team, and other space management policies effectively\\nlower occupancy. However, they do not change the mobility for individuals\\ntransitioning between spaces. We demonstrate how this data source can be put to\\npractical application for institutional crowd control and discuss the\\nimplications of our findings for policy-making.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2005.12050'}, {'title': 'Topological Drawings meet Classical Theorems from Convex Geometry. (arXiv:2005.12568v3 [math.CO] UPDATED)', 'description': '<p>In this article we discuss classical theorems from Convex Geometry in the\\ncontext of topological drawings and beyond. In a simple topological drawing of\\nthe complete graph $K_n$, any two edges share at most one point: either a\\ncommon vertex or a point where they cross. Triangles of simple topological\\ndrawings can be viewed as convex sets. This gives a link to convex geometry.\\n</p>\\n<p>As our main result, we present a generalization of Kirchberger\\'s Theorem that\\nis of purely combinatorial nature. It turned out that this classical theorem\\nalso applies to \"generalized signotopes\" - a combinatorial generalization of\\nsimple topological drawings, which we introduce and investigate in the course\\nof this article. As indicated by the name they are a generalization of\\nsignotopes, a structure studied in the context of encodings for arrangements of\\npseudolines.\\n</p>\\n<p>We also present a family of simple topological drawings with arbitrarily\\nlarge Helly number, and a new proof of a topological generalization of\\nCarath\\\\\\'{e}odory\\'s Theorem in the plane and discuss further classical theorems\\nfrom Convex Geometry in the context of simple topological drawings.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2005.12568'}, {'title': 'Spatial organisation of French research from the scholarly publication standpoint (1999-2017): Long-standing dynamics and policy-induced disorder. (arXiv:2005.13240v3 [cs.DL] UPDATED)', 'description': \"<p>In social processes, long-term trends can be influenced or disrupted by\\nvarious factors, including public policy. When public policies depend on a\\nmisrepresentation of trends in the areas they are aimed at, they become random\\nand disruptive, which can be interpreted as a source of disorder. Here we\\nconsider policies on the spatial organization of the French Higher Education\\nand Research system, which reflects the authorities' hypothesis that scientific\\nexcellence is the prerogative of a few large urban agglomerations. By\\ngeographically identifying all the French publications listed in the Web of\\nScience databases between 1999 and 2017, we highlight a spatial deconcentration\\ntrend, which has slowed down in recent years due to a freezed growth of the\\nteaching force. This deconcentration continues, however, to sustain the growth\\nof scientific production in small and medium-sized towns. An examination of the\\nlarge conurbations shows the relative decline of sites that nevertheless have\\nbeen highlighted as examples to be followed by the Excellence policies\\n(Strasbourg among others). The number of students and faculty has grown less\\nthere, and it is a plaussible explanation for the relative decline in\\nscientific production. We show that the publication output of a given site\\ndepends directly and strongly on the number of researchers hosted there. Based\\non precise data at the French level, our results confirm what is already known\\nat world scale. In conclusion, we question the amount of disorder resulting\\nfrom policies aligned with poorly assessed trends.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2005.13240'}, {'title': 'Analysis of Tree-Algorithms with Multi-Packet Reception. (arXiv:2005.13898v2 [cs.NI] UPDATED)', 'description': '<p>In this paper, we analyze binary-tree algorithms in a setup in which the\\nreceiver can perform multi-packet reception (MPR) of up to and including K\\npackets simultaneously. The analysis addresses both traffic-independent\\nperformance as well as performance under Poisson arrivals. For the former case,\\nwe show that the throughput, when normalized with respect to the assumed linear\\nincrease in resources required to achieve K-MPR capability, tends to the same\\nvalue that holds for the single-reception setup. However, when coupled with\\nPoisson arrivals in the windowed access scheme, the normalized throughput\\nincreases with K, and we present evidence that it asymptotically tends to 1. We\\nalso provide performance results for the modified tree algorithm with K-MPR in\\nthe clipped access scheme. To the best of our knowledge, this is the first\\npaper that provides an analytical treatment and a number of fundamental\\ninsights in the performance of tree-algorithms with MPR.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2005.13898'}, {'title': 'Interferobot: aligning an optical interferometer by a reinforcement learning agent. (arXiv:2006.02252v2 [cs.RO] UPDATED)', 'description': '<p>Limitations in acquiring training data restrict potential applications of\\ndeep reinforcement learning (RL) methods to the training of real-world robots.\\nHere we train an RL agent to align a Mach-Zehnder interferometer, which is an\\nessential part of many optical experiments, based on images of interference\\nfringes acquired by a monocular camera. The agent is trained in a simulated\\nenvironment, without any hand-coded features or a priori information about the\\nphysics, and subsequently transferred to a physical interferometer. Thanks to a\\nset of domain randomizations simulating uncertainties in physical measurements,\\nthe agent successfully aligns this interferometer without any fine tuning,\\nachieving a performance level of a human expert.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2006.02252'}, {'title': 'Unifying Regularisation Methods for Continual Learning. (arXiv:2006.06357v2 [cs.LG] UPDATED)', 'description': '<p>Continual Learning addresses the challenge of learning a number of different\\ntasks sequentially. The goal of maintaining knowledge of earlier tasks without\\nre-accessing them starkly conflicts with standard SGD training for artificial\\nneural networks. An influential method to tackle this problem without storing\\nold data are so-called regularisation approaches. They measure the importance\\nof each parameter for solving a given task and subsequently protect important\\nparameters from large changes. In the literature, three ways to measure\\nparameter importance have been put forward and they have inspired a large body\\nof follow-up work. Here, we present strong theoretical and empirical evidence\\nthat these three methods, Elastic Weight Consolidation (EWC), Synaptic\\nIntelligence (SI) and Memory Aware Synapses (MAS), are surprisingly similar and\\nare all linked to the same theoretical quantity. Concretely, we show that,\\ndespite stemming from very different motivations, both SI and MAS approximate\\nthe square root of the Fisher Information, with the Fisher being the\\ntheoretically justified basis of EWC. Moreover, we show that for SI the\\nrelation to the Fisher -- and in fact its performance -- is due to a previously\\nunknown bias. On top of uncovering unknown similarities and unifying\\nregularisation approaches, we also demonstrate that our insights enable\\npractical performance improvements for large batch training.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2006.06357'}, {'title': 'Disentangled Representation Learning and Generation with Manifold Optimization. (arXiv:2006.07046v2 [cs.LG] UPDATED)', 'description': '<p>Disentanglement is a useful property in representation learning which\\nincreases the interpretability of generative models such as Variational\\nAuto-Encoders (VAE), Generative Adversarial Models, and their many variants.\\nTypically in such models, an increase in disentanglement performance is\\ntraded-off with generation quality. In the context of latent space models, this\\nwork presents a representation learning framework that explicitly promotes\\ndisentanglement by encouraging orthogonal directions of variations. The\\nproposed objective is the sum of an auto-encoder error term along with a\\nPrincipal Component Analysis reconstruction error in the feature space. This\\nhas an interpretation of a Restricted Kernel Machine with an interconnection\\nmatrix on the Stiefel manifold. Our analysis shows that such a construction\\npromotes disentanglement by matching the principal directions in latent space\\nwith the directions of orthogonal variation in data space. The training\\nalgorithm involves a stochastic optimization method on the Stiefel manifold,\\nwhich increases only marginally the computing time compared to an analogous\\nVAE. Our theoretical discussion and various experiments show that the proposed\\nmodel improves over many VAE variants in terms of both generation quality and\\ndisentangled representation learning.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2006.07046'}, {'title': 'Partial Extended Observability Certification and Optimal Design of Moving Horizon Estimators Under Uncertainties. (arXiv:2006.11112v2 [eess.SY] UPDATED)', 'description': '<p>This paper addresses the observability analysis and the optimal design of\\nobservation parameters in the presence of noisy measurements and parametric\\nuncertainties. The main underlying frameworks are the nonlinear constrained\\nmoving horizon estimator design and the probabilistic certification via\\nrandomized optimization. As the perfect observability concept is not relevant\\nunder the considered uncertain and noisy context, the notion of almost\\n$\\\\epsilon$-observability is introduced and a systematic procedure to assess its\\nsatisfaction for a given system with a priori known measurement noise\\nstatistics and parameter discrepancy is sketched. A nice feature in the\\nproposed framework is that the observability is not necessarily defined as the\\nability to reconstruct the whole state, rather, the more general concept of\\nobservation-target quantities is used so that one can analyze the precision\\nwith which specific chosen expressions of the state and the parameters can be\\nreconstructed. The overall framework is exposed and validated through an\\nillustrative example.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2006.11112'}, {'title': 'Deep Implicit Coordination Graphs for Multi-agent Reinforcement Learning. (arXiv:2006.11438v2 [cs.LG] UPDATED)', 'description': '<p>Multi-agent reinforcement learning (MARL) requires coordination to\\nefficiently solve certain tasks. Fully centralized control is often infeasible\\nin such domains due to the size of joint action spaces. Coordination graph\\nbased formalization allows reasoning about the joint action based on the\\nstructure of interactions. However, they often require domain expertise in\\ntheir design. This paper introduces the deep implicit coordination graph (DICG)\\narchitecture for such scenarios. DICG consists of a module for inferring the\\ndynamic coordination graph structure which is then used by a graph neural\\nnetwork based module to learn to implicitly reason about the joint actions or\\nvalues. DICG allows learning the tradeoff between full centralization and\\ndecentralization via standard actor-critic methods to significantly improve\\ncoordination for domains with large number of agents. We apply DICG to both\\ncentralized-training-centralized-execution and\\ncentralized-training-decentralized-execution regimes. We demonstrate that DICG\\nsolves the relative overgeneralization pathology in predatory-prey tasks as\\nwell as outperforms various MARL baselines on the challenging StarCraft II\\nMulti-agent Challenge (SMAC) and traffic junction environments.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2006.11438'}, {'title': 'Adaptive Discretization for Adversarial Lipschitz Bandits. (arXiv:2006.12367v2 [cs.LG] UPDATED)', 'description': '<p>Lipschitz bandits is a prominent version of multi-armed bandits that studies\\nlarge, structured action spaces such as the [0,1] interval, where similar\\nactions are guaranteed to have similar rewards. A central theme here is the\\nadaptive discretization of the action space, which gradually \"zooms in\" on the\\nmore promising regions thereof. The goal is to take advantage of \"nicer\"\\nproblem instances, while retaining near-optimal worst-case performance. While\\nthe stochastic version of the problem is well-understood, the general version\\nwith adversarial rewards is not.\\n</p>\\n<p>We provide the first algorithm for adaptive discretization in the adversarial\\nversion, and derive instance-dependent regret bounds. In particular, we recover\\nthe worst-case optimal regret bound for the adversarial version, and the\\ninstance-dependent regret bound for the stochastic version. Further, an\\napplication of our algorithm to dynamic pricing (where a seller repeatedly\\nadjusts prices for a product) enjoys these regret bounds without any smoothness\\nassumptions.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2006.12367'}, {'title': 'Invertible Concept-based Explanations for CNN Models with Non-negative Concept Activation Vectors. (arXiv:2006.15417v3 [cs.CV] UPDATED)', 'description': '<p>Convolutional neural network (CNN) models for computer vision are powerful\\nbut lack explainability in their most basic form. This deficiency remains a key\\nchallenge when applying CNNs in important domains. Recent work for explanations\\nthrough feature importance of approximate linear models has moved from\\ninput-level features (pixels or segments) to features from mid-layer feature\\nmaps in the form of concept activation vectors (CAVs). CAVs contain\\nconcept-level information and could be learnt via clustering. In this work, we\\nrethink the ACE algorithm of Ghorbani et al., proposing an alternative\\ninevitable concept-based explanation (ICE) framework to overcome its\\nshortcomings. Based on the requirements of fidelity (approximate models to\\ntarget models) and interpretability (being meaningful to people), we design\\nmeasurements and evaluate a range of matrix factorization methods with our\\nframework. We find that \\\\emph{non-negative concept activation vectors} (NCAVs)\\nfrom non-negative matrix factorization provide superior performance in\\ninterpretability and fidelity based on computational and human subject\\nexperiments. Our framework provides both local and global concept-level\\nexplanations for pre-trained CNN models.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2006.15417'}, {'title': 'Multimodal Text Style Transfer for Outdoor Vision-and-Language Navigation. (arXiv:2007.00229v3 [cs.CL] UPDATED)', 'description': '<p>One of the most challenging topics in Natural Language Processing (NLP) is\\nvisually-grounded language understanding and reasoning. Outdoor\\nvision-and-language navigation (VLN) is such a task where an agent follows\\nnatural language instructions and navigates a real-life urban environment. Due\\nto the lack of human-annotated instructions that illustrate intricate urban\\nscenes, outdoor VLN remains a challenging task to solve. This paper introduces\\na Multimodal Text Style Transfer (MTST) learning approach and leverages\\nexternal multimodal resources to mitigate data scarcity in outdoor navigation\\ntasks. We first enrich the navigation data by transferring the style of the\\ninstructions generated by Google Maps API, then pre-train the navigator with\\nthe augmented external outdoor navigation dataset. Experimental results show\\nthat our MTST learning approach is model-agnostic, and our MTST approach\\nsignificantly outperforms the baseline models on the outdoor VLN task,\\nimproving task completion rate by 8.7% relatively on the test set.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2007.00229'}, {'title': 'Knowledge-Aware Language Model Pretraining. (arXiv:2007.00655v2 [cs.CL] UPDATED)', 'description': '<p>How much knowledge do pretrained language models hold? Recent research\\nobserved that pretrained transformers are adept at modeling semantics but it is\\nunclear to what degree they grasp human knowledge, or how to ensure they do so.\\nIn this paper we incorporate knowledge-awareness in language model pretraining\\nwithout changing the transformer architecture, inserting explicit knowledge\\nlayers, or adding external storage of semantic information. Rather, we simply\\nsignal the existence of entities to the input of the transformer in\\npretraining, with an entity-extended tokenizer; and at the output, with an\\nadditional entity prediction task. Our experiments show that solely by adding\\nthese entity signals in pretraining, significantly more knowledge is packed\\ninto the transformer parameters: we observe improved language modeling\\naccuracy, factual correctness in LAMA knowledge probing tasks, and semantics in\\nthe hidden representations through edge probing.We also show that our\\nknowledge-aware language model (KALM) can serve as a drop-in replacement for\\nGPT-2 models, significantly improving downstream tasks like zero-shot\\nquestion-answering with no task-related training.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2007.00655'}, {'title': 'MPC Protocol for G-module and its Application in Secure Compare and ReLU. (arXiv:2007.03975v3 [cs.CR] UPDATED)', 'description': '<p>Secure comparison and secure selection are two fundamental MPC (secure\\nMulti-Party Computation) protocols. One important application of these\\nprotocols is the secure ReLU and DReLU computation in privacy preserving deep\\nlearning. In this paper, we introduce G-module, a mathematics tool, to\\nre-design such protocols. In mathematics, given a group G, a G-module is an\\nabelian group M on which G acts compatibly with the abelian group structure on\\nM.\\n</p>\\n<p>We design three secure protocols for three G-module operations. i.e.\\n\"G-module action\", \"Cross G-module action\" and \"G-module recover\". As far as we\\nknow, this is the first work on secure G-module operations. Based on them, we\\ndesign secure comparison, selection, ReLU and DReLU protocols, which improve\\ncommunication efficiency by 2X to 10X compared with state of arts. Our\\nprotocols are very computation efficient too. They do not require public key\\noperations or any other expensive operations.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2007.03975'}, {'title': 'Algorithmic applications of the corestriction of central simple algebras. (arXiv:2007.06981v4 [math.NT] UPDATED)', 'description': '<p>Let $L$ be a separable quadratic extension of either $\\\\mathbb{Q}$ or\\n$\\\\mathbb{F}_q(t)$. We propose efficient algorithms for finding isomorphisms\\nbetween quaternion algebras over $L$. Our techniques are based on computing\\nmaximal one-sided ideals of the corestriction of a central simple $L$-algebra.\\nIn order to obtain efficient algorithms in the characteristic 2 case, we\\npropose an algorithm for finding nontrivial zeros of a regular quadratic form\\nin four variables over $\\\\mathbb{F}_{2^k}(t)$.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2007.06981'}, {'title': 'Relaxed-Responsibility Hierarchical Discrete VAEs. (arXiv:2007.07307v2 [stat.ML] UPDATED)', 'description': '<p>Successfully training Variational Autoencoders (VAEs) with a hierarchy of\\ndiscrete latent variables remains an area of active research.\\n</p>\\n<p>Vector-Quantised VAEs are a powerful approach to discrete VAEs, but naive\\nhierarchical extensions can be unstable when training. Leveraging insights from\\nclassical methods of inference we introduce \\\\textit{Relaxed-Responsibility\\nVector-Quantisation}, a novel way to parameterise discrete latent variables, a\\nrefinement of relaxed Vector-Quantisation that gives better performance and\\nmore stable training. This enables a novel approach to hierarchical discrete\\nvariational autoencoders with numerous layers of latent variables (here up to\\n32) that we train end-to-end. Within hierarchical probabilistic deep generative\\nmodels with discrete latent variables trained end-to-end, we achieve\\nstate-of-the-art bits-per-dim results for various standard datasets. % Unlike\\ndiscrete VAEs with a single layer of latent variables, we can produce samples\\nby ancestral sampling: it is not essential to train a second autoregressive\\ngenerative model over the learnt latent representations to then sample from and\\nthen decode. % Moreover, that latter approach in these deep hierarchical models\\nwould require thousands of forward passes to generate a single sample. Further,\\nwe observe different layers of our model become associated with different\\naspects of the data.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2007.07307'}, {'title': 'An empirical study of Linespots: A novel past-fault algorithm. (arXiv:2007.09394v2 [cs.SE] UPDATED)', 'description': '<p>This paper proposes the novel past-faults fault prediction algorithm\\nLinespots, based on the Bugspots algorithm. We analyze the predictive\\nperformance and runtime of Linespots compared to Bugspots with an empirical\\nstudy using the most significant self-built dataset as of now, including\\nhigh-quality samples for validation. As a novelty in fault prediction, we use\\nBayesian data analysis and Directed Acyclic Graphs to model the effects. We\\nfound consistent improvements in the predictive performance of Linespots over\\nBugspots for all seven evaluation metrics. We conclude that Linespots should be\\nused over Bugspots in all cases where no real-time performance is necessary.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2007.09394'}, {'title': 'Calibration of Google Trends Time Series. (arXiv:2007.13861v5 [cs.SI] UPDATED)', 'description': '<p>Google Trends is a tool that allows researchers to analyze the popularity of\\nGoogle search queries across time and space. In a single request, users can\\nobtain time series for up to 5 queries on a common scale, normalized to the\\nrange from 0 to 100 and rounded to integer precision. Despite the overall value\\nof Google Trends, rounding causes major problems, to the extent that entirely\\nuninformative, all-zero time series may be returned for unpopular queries when\\nrequested together with more popular queries. We address this issue by\\nproposing Google Trends Anchor Bank (G-TAB), an efficient solution for the\\ncalibration of Google Trends data. Our method expresses the popularity of an\\narbitrary number of queries on a common scale without being compromised by\\nrounding errors. The method proceeds in two phases. In the offline\\npreprocessing phase, an \"anchor bank\" is constructed, a set of queries spanning\\nthe full spectrum of popularity, all calibrated against a common reference\\nquery by carefully chaining together multiple Google Trends requests. In the\\nonline deployment phase, any given search query is calibrated by performing an\\nefficient binary search in the anchor bank. Each search step requires one\\nGoogle Trends request, but few steps suffice, as we demonstrate in an empirical\\nevaluation. We make our code publicly available as an easy-to-use library at\\nhttps://github.com/epfl-dlab/GoogleTrendsAnchorBank.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2007.13861'}, {'title': 'A Process Mining Software Comparison. (arXiv:2007.14038v3 [cs.SE] UPDATED)', 'description': \"<p>www.processmining-software.com is a dedicated website for process mining\\nsoftware comparison and was developed to give practitioners and researchers an\\noverview of commercial tools available on the market. Based on literature\\nreview and experimental tool testing, a set of criteria was developed in order\\nto assess the tools' functional capabilities in an objective manner. With our\\npublicly accessible website, we intend to increase the transparency of tool\\nfunctionality. Being an academic endeavour, the non-commercial nature of the\\nstudy ensures a less biased assessment as compared with reports from analyst\\nfirms.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2007.14038'}, {'title': 'An Empirical Survey of Data Augmentation for Time Series Classification with Neural Networks. (arXiv:2007.15951v2 [cs.LG] UPDATED)', 'description': '<p>In recent times, deep artificial neural networks have achieved many successes\\nin pattern recognition. Part of this success can be attributed to the reliance\\non big data to increase generalization. However, in the field of time series\\nrecognition, many datasets are often very small. One method of addressing this\\nproblem is through the use of data augmentation. In this paper, we survey data\\naugmentation techniques for time series and their application to time series\\nclassification with neural networks. We outline four families of time series\\ndata augmentation, including transformation-based methods, pattern mixing,\\ngenerative models, and decomposition methods, and detail their taxonomy.\\nFurthermore, we empirically evaluate 12 time series data augmentation methods\\non 128 time series classification datasets with 6 different types of neural\\nnetworks. Through the results, we are able to analyze the characteristics,\\nadvantages and disadvantages, and recommendations of each data augmentation\\nmethod. This survey aims to help in the selection of time series data\\naugmentation for neural network applications.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2007.15951'}, {'title': 'Noise-Response Analysis of Deep Neural Networks Quantifies Robustness and Fingerprints Structural Malware. (arXiv:2008.00123v2 [cs.LG] UPDATED)', 'description': \"<p>The ubiquity of deep neural networks (DNNs), cloud-based training, and\\ntransfer learning is giving rise to a new cybersecurity frontier in which\\nunsecure DNNs have `structural malware' (i.e., compromised weights and\\nactivation pathways). In particular, DNNs can be designed to have backdoors\\nthat allow an adversary to easily and reliably fool an image classifier by\\nadding a pattern of pixels called a trigger. It is generally difficult to\\ndetect backdoors, and existing detection methods are computationally expensive\\nand require extensive resources (e.g., access to the training data). Here, we\\npropose a rapid feature-generation technique that quantifies the robustness of\\na DNN, `fingerprints' its nonlinearity, and allows us to detect backdoors (if\\npresent). Our approach involves studying how a DNN responds to noise-infused\\nimages with varying noise intensity, which we summarize with titration curves.\\nWe find that DNNs with backdoors are more sensitive to input noise and respond\\nin a characteristic way that reveals the backdoor and where it leads (its\\n`target'). Our empirical results demonstrate that we can accurately detect\\nbackdoors with high confidence orders-of-magnitude faster than existing\\napproaches (seconds versus hours).\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2008.00123'}, {'title': 'Accuracy and Fairness Trade-offs in Machine Learning: A Stochastic Multi-Objective Approach. (arXiv:2008.01132v2 [cs.LG] UPDATED)', 'description': '<p>In the application of machine learning to real-life decision-making systems,\\ne.g., credit scoring and criminal justice, the prediction outcomes might\\ndiscriminate against people with sensitive attributes, leading to unfairness.\\nThe commonly used strategy in fair machine learning is to include fairness as a\\nconstraint or a penalization term in the minimization of the prediction loss,\\nwhich ultimately limits the information given to decision-makers. In this\\npaper, we introduce a new approach to handle fairness by formulating a\\nstochastic multi-objective optimization problem for which the corresponding\\nPareto fronts uniquely and comprehensively define the accuracy-fairness\\ntrade-offs. We have then applied a stochastic approximation-type method to\\nefficiently obtain well-spread and accurate Pareto fronts, and by doing so we\\ncan handle training data arriving in a streaming way.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2008.01132'}, {'title': 'Point Proposal Network: Accelerating Point Source Detection Through Deep Learning. (arXiv:2008.02093v2 [cs.CV] UPDATED)', 'description': '<p>Point source detection techniques are used to identify and localise point\\nsources in radio astronomical surveys. With the development of the Square\\nKilometre Array (SKA) telescope, survey images will see a massive increase in\\nsize from Gigapixels to Terapixels. Point source detection has already proven\\nto be a challenge in recent surveys performed by SKA pathfinder telescopes.\\nThis paper proposes the Point Proposal Network (PPN): a point source detector\\nthat utilises deep convolutional neural networks for fast source detection.\\nResults measured on simulated MeerKAT images show that, although less precise\\nwhen compared to leading alternative approaches, PPN performs source detection\\nfaster and is able to scale to large images, unlike the alternative approaches.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2008.02093'}, {'title': 'Data-driven reduced-order models via regularized operator inference for a single-injector combustion process. (arXiv:2008.02862v2 [cs.CE] UPDATED)', 'description': '<p>This paper derives predictive reduced-order models for rocket engine\\ncombustion dynamics via Operator Inference, a scientific machine learning\\napproach that blends data-driven learning with physics-based modeling. The\\nnon-intrusive nature of the approach enables variable transformations that\\nexpose system structure. The specific contribution of this paper is to advance\\nthe formulation robustness and algorithmic scalability of the Operator\\nInference approach. Regularization is introduced to the formulation to avoid\\nover-fitting. The task of determining an optimal regularization is posed as an\\noptimization problem that balances training error and stability of long-time\\nintegration dynamics. A scalable algorithm and open-source implementation are\\npresented, then demonstrated for a single-injector rocket combustion example.\\nThis example exhibits rich dynamics that are difficult to capture with\\nstate-of-the-art reduced models. With appropriate regularization and an\\ninformed selection of learning variables, the reduced-order models exhibit high\\naccuracy in re-predicting the training regime and acceptable accuracy in\\npredicting future dynamics, while achieving close to a million times speedup in\\ncomputational cost. When compared to a state-of-the-art model reduction method,\\nthe Operator Inference models provide the same or better accuracy at\\napproximately one thousandth of the computational cost.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2008.02862'}, {'title': 'On construction and (non)existence of $c$-(almost) perfect nonlinear functions. (arXiv:2008.03953v3 [math.CO] UPDATED)', 'description': '<p>Functions with low differential uniformity have relevant applications in\\ncryptography. Recently, functions with low $c$-differential uniformity\\nattracted lots of attention. In particular, so-called APcN and PcN functions\\n(generalization of APN and PN functions) have been investigated. Here, we\\nprovide a characterization of such functions via quadratic polynomials as well\\nas non-existence results.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2008.03953'}, {'title': 'Distributed Stochastic Subgradient Optimization Algorithms Over Random and Noisy Networks. (arXiv:2008.08796v4 [eess.SY] UPDATED)', 'description': \"<p>We study distributed stochastic optimization by networked nodes to\\ncooperatively minimize a sum of convex cost functions. The network is modeled\\nby a sequence of time-varying random digraphs with each node representing a\\nlocal optimizer and each edge representing a communication link. We consider\\nthe distributed subgradient optimization algorithm with noisy measurements of\\nlocal cost functions' subgradients, additive and multiplicative noises among\\ninformation exchanging between each pair of nodes. By stochastic Lyapunov\\nmethod, convex analysis, algebraic graph theory and martingale convergence\\ntheory, it is proved that if the local subgradient functions grow linearly and\\nthe sequence of digraphs is conditionally balanced and uniformly conditionally\\njointly connected, then proper algorithm step sizes can be designed so that all\\nnodes' states converge to the global optimal solution almost surely.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2008.08796'}, {'title': 'Active Disturbance Rejection Control Design with Suppression of Sensor Noise Effects in Application to DC-DC Buck Power Converter. (arXiv:2009.02948v2 [eess.SY] UPDATED)', 'description': '<p>The performance of active disturbance rejection control (ADRC) algorithms can\\nbe limited in practice by high-frequency measurement noise. In this work, this\\nproblem is addressed by transforming the high-gain extended state observer\\n(ESO), which is the inherent element of ADRC, into a new cascade observer\\nstructure. Set of experiments, performed on a DC-DC buck power converter\\nsystem, show that the new cascade ESO design, compared to the conventional\\napproach, effectively suppresses the detrimental effect of sensor noise\\nover-amplification while increasing the estimation/control performance. The\\nproposed design is also analyzed with a low-pass filter at the converter\\noutput, which is a common technique for reducing measurement noise in\\nindustrial applications.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2009.02948'}, {'title': 'Ebb-and-Flow Protocols: A Resolution of the Availability-Finality Dilemma. (arXiv:2009.04987v3 [cs.CR] UPDATED)', 'description': \"<p>The CAP theorem says that no blockchain can be live under dynamic\\nparticipation and safe under temporary network partitions. To resolve this\\navailability-finality dilemma, we formulate a new class of flexible consensus\\nprotocols, ebb-and-flow protocols, which support a full dynamically available\\nledger in conjunction with a finalized prefix ledger. The finalized ledger\\nfalls behind the full ledger when the network partitions but catches up when\\nthe network heals. Gasper, the current candidate protocol for Ethereum 2.0's\\nbeacon chain, combines the finality gadget Casper FFG with the LMD GHOST fork\\nchoice rule and aims to achieve this property. However, we discovered an attack\\nin the standard synchronous network model, highlighting a general difficulty\\nwith existing finality-gadget-based designs. We present a construction of\\nprovably secure ebb-and-flow protocols with optimal resilience. Nodes run an\\noff-the-shelf dynamically available protocol, take snapshots of the growing\\navailable ledger, and input them into a separate off-the-shelf BFT protocol to\\nfinalize a prefix. We explore connections with flexible BFT and improve upon\\nthe state-of-the-art for that problem.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2009.04987'}, {'title': 'Contrastive Triple Extraction with Generative Transformer. (arXiv:2009.06207v4 [cs.CL] UPDATED)', 'description': '<p>Triple extraction is an essential task in information extraction for natural\\nlanguage processing and knowledge graph construction. In this paper, we revisit\\nthe end-to-end triple extraction task for sequence generation. Since generative\\ntriple extraction may struggle to capture long-term dependencies and generate\\nunfaithful triples, we introduce a novel model, contrastive triple extraction\\nwith a generative transformer. Specifically, we introduce a single shared\\ntransformer module for encoder-decoder-based generation. To generate faithful\\nresults, we propose a novel triplet contrastive training object. Moreover, we\\nintroduce two mechanisms to further improve model performance (i.e., batch-wise\\ndynamic attention-masking and triple-wise calibration). Experimental results on\\nthree datasets (i.e., NYT, WebNLG, and MIE) show that our approach achieves\\nbetter performance than that of baselines.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2009.06207'}, {'title': 'A categorical duality for algebras of partial functions. (arXiv:2009.07895v2 [math.RA] UPDATED)', 'description': \"<p>We prove a categorical duality between a class of abstract algebras of\\npartial functions and a class of (small) topological categories. The algebras\\nare the isomorphs of collections of partial functions closed under the\\noperations of composition, antidomain, range, and preferential union (or\\n'override'). The topological categories are those whose space of objects is a\\nStone space, source map is a local homeomorphism, target map is open, and all\\nof whose arrows are epimorphisms.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2009.07895'}, {'title': 'A General Framework for the Security Analysis of Blockchain Protocols. (arXiv:2009.09480v3 [cs.DC] UPDATED)', 'description': '<p>Blockchain protocols differ in fundamental ways, including the mechanics of\\nselecting users to produce blocks (e.g., proof-of-work vs. proof-of-stake) and\\nthe method to establish consensus (e.g., longest chain rules vs. Byzantine\\nfault-tolerant (BFT) inspired protocols). These fundamental differences have\\nhindered \"apples-to-apples\" comparisons between different categories of\\nblockchain protocols and, in turn, the development of theory to formally\\ndiscuss their relative merits.\\n</p>\\n<p>This paper presents a parsimonious abstraction sufficient for capturing and\\ncomparing properties of many well-known permissionless blockchain protocols,\\nsimultaneously capturing essential properties of both proof-of-work (PoW) and\\nproof-of-stake (PoS) protocols, and of both longest-chain-type and BFT-type\\nprotocols. Our framework blackboxes the precise mechanics of the user selection\\nprocess, allowing us to isolate the properties of the selection process that\\nare significant for protocol design.\\n</p>\\n<p>We demonstrate the utility of our general framework with several concrete\\nresults:\\n</p>\\n<p>1. We prove a CAP-type impossibility theorem asserting that liveness with an\\nunknown level of participation rules out security in a partially synchronous\\nsetting.\\n</p>\\n<p>2. Delving deeper into the partially synchronous setting, we prove that a\\nnecessary and sufficient condition for security is the production of\\n\"certificates,\" meaning stand-alone proofs of block confirmation.\\n</p>\\n<p>3. Restricting to synchronous settings, we prove that typical protocols with\\na known level of participation (including longest chain-type PoS protocols) can\\nbe adapted to provide certificates, but those with an unknown level of\\nparticipation cannot.\\n</p>\\n<p>4. Finally, we use our framework to articulate a modular two-step approach to\\nblockchain security analysis that effectively reduces the permissionless case\\nto the permissioned case.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2009.09480'}, {'title': 'Semi-supervised Semantic Segmentation of Prostate and Organs-at-Risk on 3D Pelvic CT Images. (arXiv:2009.09571v3 [cs.CV] UPDATED)', 'description': '<p>Automated segmentation can assist radiotherapy treatment planning by saving\\nmanual contouring efforts and reducing intra-observer and inter-observer\\nvariations. The recent development of deep learning approaches has revoluted\\nmedical data processing, including semantic segmentation, by dramatically\\nimproving performance. However, training effective deep learning models usually\\nrequire a large amount of high-quality labeled data, which are often costly to\\ncollect. We developed a novel semi-supervised adversarial deep learning\\napproach for 3D pelvic CT image semantic segmentation. Unlike supervised deep\\nlearning methods, the new approach can utilize both annotated and un-annotated\\ndata for training. It generates un-annotated synthetic data by a data\\naugmentation scheme using generative adversarial networks (GANs). We applied\\nthe new approach to segmenting multiple organs in male pelvic CT images, where\\nCT images without annotations and GAN-synthesized un-annotated images were used\\nin semi-supervised learning. Experimental results, evaluated by three metrics\\n(Dice similarity coefficient, average Hausdorff distance, and average surface\\nHausdorff distance), showed that the new method achieved either comparable\\nperformance with substantially fewer annotated images or better performance\\nwith the same amount of annotated data, outperforming the existing\\nstate-of-the-art methods.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2009.09571'}, {'title': 'Dark Patterns and the Legal Requirements of Consent Banners: An Interaction Criticism Perspective. (arXiv:2009.10194v2 [cs.HC] UPDATED)', 'description': '<p>User engagement with data privacy and security through consent banners has\\nbecome a ubiquitous part of interacting with internet services. While previous\\nwork has addressed consent banners from either interaction design, legal, and\\nethics-focused perspectives, little research addresses the connections among\\nmultiple disciplinary approaches, including tensions and opportunities that\\ntranscend disciplinary boundaries. In this paper, we draw together perspectives\\nand commentary from HCI, design, privacy and data protection, and legal\\nresearch communities, using the language and strategies of \"dark patterns\" to\\nperform an interaction criticism reading of three different types of consent\\nbanners. Our analysis builds upon designer, interface, user, and social context\\nlenses to raise tensions and synergies that arise together in complex,\\ncontingent, and conflicting ways in the act of designing consent banners. We\\nconclude with opportunities for transdisciplinary dialogue across legal,\\nethical, computer science, and interactive systems scholarship to translate\\nmatters of ethical concern into public policy.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2009.10194'}, {'title': 'The Ultimate DataFlow for Ultimate SuperComputers-on-a-Chips. (arXiv:2009.10593v4 [cs.DC] UPDATED)', 'description': '<p>This article starts from the assumption that near future 100BTransistor\\nSuperComputers-on-a-Chip will include N big multi-core processors, 1000N small\\nmany-core processors, a TPU-like fixed-structure systolic array accelerator for\\nthe most frequently used Machine Learning algorithms needed in bandwidth-bound\\napplications and a flexible-structure reprogrammable accelerator for less\\nfrequently used Machine Learning algorithms needed in latency-critical\\napplications.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2009.10593'}, {'title': 'EEG based Major Depressive disorder and Bipolar disorder detection using Neural Networks: A review. (arXiv:2009.13402v2 [q-bio.NC] UPDATED)', 'description': '<p>Mental disorders represent critical public health challenges as they are\\nleading contributors to the global burden of disease and intensely influence\\nsocial and financial welfare of individuals. The present comprehensive review\\nconcentrate on the two mental disorders: Major depressive Disorder (MDD) and\\nBipolar Disorder (BD) with noteworthy publications during the last ten years.\\nThere is a big need nowadays for phenotypic characterization of psychiatric\\ndisorders with biomarkers. Electroencephalography (EEG) signals could offer a\\nrich signature for MDD and BD and then they could improve understanding of\\npathophysiological mechanisms underling these mental disorders. In this review,\\nwe focus on the literature works adopting neural networks fed by EEG signals.\\nAmong those studies using EEG and neural networks, we have discussed a variety\\nof EEG based protocols, biomarkers and public datasets for depression and\\nbipolar disorder detection. We conclude with a discussion and valuable\\nrecommendations that will help to improve the reliability of developed models\\nand for more accurate and more deterministic computational intelligence based\\nsystems in psychiatry. This review will prove to be a structured and valuable\\ninitial point for the researchers working on depression and bipolar disorders\\nrecognition by using EEG signals.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2009.13402'}, {'title': 'Graph Neural Networks with Heterophily. (arXiv:2009.13566v2 [cs.LG] UPDATED)', 'description': '<p>Graph Neural Networks (GNNs) have proven to be useful for many different\\npractical applications. However, many existing GNN models have implicitly\\nassumed homophily among the nodes connected in the graph, and therefore have\\nlargely overlooked the important setting of heterophily, where most connected\\nnodes are from different classes. In this work, we propose a novel framework\\ncalled CPGNN that generalizes GNNs for graphs with either homophily or\\nheterophily. The proposed framework incorporates an interpretable compatibility\\nmatrix for modeling the heterophily or homophily level in the graph, which can\\nbe learned in an end-to-end fashion, enabling it to go beyond the assumption of\\nstrong homophily. Theoretically, we show that replacing the compatibility\\nmatrix in our framework with the identity (which represents pure homophily)\\nreduces to GCN. Our extensive experiments demonstrate the effectiveness of our\\napproach in more realistic and challenging experimental settings with\\nsignificantly less training data compared to previous works: CPGNN variants\\nachieve state-of-the-art results in heterophily settings with or without\\ncontextual node features, while maintaining comparable performance in homophily\\nsettings.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2009.13566'}, {'title': 'Engineering In-place (Shared-memory) Sorting Algorithms. (arXiv:2009.13569v2 [cs.DC] UPDATED)', 'description': '<p>We present sorting algorithms that represent the fastest known techniques for\\na wide range of input sizes, input distributions, data types, and machines. A\\npart of the speed advantage is due to the feature to work in-place. Previously,\\nthe in-place feature often implied performance penalties. Our main algorithmic\\ncontribution is a blockwise approach to in-place data distribution that is\\nprovably cache-efficient. We also parallelize this approach taking dynamic load\\nbalancing and memory locality into account. Our comparison-based algorithm,\\nIn-place Superscalar Samplesort (IPS$^4$o), combines this technique with\\nbranchless decision trees. By taking cases with many equal elements into\\naccount and by adapting the distribution degree dynamically, we obtain a highly\\nrobust algorithm that outperforms the best in-place parallel comparison-based\\ncompetitor by almost a factor of three. IPS$^4$o also outperforms the best\\ncomparison-based competitors in the in-place or not in-place, parallel or\\nsequential settings. IPS$^4$o even outperforms the best integer sorting\\nalgorithms in a wide range of situations. In many of the remaining cases (often\\ninvolving near-uniform input distributions, small keys, or a sequential\\nsetting), our new in-place radix sorter turns out to be the best algorithm.\\nClaims to have the, in some sense, \"best\" sorting algorithm can be found in\\nmany papers which cannot all be true. Therefore, we base our conclusions on\\nextensive experiments involving a large part of the cross product of 21\\nstate-of-the-art sorting codes, 6 data types, 10 input distributions, 4\\nmachines, 4 memory allocation strategies, and input sizes varying over 7 orders\\nof magnitude. This confirms the robust performance of our algorithms while\\nrevealing major performance problems in many competitors outside the concrete\\nset of measurements reported in the associated publications.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2009.13569'}, {'title': 'On Statistical Discrimination as a Failure of Social Learning: A Multi-Armed Bandit Approach. (arXiv:2010.01079v4 [econ.TH] UPDATED)', 'description': \"<p>We analyze statistical discrimination using a multi-armed bandit model where\\nmyopic firms face candidate workers arriving with heterogeneous observable\\ncharacteristics. The association between the worker's skill and characteristics\\nis unknown ex ante; thus, firms need to learn it. In such an environment,\\nlaissez-faire may result in a highly unfair and inefficient outcome -- myopic\\nfirms are reluctant to hire minority workers because the lack of data about\\nminority workers prevents accurate estimation of their performance.\\nConsequently, minority groups could be perpetually underestimated -- they are\\nnever hired, and therefore, data about them is never accumulated. We proved\\nthat this problem becomes more serious when the population ratio is imbalanced,\\nas is the case in many extant discrimination problems. We consider two\\naffirmative-action policies for solving this dilemma: One is a subsidy rule\\nthat is based on the popular upper confidence bound algorithm, and another is\\nthe Rooney Rule, which requires firms to interview at least one minority worker\\nfor each hiring opportunity. Our results indicate temporary affirmative actions\\nare effective for statistical discrimination caused by data insufficiency.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2010.01079'}, {'title': 'Regret Guarantees for Online Receding Horizon Learning Control. (arXiv:2010.07269v8 [math.OC] UPDATED)', 'description': \"<p>In this paper we provide provable regret guarantees for an online learning\\nreceding horizon type control policy in a setting where the system to be\\ncontrolled is an unknown linear dynamical system, the cost for the controller\\nis a general additive function over a finite period $T$, and there exist\\ncontrol input constraints that when violated incur an additional cost. We show\\nthat the learning based receding horizon control policy achieves the regret of\\n$\\\\tilde{O}(T^{3/4})$ for both the controller's cost and cumulative constraint\\nviolation w.r.t the baseline receding horizon control policy that has full\\nknowledge of the system.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2010.07269'}, {'title': 'Entropic proofs of Singleton bounds for quantum error-correcting codes. (arXiv:2010.07902v2 [quant-ph] UPDATED)', 'description': '<p>We show that a relatively simple reasoning using von Neumann entropy\\ninequalities yields a robust proof of the quantum Singleton bound for quantum\\nerror-correcting codes (QECC). For entanglement-assisted quantum\\nerror-correcting codes (EAQECC) and catalytic codes (CQECC), the generalised\\nquantum Singleton bound was believed to hold for many years until recently one\\nof us found a counterexample [MG, <a href=\"/abs/2007.01249\">arXiv:2007.01249</a>]. Here, we rectify this\\nstate of affairs by proving the correct generalised quantum Singleton bound for\\nCQECC, extending the above-mentioned proof method for QECC; we also prove\\ninformation-theoretically tight bounds on the entanglement-communication\\ntradeoff for EAQECC. All of the bounds relate block length $n$ and code length\\n$k$ for given minimum distance $d$ and we show that they are robust, in the\\nsense that they hold with small perturbations for codes which only correct most\\nof the erasure errors of less than $d$ letters. In contrast to the classical\\ncase, the bounds take on qualitatively different forms depending on whether the\\nminimum distance is smaller or larger than half the block length. We also\\nprovide a propagation rule, where any pure QECC yields an EAQECC with the same\\ndistance and dimension but of shorter block length.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2010.07902'}, {'title': 'Optimal Index Assignment for Scalar Quantizers and M-PSK via a Discrete Convolution-Rearrangement Inequality. (arXiv:2010.10300v3 [cs.IT] UPDATED)', 'description': '<p>This paper investigates the problem of finding an optimal nonbinary index\\nassignment from \\\\(M\\\\) quantization levels of a maximum entropy scalar quantizer\\nto \\\\(M\\\\)-PSK symbols transmitted over a symmetric memoryless channel with\\nadditive noise following decreasing probability density function (such as the\\nAWGN channel) so as to minimize the channel mean-squared distortion. The\\nso-called zigzag mapping under maximum-likelihood (ML) decoding was known to be\\nasymptotically optimal, but the problem of determining the optimal index\\nassignment for any given signal-to-noise ratio (SNR) is still open. Based on a\\ngeneralized version of the Hardy-Littlewood convolution-rearrangement\\ninequality, we prove that the zigzag mapping under ML decoding is optimal for\\nall SNRs. It is further proved that the same optimality results also hold under\\nminimum mean-square-error (MMSE) decoding. Numerical results are presented to\\nverify our optimality results and to demonstrate the performance gain of the\\noptimal \\\\(M\\\\)-ary index assignment over the state-of-the-art binary counterpart\\nfor the case of \\\\(8\\\\)-PSK over the AWGN channel.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2010.10300'}, {'title': 'FastEmit: Low-latency Streaming ASR with Sequence-level Emission Regularization. (arXiv:2010.11148v2 [eess.AS] UPDATED)', 'description': '<p>Streaming automatic speech recognition (ASR) aims to emit each hypothesized\\nword as quickly and accurately as possible. However, emitting fast without\\ndegrading quality, as measured by word error rate (WER), is highly challenging.\\nExisting approaches including Early and Late Penalties and Constrained\\nAlignments penalize emission delay by manipulating per-token or per-frame\\nprobability prediction in sequence transducer models. While being successful in\\nreducing delay, these approaches suffer from significant accuracy regression\\nand also require additional word alignment information from an existing model.\\nIn this work, we propose a sequence-level emission regularization method, named\\nFastEmit, that applies latency regularization directly on per-sequence\\nprobability in training transducer models, and does not require any alignment.\\nWe demonstrate that FastEmit is more suitable to the sequence-level\\noptimization of transducer models for streaming ASR by applying it on various\\nend-to-end streaming ASR networks including RNN-Transducer,\\nTransformer-Transducer, ConvNet-Transducer and Conformer-Transducer. We achieve\\n150-300 ms latency reduction with significantly better accuracy over previous\\ntechniques on a Voice Search test set. FastEmit also improves streaming ASR\\naccuracy from 4.4%/8.9% to 3.1%/7.5% WER, meanwhile reduces 90th percentile\\nlatency from 210 ms to only 30 ms on LibriSpeech.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2010.11148'}, {'title': 'HateBERT: Retraining BERT for Abusive Language Detection in English. (arXiv:2010.12472v2 [cs.CL] UPDATED)', 'description': '<p>In this paper, we introduce HateBERT, a re-trained BERT model for abusive\\nlanguage detection in English. The model was trained on RAL-E, a large-scale\\ndataset of Reddit comments in English from communities banned for being\\noffensive, abusive, or hateful that we have collected and made available to the\\npublic. We present the results of a detailed comparison between a general\\npre-trained language model and the abuse-inclined version obtained by\\nretraining with posts from the banned communities on three English datasets for\\noffensive, abusive language and hate speech detection tasks. In all datasets,\\nHateBERT outperforms the corresponding general BERT model. We also discuss a\\nbattery of experiments comparing the portability of the generic pre-trained\\nlanguage model and its corresponding abusive language-inclined counterpart\\nacross the datasets, indicating that portability is affected by compatibility\\nof the annotated phenomena.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2010.12472'}, {'title': 'Overlapping Domain Decomposition Methods for Ptychographic Imaging. (arXiv:2011.00162v2 [math.NA] UPDATED)', 'description': '<p>In ptychography experiments, redundant scanning is usually required to\\nguarantee the stable recovery, such that a huge amount of frames are generated,\\nand thus it poses a great demand of parallel computing in order to solve this\\nlarge-scale inverse problem. In this paper, we propose the overlapping Domain\\nDecomposition Methods(DDMs) to solve the nonconvex optimization problem in\\nptychographic imaging. They decouple the problem defined on the whole domain\\ninto subproblems only defined on the subdomains with synchronizing information\\nin the overlapping regions of these subdomains,thus leading to highly parallel\\nalgorithms with good load balance. More specifically, for the nonblind recovery\\n(with known probe in advance), by enforcing the continuity of the overlapping\\nregions for the image (sample), the nonlinear optimization model is established\\nbased on a novel smooth-truncated amplitude-Gaussian metric (ST-AGM). Such\\nmetric allows for fast calculation of the proximal mapping with closed form,\\nand meanwhile provides the possibility for the convergence guarantee of the\\nfirst-order nonconvex optimization algorithm due to its Lipschitz smoothness.\\nThen the Alternating Direction Method of Multipliers (ADMM) is utilized to\\ngenerate an efficient Overlapping Domain Decomposition based Ptychography\\nalgorithm(OD2P) for the two-subdomain domain decomposition (DD), where all\\nsubproblems can be computed with close-form solutions.Due to the Lipschitz\\ncontinuity for the gradient of the objective function with ST-AGM, the\\nconvergence of the proposed OD2P is derived under mild conditions. Moreover, it\\nis extended to more general case including multiple-subdomain DD and blind\\nrecovery. Numerical experiments are further conducted to show the performance\\nof proposed algorithms, demonstrating good convergence speed and robustness to\\nthe noise.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2011.00162'}, {'title': 'Exponential Polynomial Block Methods. (arXiv:2011.00670v2 [math.NA] UPDATED)', 'description': '<p>In this paper we extend the polynomial time integration framework to include\\nexponential integration for both partitioned and unpartitioned initial value\\nproblems. We then demonstrate the utility of the exponential polynomial\\nframework by constructing a new class of parallel exponential polynomial block\\nmethods (EPBMs) based on the Legendre points. These new integrators can be\\nconstructed at arbitrary orders of accuracy and have improved stability\\ncompared to existing exponential linear multistep methods. Moreover, if the ODE\\nright-hand side evaluations can be parallelized efficiently, then high-order\\nEPBMs are significantly more efficient at obtaining highly accurate solutions\\nthan exponential linear multistep methods and exponential spectral deferred\\ncorrection methods of equivalent order.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2011.00670'}, {'title': 'CUTIE: Beyond PetaOp/s/W Ternary DNN Inference Acceleration with Better-than-Binary Energy Efficiency. (arXiv:2011.01713v2 [cs.AR] UPDATED)', 'description': '<p>We present a 3.1 POp/s/W fully digital hardware accelerator for ternary\\nneural networks. CUTIE, the Completely Unrolled Ternary Inference Engine,\\nfocuses on minimizing non-computational energy and switching activity so that\\ndynamic power spent on storing (locally or globally) intermediate results is\\nminimized. This is achieved by 1) a data path architecture completely unrolled\\nin the feature map and filter dimensions to reduce switching activity by\\nfavoring silencing over iterative computation and maximizing data re-use, 2)\\ntargeting ternary neural networks which, in contrast to binary NNs, allow for\\nsparse weights which reduce switching activity, and 3) introducing an optimized\\ntraining method for higher sparsity of the filter weights, resulting in a\\nfurther reduction of the switching activity. Compared with state-of-the-art\\naccelerators, CUTIE achieves greater or equal accuracy while decreasing the\\noverall core inference energy cost by a factor of 4.8x-21x.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2011.01713'}, {'title': 'Motion Generation Using Bilateral Control-Based Imitation Learning with Autoregressive Learning. (arXiv:2011.06192v5 [cs.RO] UPDATED)', 'description': '<p>Robots that can execute various tasks automatically on behalf of humans are\\nbecoming an increasingly important focus of research in the field of robotics.\\nImitation learning has been studied as an efficient and high-performance\\nmethod, and imitation learning based on bilateral control has been proposed as\\na method that can realize fast motion. However, because this method cannot\\nimplement autoregressive learning, this method may not generate desirable\\nlong-term behavior. Therefore, in this paper, we propose a method of\\nautoregressive learning for bilateral control-based imitation learning. A new\\nneural network model for implementing autoregressive learning is proposed. In\\nthis study, three types of experiments are conducted to verify the\\neffectiveness of the proposed method. The performance is improved compared to\\nconventional approaches; the proposed method has the highest rate of success.\\nOwing to the structure and autoregressive learning of the proposed model, the\\nproposed method can generate the desirable motion for successful tasks and have\\na high generalization ability for environmental changes.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2011.06192'}, {'title': 'Unified Multi-Modal Landmark Tracking for Tightly Coupled Lidar-Visual-Inertial Odometry. (arXiv:2011.06838v2 [cs.RO] UPDATED)', 'description': '<p>We present an efficient multi-sensor odometry system for mobile platforms\\nthat jointly optimizes visual, lidar, and inertial information within a single\\nintegrated factor graph. This runs in real-time at full framerate using fixed\\nlag smoothing. To perform such tight integration, a new method to extract 3D\\nline and planar primitives from lidar point clouds is presented. This approach\\novercomes the suboptimality of typical frame-to-frame tracking methods by\\ntreating the primitives as landmarks and tracking them over multiple scans.\\nTrue integration of lidar features with standard visual features and IMU is\\nmade possible using a subtle passive synchronization of lidar and camera\\nframes. The lightweight formulation of the 3D features allows for real-time\\nexecution on a single CPU. Our proposed system has been tested on a variety of\\nplatforms and scenarios, including underground exploration with a legged robot\\nand outdoor scanning with a dynamically moving handheld device, for a total\\nduration of 96 min and 2.4 km traveled distance. In these test sequences, using\\nonly one exteroceptive sensor leads to failure due to either underconstrained\\ngeometry (affecting lidar) or textureless areas caused by aggressive lighting\\nchanges (affecting vision). In these conditions, our factor graph naturally\\nuses the best information available from each sensor modality without any hard\\nswitches.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2011.06838'}, {'title': 'Risk-Constrained Thompson Sampling for CVaR Bandits. (arXiv:2011.08046v4 [cs.LG] UPDATED)', 'description': '<p>The multi-armed bandit (MAB) problem is a ubiquitous decision-making problem\\nthat exemplifies the exploration-exploitation tradeoff. Standard formulations\\nexclude risk in decision making. Risk notably complicates the basic\\nreward-maximising objective, in part because there is no universally agreed\\ndefinition of it. In this paper, we consider a popular risk measure in\\nquantitative finance known as the Conditional Value at Risk (CVaR). We explore\\nthe performance of a Thompson Sampling-based algorithm CVaR-TS under this risk\\nmeasure. We provide comprehensive comparisons between our regret bounds with\\nstate-of-the-art L/UCB-based algorithms in comparable settings and demonstrate\\ntheir clear improvement in performance. We also include numerical simulations\\nto empirically verify that CVaR-TS outperforms other L/UCB-based algorithms.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2011.08046'}, {'title': 'Time-Series Snapshot Network for Partner Recommendation: A Case Study on OSS. (arXiv:2011.09883v3 [cs.SI] UPDATED)', 'description': \"<p>The last decade has witnessed the rapid growth of open source software (OSS).\\nStill, all contributors may find it difficult to assimilate into OSS community\\neven they are enthusiastic to make contributions. We thus suggest that partner\\nrecommendation across different roles may benefit both the users and\\ndevelopers, i.e., once we are able to make successful recommendation for those\\nin need, it may dramatically contribute to the productivity of developers and\\nthe enthusiasm of users, thus further boosting OSS projects' development.\\nMotivated by this potential, we model the partner recommendation as link\\nprediction task from email data via network embedding methods. In this paper,\\nwe introduce time-series snapshot network (TSSN) which is a mixture network to\\nmodel the interactions among users and developers. Based on the established\\nTSSN, we perform temporal biased walk (TBW) to automatically capture both\\ntemporal and structural information of the email network, i.e., the behavioral\\nsimilarity between individuals in the OSS email network. Experiments on ten\\nApache datasets demonstrate that the proposed TBW significantly outperforms a\\nnumber of advanced random walk based embedding methods, leading to the\\nstate-of-the-art recommendation performance.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2011.09883'}, {'title': 'Zero Queueing for Multi-Server Jobs. (arXiv:2011.10521v2 [cs.PF] UPDATED)', 'description': '<p>Cloud computing today is dominated by multi-server jobs. These are jobs that\\nrequest multiple servers simultaneously and hold onto all of these servers for\\nthe duration of the job. Multi-server jobs add a lot of complexity to the\\ntraditional one-job-per-server model: an arrival might not \"fit\" into the\\navailable servers and might have to queue, blocking later arrivals and leaving\\nservers idle. From a queueing perspective, almost nothing is understood about\\nmulti-server job queueing systems; even understanding the exact stability\\nregion is a very hard problem.\\n</p>\\n<p>In this paper, we investigate a multi-server job queueing model under scaling\\nregimes where the number of servers in the system grows. Specifically, we\\nconsider a system with multiple classes of jobs, where jobs from different\\nclasses can request different numbers of servers and have different service\\ntime distributions, and jobs are served in first-come-first-served order. The\\nmulti-server job model opens up new scaling regimes where both the number of\\nservers that a job needs and the system load scale with the total number of\\nservers. Within these scaling regimes, we derive the first results on\\nstability, queueing probability, and the transient analysis of the number of\\njobs in the system for each class. In particular we derive sufficient\\nconditions for zero queueing. Our analysis introduces a novel way of extracting\\ninformation from the Lyapunov drift, which can be applicable to a broader scope\\nof problems in queueing systems.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2011.10521'}, {'title': 'Logical Obstruction to Set Agreement Tasks for Superset-Closed Adversaries. (arXiv:2011.13630v2 [cs.DC] UPDATED)', 'description': \"<p>In their recent paper (GandALF 2018), Goubault, Ledent, and Rajsbaum provided\\na formal epistemic model for distributed computing. Their logical model, as an\\nalternative to the well-studied topological model, provides an attractive\\nframework for refuting the solvability of a given distributed task by means of\\nlogical obstruction: One just needs to devise a formula, in the formal language\\nof epistemic logic, that describes a discrepancy between the model of\\ncomputation and that of the task. However, few instances of logical obstruction\\nwere presented in their paper and specifically logical obstruction to the\\nwait-free 2-set agreement task was left as an open problem. Soon later, Nishida\\naffirmatively answered to the problem by providing inductively defined logical\\nobstruction formulas to the wait-free $k$-set agreement tasks.\\n</p>\\n<p>The present paper refines Nishida's work and devises logical obstruction\\nformulas to $k$-set agreement tasks for superset-closed adversaries, which\\nsupersede the wait-free model. These instances of logical obstruction formulas\\nexemplify that the logical framework can provide yet another feasible method\\nfor showing impossibility of distributed tasks, though it is currently being\\nconfined to one-round distributed protocols. The logical method has an\\nadvantage over the topological method that it enjoys a self-contained,\\nelementary induction proof. This is in contrast to topological methods, in\\nwhich sophisticated topological tools, such as Nerve lemma, are often assumed\\nas granted.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2011.13630'}, {'title': 'Emergent Complexity and Zero-shot Transfer via Unsupervised Environment Design. (arXiv:2012.02096v2 [cs.LG] UPDATED)', 'description': \"<p>A wide range of reinforcement learning (RL) problems - including robustness,\\ntransfer learning, unsupervised RL, and emergent complexity - require\\nspecifying a distribution of tasks or environments in which a policy will be\\ntrained. However, creating a useful distribution of environments is error\\nprone, and takes a significant amount of developer time and effort. We propose\\nUnsupervised Environment Design (UED) as an alternative paradigm, where\\ndevelopers provide environments with unknown parameters, and these parameters\\nare used to automatically produce a distribution over valid, solvable\\nenvironments. Existing approaches to automatically generating environments\\nsuffer from common failure modes: domain randomization cannot generate\\nstructure or adapt the difficulty of the environment to the agent's learning\\nprogress, and minimax adversarial training leads to worst-case environments\\nthat are often unsolvable. To generate structured, solvable environments for\\nour protagonist agent, we introduce a second, antagonist agent that is allied\\nwith the environment-generating adversary. The adversary is motivated to\\ngenerate environments which maximize regret, defined as the difference between\\nthe protagonist and antagonist agent's return. We call our technique\\nProtagonist Antagonist Induced Regret Environment Design (PAIRED). Our\\nexperiments demonstrate that PAIRED produces a natural curriculum of\\nincreasingly complex environments, and PAIRED agents achieve higher zero-shot\\ntransfer performance when tested in highly novel environments.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2012.02096'}, {'title': 'Using topological autoencoders as a filtering function for global and local topology. (arXiv:2012.03383v2 [cs.CG] UPDATED)', 'description': '<p>Choosing a suitable filtering function for the Mapper algorithm can be\\ndifficult due to its arbitrariness and domain-specific requirements. Finding a\\ngeneral filtering function that can be applied across domains is therefore of\\ninterest, since it would improve the representation of manifolds in higher\\ndimensions. In this extended abstract, we propose that topological autoencoders\\nis a suitable candidate for this and report initial results strengthening this\\nhypothesis for one set of high-dimensional manifolds. The results indicate a\\npotential for an easier choice of filtering function when using the Mapper\\nalgorithm, allowing for a more general and descriptive representation of\\nhigh-dimensional data.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2012.03383'}, {'title': 'Certified Robustness of Nearest Neighbors against Data Poisoning Attacks. (arXiv:2012.03765v2 [cs.CR] UPDATED)', 'description': '<p>Data poisoning attacks aim to corrupt a machine learning model via modifying,\\nadding, and/or removing some carefully selected training examples, such that\\nthe corrupted model predicts any or attacker-chosen incorrect labels for\\ntesting examples. The key idea of state-of-the-art certified defenses against\\ndata poisoning attacks is to create a \\\\emph{majority vote} mechanism to predict\\nthe label of a testing example. Moreover, each voter is a base classifier\\ntrained on a subset of the training dataset. Classical simple learning\\nalgorithms such as $k$ nearest neighbors (kNN) and radius nearest neighbors\\n(rNN) have intrinsic majority vote mechanisms. In this work, we show that the\\nintrinsic majority vote mechanisms in kNN and rNN already provide certified\\nrobustness guarantees against general data poisoning attacks. Moreover, our\\nevaluation results on MNIST and CIFAR10 show that the intrinsic certified\\nrobustness guarantees of kNN and rNN outperform those provided by\\nstate-of-the-art certified defenses. Our results serve as standard baselines\\nfor future certified defenses against data poisoning attacks.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2012.03765'}, {'title': 'Model-agnostic Fits for Understanding Information Seeking Patterns in Humans. (arXiv:2012.04858v2 [cs.AI] UPDATED)', 'description': '<p>In decision making tasks under uncertainty, humans display characteristic\\nbiases in seeking, integrating, and acting upon information relevant to the\\ntask. Here, we reexamine data from previous carefully designed experiments,\\ncollected at scale, that measured and catalogued these biases in aggregate\\nform. We design deep learning models that replicate these biases in aggregate,\\nwhile also capturing individual variation in behavior. A key finding of our\\nwork is that paucity of data collected from each individual subject can be\\novercome by sampling large numbers of subjects from the population, while still\\ncapturing individual differences. In addition, we can predict human behavior\\nwith high accuracy without making any assumptions about task goals, reward\\nstructure, or individual biases, thus providing a model-agnostic fit to human\\nbehavior in the task. Such an approach can sidestep potential limitations in\\nmodeler-specified inductive biases, and has implications for computational\\nmodeling of human cognitive function in general, and of human-AI interfaces in\\nparticular.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2012.04858'}, {'title': 'Empirical Analysis of Unlabeled Entity Problem in Named Entity Recognition. (arXiv:2012.05426v4 [cs.CL] UPDATED)', 'description': '<p>In many scenarios, named entity recognition (NER) models severely suffer from\\nunlabeled entity problem, where the entities of a sentence may not be fully\\nannotated. Through empirical studies performed on synthetic datasets, we find\\ntwo causes of the performance degradation. One is the reduction of annotated\\nentities and the other is treating unlabeled entities as negative instances.\\nThe first cause has less impact than the second one and can be mitigated by\\nadopting pretraining language models. The second cause seriously misguides a\\nmodel in training and greatly affects its performances. Based on the above\\nobservations, we propose a general approach that is capable of eliminating the\\nmisguidance brought by unlabeled entities. The core idea is using negative\\nsampling to keep the probability of training with unlabeled entities at a very\\nlow level. Experiments on synthetic datasets and real-world datasets show that\\nour model is robust to unlabeled entity problem and surpasses prior baselines.\\nOn well-annotated datasets, our model is competitive with state-of-the-art\\nmethod.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2012.05426'}, {'title': 'Application-aware Congestion Mitigation for High-Performance Computing Systems. (arXiv:2012.07755v2 [cs.DC] UPDATED)', 'description': '<p>High-performance computing (HPC) systems frequently experience congestion\\nleading to significant application performance variation. However, the impact\\nof congestion on application runtime differs from application to application\\ndepending on their network characteristics (such as bandwidth and latency\\nrequirements). We leverage this insight to develop Netscope, an automated\\nML-driven framework that considers those network characteristics to dynamically\\nmitigate congestion. We evaluate Netscope on four Cray Aries systems, including\\na production supercomputer on real scientific applications. Netscope has a\\nlower training cost and accurately estimates the impact of congestion on\\napplication runtime with a correlation between 0.7and 0.9 for common scientific\\napplications. Moreover, we find that Netscope reduces tail runtime variability\\nby up to 14.9 times while improving median system utility by 12%.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2012.07755'}, {'title': 'The Parameterized Suffix Tray. (arXiv:2012.10092v2 [cs.DS] UPDATED)', 'description': '<p>Let $\\\\Sigma$ and $\\\\Pi$ be disjoint alphabets, respectively called the static\\nalphabet and the parameterized alphabet. Two strings $x$ and $y$ over $\\\\Sigma\\n\\\\cup \\\\Pi$ of equal length are said to parameterized match (p-match) if there\\nexists a renaming bijection $f$ on $\\\\Sigma$ and $\\\\Pi$ which is identity on\\n$\\\\Sigma$ and maps the characters of $x$ to those of $y$ so that the two strings\\nbecome identical. The indexing version of the problem of finding p-matching\\noccurrences of a given pattern in the text is a well-studied topic in string\\nmatching. In this paper, we present a state-of-the-art indexing structure for\\np-matching called the parameterized suffix tray of an input text $T$, denoted\\nby $\\\\mathsf{PSTray}(T)$. We show that $\\\\mathsf{PSTray}(T)$ occupies $O(n)$\\nspace and supports pattern matching queries in $O(m + \\\\log (\\\\sigma+\\\\pi) +\\n\\\\mathit{occ})$ time, where $n$ is the length of $T$, $m$ is the length of a\\nquery pattern $P$, $\\\\pi$ is the number of distinct symbols of $|\\\\Pi|$ in $T$,\\n$\\\\sigma$ is the number of distinct symbols of $|\\\\Sigma|$ in $T$ and\\n$\\\\mathit{occ}$ is the number of p-matching occurrences of $P$ in $T$. We also\\npresent how to build $\\\\mathsf{PSTray}(T)$ in $O(n)$ time from the parameterized\\nsuffix tree of $T$.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2012.10092'}, {'title': 'FcaNet: Frequency Channel Attention Networks. (arXiv:2012.11879v3 [cs.CV] UPDATED)', 'description': '<p>Attention mechanism, especially channel attention, has gained great success\\nin the computer vision field. Many works focus on how to design efficient\\nchannel attention mechanisms while ignoring a fundamental problem, i.e., using\\nglobal average pooling (GAP) as the unquestionable pre-processing method. In\\nthis work, we start from a different view and rethink channel attention using\\nfrequency analysis. Based on the frequency analysis, we mathematically prove\\nthat the conventional GAP is a special case of the feature decomposition in the\\nfrequency domain. With the proof, we naturally generalize the pre-processing of\\nchannel attention mechanism in the frequency domain and propose FcaNet with\\nnovel multi-spectral channel attention. The proposed method is simple but\\neffective. We can change only one line of code in the calculation to implement\\nour method within existing channel attention methods. Moreover, the proposed\\nmethod achieves state-of-the-art results compared with other channel attention\\nmethods on image classification, object detection, and instance segmentation\\ntasks. Our method could improve by 1.8% in terms of Top-1 accuracy on ImageNet\\ncompared with the baseline SENet-50, with the same number of parameters and the\\nsame computational cost. Our code and models are publicly available at\\nhttps://github.com/cfzd/FcaNet.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2012.11879'}, {'title': 'Fundamental Limits on the Maximum Deviations in Control Systems: How Short Can Distribution Tails be Made by Feedback?. (arXiv:2012.12174v4 [eess.SY] UPDATED)', 'description': '<p>This paper is on the application of information theory to the analysis of\\nfundamental lower bounds on the maximum deviations in feedback control systems,\\nwhere the plant is linear time-invariant while the controller can generically\\nbe any causal functions as long as it stabilizes the plant. It is seen in\\ngeneral that the lower bounds are characterized by the unstable poles (or\\nnonminimum-phase zeros) of the plant as well as the conditional entropy of the\\ndisturbance. Such bounds provide fundamental limits on how short the\\ndistribution tails in control systems can be made by feedback.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2012.12174'}, {'title': 'Existence and Computation of Maximin Fair Allocations Under Matroid-Rank Valuations. (arXiv:2012.12710v2 [cs.GT] UPDATED)', 'description': '<p>We study fair and economically efficient allocation of indivisible goods\\namong agents whose valuations are rank functions of matroids. Such valuations\\nconstitute a well-studied class of submodular functions (i.e., they exhibit a\\ndiminishing returns property) and model preferences in several\\nresource-allocation settings. We prove that, for matroid-rank valuations, a\\nsocial welfare-maximizing allocation that gives each agent her maximin share\\nalways exists. Furthermore, such an allocation can be computed in polynomial\\ntime. We establish similar existential and algorithmic results for the pairwise\\nmaximin share guarantee as well.\\n</p>\\n<p>To complement these results, we show that if the agents have binary XOS\\nvaluations or weighted-rank valuations, then maximin fair allocations are not\\nguaranteed to exist. Both of these valuation classes are immediate\\ngeneralizations of matroid-rank functions.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2012.12710'}, {'title': 'Reinforcement Learning for Control of Valves. (arXiv:2012.14668v2 [cs.LG] UPDATED)', 'description': '<p>This paper is a study of reinforcement learning (RL) as an optimal-control\\nstrategy for control of nonlinear valves. It is evaluated against the PID\\n(proportional-integral-derivative) strategy, using a unified framework. RL is\\nan autonomous learning mechanism that learns by interacting with its\\nenvironment. It is gaining increasing attention in the world of control systems\\nas a means of building optimal-controllers for challenging dynamic and\\nnonlinear processes. Published RL research often uses open-source tools (Python\\nand OpenAI Gym environments). We use MATLAB\\'s recently launched (R2019a)\\nReinforcement Learning Toolbox to develop the valve controller; trained using\\nthe DDPG (Deep Deterministic Policy-Gradient) algorithm and Simulink to\\nsimulate the nonlinear valve and create the experimental test-bench for\\nevaluation. Simulink allows industrial engineers to quickly adapt and\\nexperiment with other systems of their choice. Results indicate that the RL\\ncontroller is extremely good at tracking the signal with speed and produces a\\nlower error with respect to the reference signal. The PID, however, is better\\nat disturbance rejection and hence provides a longer life for the valves.\\nSuccessful machine learning involves tuning many hyperparameters requiring\\nsignificant investment of time and efforts. We introduce \"Graded Learning\" as a\\nsimplified, application oriented adaptation of the more formal and algorithmic\\n\"Curriculum for Reinforcement Learning\". It is shown via experiments that it\\nhelps converge the learning task of complex non-linear real world systems.\\nFinally, experiential learnings gained from this research are corroborated\\nagainst published research.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2012.14668'}, {'title': 'Towards User Scheduling for 6G: A Fairness-Oriented Scheduler Using Multi-Agent Reinforcement Learning. (arXiv:2012.15081v3 [cs.OS] UPDATED)', 'description': '<p>User scheduling is a classical problem and key technology in wireless\\ncommunication, which will still plays an important role in the prospective 6G.\\nThere are many sophisticated schedulers that are widely deployed in the base\\nstations, such as Proportional Fairness (PF) and Round-Robin Fashion (RRF). It\\nis known that the Opportunistic (OP) scheduling is the optimal scheduler for\\nmaximizing the average user data rate (AUDR) considering the full buffer\\ntraffic. But the optimal strategy achieving the highest fairness still remains\\nlargely unknown both in the full buffer traffic and the bursty traffic. In this\\nwork, we investigate the problem of fairness-oriented user scheduling,\\nespecially for the RBG allocation. We build a user scheduler using Multi-Agent\\nReinforcement Learning (MARL), which conducts distributional optimization to\\nmaximize the fairness of the communication system. The agents take the\\ncross-layer information (e.g. RSRP, Buffer size) as state and the RBG\\nallocation result as action, then explore the optimal solution following a\\nwell-defined reward function designed for maximizing fairness. Furthermore, we\\ntake the 5%-tile user data rate (5TUDR) as the key performance indicator (KPI)\\nof fairness, and compare the performance of MARL scheduling with PF scheduling\\nand RRF scheduling by conducting extensive simulations. And the simulation\\nresults show that the proposed MARL scheduling outperforms the traditional\\nschedulers.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2012.15081'}, {'title': 'CASS: Towards Building a Social-Support Chatbot for Online Health Community. (arXiv:2101.01583v3 [cs.HC] UPDATED)', 'description': \"<p>Chatbots systems, despite their popularity in today's HCI and CSCW research,\\nfall short for one of the two reasons: 1) many of the systems use a rule-based\\ndialog flow, thus they can only respond to a limited number of pre-defined\\ninputs with pre-scripted responses; or 2) they are designed with a focus on\\nsingle-user scenarios, thus it is unclear how these systems may affect other\\nusers or the community. In this paper, we develop a generalizable chatbot\\narchitecture (CASS) to provide social support for community members in an\\nonline health community. The CASS architecture is based on advanced neural\\nnetwork algorithms, thus it can handle new inputs from users and generate a\\nvariety of responses to them. CASS is also generalizable as it can be easily\\nmigrate to other online communities. With a follow-up field experiment, CASS is\\nproven useful in supporting individual members who seek emotional support. Our\\nwork also contributes to fill the research gap on how a chatbot may influence\\nthe whole community's engagement.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2101.01583'}, {'title': 'Scalable Parallel Linear Solver for Compact Banded Systems on Heterogeneous Architectures. (arXiv:2101.02286v2 [cs.DC] UPDATED)', 'description': '<p>A scalable algorithm for solving compact banded linear systems on distributed\\nmemory architectures is presented. The proposed method factorizes the original\\nsystem into two levels of memory hierarchies, and solves it using parallel\\ncyclic reduction on both distributed and shared memory. This method has a lower\\ncommunication footprint across distributed memory partitions compared to\\nconventional algorithms involving data transpose or re-partitioning. The\\nalgorithm developed in this work is generalized to cyclic compact banded\\nsystems with flexible data decompositions. For cyclic compact banded systems,\\nthe method is a direct solver with a deterministic operation and communication\\ncounts depending on the matrix size, its bandwidth, and the partition strategy.\\nThe implementation and runtime configuration details are discussed for\\nperformance optimization. Scalability is demonstrated on the linear solver as\\nwell as on a representative fluid mechanics application problem, in which the\\ndominant computational cost is solving the cyclic tridiagonal linear systems of\\ncompact numerical schemes on a 3D periodic domain. The algorithm is\\nparticularly useful for solving the linear systems arising from the application\\nof compact finite difference operators to a wide range of partial differential\\nequation problems, such as but not limited to the numerical simulations of\\ncompressible turbulent flows, aeroacoustics, elastic-plastic wave propagation,\\nand electromagnetics. It alleviates obstacles to their use on modern high\\nperformance computing hardware, where memory and computational power are\\ndistributed across nodes with multi-threaded processing units.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.02286'}, {'title': 'The joint role of geometry and illumination on material recognition. (arXiv:2101.02496v2 [cs.CV] UPDATED)', 'description': '<p>Observing and recognizing materials is a fundamental part of our daily life.\\nUnder typical viewing conditions, we are capable of effortlessly identifying\\nthe objects that surround us and recognizing the materials they are made of.\\nNevertheless, understanding the underlying perceptual processes that take place\\nto accurately discern the visual properties of an object is a long-standing\\nproblem. In this work, we perform a comprehensive and systematic analysis of\\nhow the interplay of geometry, illumination, and their spatial frequencies\\naffects human performance on material recognition tasks. We carry out\\nlarge-scale behavioral experiments where participants are asked to recognize\\ndifferent reference materials among a pool of candidate samples. In the\\ndifferent experiments, we carefully sample the information in the frequency\\ndomain of the stimuli. From our analysis, we find significant first-order\\ninteractions between the geometry and the illumination, of both the reference\\nand the candidates. In addition, we observe that simple image statistics and\\nhigher-order image histograms do not correlate with human performance.\\nTherefore, we perform a high-level comparison of highly non-linear statistics\\nby training a deep neural network on material recognition tasks. Our results\\nshow that such models can accurately classify materials, which suggests that\\nthey are capable of defining a meaningful representation of material appearance\\nfrom labeled proximal image data. Last, we find preliminary evidence that these\\nhighly non-linear models and humans may use similar high-level factors for\\nmaterial recognition tasks.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.02496'}, {'title': 'Explain and Predict, and then Predict Again. (arXiv:2101.04109v2 [cs.CL] UPDATED)', 'description': '<p>A desirable property of learning systems is to be both effective and\\ninterpretable. Towards this goal, recent models have been proposed that first\\ngenerate an extractive explanation from the input text and then generate a\\nprediction on just the explanation called explain-then-predict models. These\\nmodels primarily consider the task input as a supervision signal in learning an\\nextractive explanation and do not effectively integrate rationales data as an\\nadditional inductive bias to improve task performance. We propose a novel yet\\nsimple approach ExPred, that uses multi-task learning in the explanation\\ngeneration phase effectively trading-off explanation and prediction losses. And\\nthen we use another prediction network on just the extracted explanations for\\noptimizing the task performance. We conduct an extensive evaluation of our\\napproach on three diverse language datasets -- fact verification, sentiment\\nclassification, and QA -- and find that we substantially outperform existing\\napproaches.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.04109'}, {'title': 'What Do We Mean by \"Accessibility Research\"? A Literature Survey of Accessibility Papers in CHI and ASSETS from 1994 to 2019. (arXiv:2101.04271v4 [cs.HC] UPDATED)', 'description': \"<p>Accessibility research has grown substantially in the past few decades, yet\\nthere has been no literature review of the field. To understand current and\\nhistorical trends, we created and analyzed a dataset of accessibility papers\\nappearing at CHI and ASSETS since ASSETS' founding in 1994. We qualitatively\\ncoded areas of focus and methodological decisions for the past 10 years\\n(2010-2019, N=506 papers), and analyzed paper counts and keywords over the full\\n26 years (N=836 papers). Our findings highlight areas that have received\\ndisproportionate attention and those that are underserved--for example, over\\n43% of papers in the past 10 years are on accessibility for blind and low\\nvision people. We also capture common study characteristics, such as the roles\\nof disabled and nondisabled participants as well as sample sizes (e.g., a\\nmedian of 13 for participant groups with disabilities and older adults). We\\nclose by critically reflecting on gaps in the literature and offering guidance\\nfor future work in the field.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2101.04271'}, {'title': 'Robustness of on-device Models: Adversarial Attack to Deep Learning Models on Android Apps. (arXiv:2101.04401v2 [cs.LG] UPDATED)', 'description': \"<p>Deep learning has shown its power in many applications, including object\\ndetection in images, natural-language understanding, and speech recognition. To\\nmake it more accessible to end users, many deep learning models are now\\nembedded in mobile apps. Compared to offloading deep learning from smartphones\\nto the cloud, performing machine learning on-device can help improve latency,\\nconnectivity, and power consumption. However, most deep learning models within\\nAndroid apps can easily be obtained via mature reverse engineering, while the\\nmodels' exposure may invite adversarial attacks. In this study, we propose a\\nsimple but effective approach to hacking deep learning models using adversarial\\nattacks by identifying highly similar pre-trained models from TensorFlow Hub.\\nAll 10 real-world Android apps in the experiment are successfully attacked by\\nour approach. Apart from the feasibility of the model attack, we also carry out\\nan empirical study that investigates the characteristics of deep learning\\nmodels used by hundreds of Android apps on Google Play. The results show that\\nmany of them are similar to each other and widely use fine-tuning techniques to\\npre-trained models on the Internet.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2101.04401'}, {'title': 'Survival of the strictest: Stable and unstable equilibria under regularized learning with partial information. (arXiv:2101.04667v2 [cs.GT] UPDATED)', 'description': '<p>In this paper, we examine the Nash equilibrium convergence properties of\\nno-regret learning in general N-player games. For concreteness, we focus on the\\narchetypal follow the regularized leader (FTRL) family of algorithms, and we\\nconsider the full spectrum of uncertainty that the players may encounter - from\\nnoisy, oracle-based feedback, to bandit, payoff-based information. In this\\ngeneral context, we establish a comprehensive equivalence between the stability\\nof a Nash equilibrium and its support: a Nash equilibrium is stable and\\nattracting with arbitrarily high probability if and only if it is strict (i.e.,\\neach equilibrium strategy has a unique best response). This equivalence extends\\nexisting continuous-time versions of the folk theorem of evolutionary game\\ntheory to a bona fide algorithmic learning setting, and it provides a clear\\nrefinement criterion for the prediction of the day-to-day behavior of no-regret\\nlearning in games\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.04667'}, {'title': 'ChemNODE: A Neural Ordinary Differential Equations Approach for Chemical Kinetics Solvers. (arXiv:2101.04749v2 [cs.CE] UPDATED)', 'description': '<p>The main bottleneck when performing computational fluid dynamics (CFD)\\nsimulations of combustion systems is the computation and integration of the\\nhighly non-linear and stiff chemical source terms. In recent times, machine\\nlearning has emerged as a promising tool to accelerate combustion chemistry,\\ninvolving the use of regression models to predict the chemical source terms as\\nfunctions of the thermochemical state of the system. However, combustion is a\\nhighly nonlinear phenomenon, and this often leads to divergence from the true\\nsolution when the neural network representation of chemical kinetics is\\nintegrated in time. This is because these approaches minimize the error during\\ntraining without guaranteeing successful integration with ordinary differential\\nequation (ODE) solvers. In this work, a novel neural ODE approach to combustion\\nmodeling, ChemNODE, is developed to address this issue. The source terms\\npredicted by the neural network are integrated during training, and by\\nbackpropagating errors through the ODE solver, the neural network weights are\\nadjusted accordingly to minimize the difference between the predicted and\\nactual ODE solutions. It is shown that even when the dimensionality of the\\nthermochemical manifold is trimmed to remove redundant species, the proposed\\napproach accurately captures the correct physical behavior and reproduces the\\nresults obtained using the full chemical kinetic mechanism.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.04749'}, {'title': 'MFFCN: Multi-layer Feature Fusion Convolution Network for Audio-visual Speech Enhancement. (arXiv:2101.05975v2 [eess.AS] UPDATED)', 'description': '<p>The purpose of speech enhancement is to extract target speech signal from a\\nmixture of sounds generated from several sources. Speech enhancement can\\npotentially benefit from the visual information from the target speaker, such\\nas lip move-ment and facial expressions, because the visual aspect of speech\\nisessentially unaffected by acoustic environment. In order to fuse audio and\\nvisual information, an audio-visual fusion strategy is proposed, which goes\\nbeyond simple feature concatenation and learns to automatically align the two\\nmodalities, leading to more powerful representation which increase\\nintelligibility in noisy conditions. The proposed model fuses audio-visual\\nfeatureslayer by layer, and feed these audio-visual features to each\\ncorresponding decoding layer. Experiment results show relative improvement from\\n6% to 24% on test sets over the audio modalityalone, depending on audio noise\\nlevel. Moreover, there is a significant increase of PESQ from 1.21 to 2.06 in\\nour -15 dB SNR experiment.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.05975'}, {'title': 'AMFFCN: Attentional Multi-layer Feature Fusion Convolution Network for Audio-visual Speech Enhancement. (arXiv:2101.06268v2 [eess.AS] UPDATED)', 'description': '<p>Audio-visual speech enhancement system is regarded to be one of promising\\nsolutions for isolating and enhancing speech of desired speaker. Conventional\\nmethods focus on predicting clean speech spectrum via a naive convolution\\nneural network based encoder-decoder architecture, and these methods a) not\\nadequate to use data fully and effectively, b) cannot process features\\nselectively. The proposed model addresses these drawbacks, by a) applying a\\nmodel that fuses audio and visual features layer by layer in encoding phase,\\nand that feeds fused audio-visual features to each corresponding decoder layer,\\nand more importantly, b) introducing soft threshold attention into the model to\\nselect the informative modality softly. This paper proposes attentional\\naudio-visual multi-layer feature fusion model, in which soft threshold\\nattention unit are applied on feature mapping at every layer of decoder. The\\nproposed model demonstrates the superior performance of the network against the\\nstate-of-the-art models.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.06268'}, {'title': 'Byzantine Generals in the Permissionless Setting. (arXiv:2101.07095v2 [cs.DC] UPDATED)', 'description': '<p>Consensus protocols have traditionally been studied in a setting where all\\nparticipants are known to each other from the start of the protocol execution.\\nIn the parlance of the \\'blockchain\\' literature, this is referred to as the\\npermissioned setting. What differentiates Bitcoin from these previously studied\\nprotocols is that it operates in a permissionless setting, i.e. it is a\\nprotocol for establishing consensus over an unknown network of participants\\nthat anybody can join, with as many identities as they like in any role. The\\narrival of this new form of protocol brings with it many questions. Beyond\\nBitcoin, what can we prove about permissionless protocols in a general sense?\\nHow does recent work on permissionless protocols in the blockchain literature\\nrelate to the well-developed history of research on permissioned protocols in\\ndistributed computing?\\n</p>\\n<p>To answer these questions, we describe a formal framework for the analysis of\\nboth permissioned and permissionless systems. Our framework allows for\\n\"apples-to-apples\" comparisons between different categories of protocols and,\\nin turn, the development of theory to formally discuss their relative merits. A\\nmajor benefit of the framework is that it facilitates the application of a rich\\nhistory of proofs and techniques in distributed computing to problems in\\nblockchain and the study of permissionless systems. Within our framework, we\\nthen address the questions above. We consider the Byzantine Generals Problem as\\na formalisation of the problem of reaching consensus, and address a programme\\nof research that asks, \"Under what adversarial conditions, and for what types\\nof permissionless protocol, is consensus possible?\" We prove a number of\\nresults for this programme, our main result being that deterministic consensus\\nis not possible for decentralised permissionless protocols. To close, we give a\\nlist of seven open questions.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.07095'}, {'title': 'Deep Reinforcement Learning for Active High Frequency Trading. (arXiv:2101.07107v2 [cs.LG] UPDATED)', 'description': \"<p>We introduce the first end-to-end Deep Reinforcement Learning (DRL) based\\nframework for active high frequency trading. We train DRL agents to trade one\\nunit of Intel Corporation stock by employing the Proximal Policy Optimization\\nalgorithm. The training is performed on three contiguous months of high\\nfrequency Limit Order Book data, of which the last month constitutes the\\nvalidation data. In order to maximise the signal to noise ratio in the training\\ndata, we compose the latter by only selecting training samples with largest\\nprice changes. The test is then carried out on the following month of data.\\nHyperparameters are tuned using the Sequential Model Based Optimization\\ntechnique. We consider three different state characterizations, which differ in\\ntheir LOB-based meta-features. Analysing the agents' performances on test data,\\nwe argue that the agents are able to create a dynamic representation of the\\nunderlying environment. They identify occasional regularities present in the\\ndata and exploit them to create long-term profitable trading strategies.\\nIndeed, agents learn trading strategies able to produce stable positive returns\\nin spite of the highly stochastic and non-stationary environment.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2101.07107'}, {'title': 'Policy choices can help keep 4G and 5G universal broadband affordable. (arXiv:2101.07820v2 [econ.GN] UPDATED)', 'description': '<p>In recognition of the transformative opportunities that broadband\\nconnectivity presents, the United Nations Broadband Commission has committed\\nthe international community to accelerate universal access across the\\ndeveloping world. However, the cost of meeting this objective, and the\\nfeasibility of doing so on a commercially viable basis, are not well\\nunderstood. This paper compares the global cost-effectiveness of different\\ninfrastructure strategies for the developing world to achieve universal 4G or\\n5G mobile broadband. Utilizing remote sensing and geospatial infrastructure\\nsimulation, least-cost network designs are developed for eight representative\\nlow and middle-income countries (Malawi, Uganda, Kenya, Senegal, Pakistan,\\nAlbania, Peru and Mexico), the results from which form the basis for\\naggregation to the global level. To provide at least 2 Mbps per user, 4G is\\noften the cheapest option to reach universal coverage. The cost of meeting the\\nUN Broadband Commission target of a minimum 10 Mbps per user is estimated at\\n$1.7 trillion using 5G NSA, equating to approximately 0.6% of annual GDP for\\nthe developing world over the next decade. However, by creating a favorable\\nregulatory environment, governments can bring down these costs by as much as\\nthree quarters, to $0.5 trillion (approximately 0.2% of annual GDP), and avoid\\nthe need for public subsidy. Providing governments make judicious choices,\\nadopting fiscal and regulatory regimes conducive to lowering costs, broadband\\nuniversal service may be within reach of most developing countries over the\\nnext decade.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.07820'}, {'title': 'TCLR: Temporal Contrastive Learning for Video Representation. (arXiv:2101.07974v2 [cs.CV] UPDATED)', 'description': '<p>Contrastive learning has nearly closed the gap between supervised and\\nself-supervised learning of image representations. Existing extensions of\\ncontrastive learning to the domain of video data however do not explicitly\\nattempt to represent the internal distinctiveness across the temporal dimension\\nof video clips. We develop a new temporal contrastive learning framework\\nconsisting of two novel losses to improve upon existing contrastive\\nself-supervised video representation learning methods. The first loss adds the\\ntask of discriminating between non-overlapping clips from the same video,\\nwhereas the second loss aims to discriminate between timesteps of the feature\\nmap of an input clip in order to increase the temporal diversity of the\\nfeatures. Temporal contrastive learning achieves significant improvement over\\nthe state-of-the-art results in downstream video understanding tasks such as\\naction recognition, limited-label action classification, and nearest-neighbor\\nvideo retrieval on video datasets across multiple 3D CNN architectures. With\\nthe commonly used 3D-ResNet-18 architecture, we achieve 82.4% (+5.1% increase\\nover the previous best) top-1 accuracy on UCF101 and 52.9% (+5.4% increase) on\\nHMDB51 action classification, and 56.2% (+11.7% increase) Top-1 Recall on\\nUCF101 nearest neighbor video retrieval.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.07974'}, {'title': 'Few-shot Action Recognition with Prototype-centered Attentive Learning. (arXiv:2101.08085v2 [cs.CV] UPDATED)', 'description': '<p>Few-shot action recognition aims to recognize action classes with few\\ntraining samples. Most existing methods adopt a meta-learning approach with\\nepisodic training. In each episode, the few samples in a meta-training task are\\nsplit into support and query sets. The former is used to build a classifier,\\nwhich is then evaluated on the latter using a query-centered loss for model\\nupdating. There are however two major limitations: lack of data efficiency due\\nto the query-centered only loss design and inability to deal with the support\\nset outlying samples and inter-class distribution overlapping problems. In this\\npaper, we overcome both limitations by proposing a new Prototype-centered\\nAttentive Learning (PAL) model composed of two novel components. First, a\\nprototype-centered contrastive learning loss is introduced to complement the\\nconventional query-centered learning objective, in order to make full use of\\nthe limited training samples in each episode. Second, PAL further integrates a\\nhybrid attentive learning mechanism that can minimize the negative impacts of\\noutliers and promote class separation. Extensive experiments on four standard\\nfew-shot action benchmarks show that our method clearly outperforms previous\\nstate-of-the-art methods, with the improvement particularly significant (10+\\\\%)\\non the most challenging fine-grained action recognition benchmark.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.08085'}, {'title': 'Rank the Episodes: A Simple Approach for Exploration in Procedurally-Generated Environments. (arXiv:2101.08152v2 [cs.LG] UPDATED)', 'description': '<p>Exploration under sparse reward is a long-standing challenge of model-free\\nreinforcement learning. The state-of-the-art methods address this challenge by\\nintroducing intrinsic rewards to encourage exploration in novel states or\\nuncertain environment dynamics. Unfortunately, methods based on intrinsic\\nrewards often fall short in procedurally-generated environments, where a\\ndifferent environment is generated in each episode so that the agent is not\\nlikely to visit the same state more than once. Motivated by how humans\\ndistinguish good exploration behaviors by looking into the entire episode, we\\nintroduce RAPID, a simple yet effective episode-level exploration method for\\nprocedurally-generated environments. RAPID regards each episode as a whole and\\ngives an episodic exploration score from both per-episode and long-term views.\\nThose highly scored episodes are treated as good exploration behaviors and are\\nstored in a small ranking buffer. The agent then imitates the episodes in the\\nbuffer to reproduce the past good exploration behaviors. We demonstrate our\\nmethod on several procedurally-generated MiniGrid environments, a\\nfirst-person-view 3D Maze navigation task from MiniWorld, and several sparse\\nMuJoCo tasks. The results show that RAPID significantly outperforms the\\nstate-of-the-art intrinsic reward strategies in terms of sample efficiency and\\nfinal performance. The code is available at https://github.com/daochenzha/rapid\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.08152'}, {'title': 'A novel DL approach to PE malware detection: exploring Glove vectorization, MCC_RCNN and feature fusion. (arXiv:2101.08969v3 [cs.CR] UPDATED)', 'description': '<p>In recent years, malware becomes more threatening. Concerning the increasing\\nmalware variants, there comes Machine Learning (ML)-based and Deep Learning\\n(DL)-based approaches for heuristic detection. Nevertheless, the prediction\\naccuracy of both needs to be improved. In response to the above issues in the\\nPE malware domain, we propose the DL-based approaches for detection and use\\nstatic-based features fed up into models. The contributions are as follows: we\\nrecapitulate existing malware detection methods. That is, we propose a\\nvec-torized representation model of the malware instruction layer and semantic\\nlayer based on Glove. We implement a neural network model called MCC_RCNN\\n(Malware Detection and Recurrent Convolutional Neural Network), comprising of\\nthe combination with CNN and RNN. Moreover, we provide a description of feature\\nfusion in static behavior levels. With the numerical results generated from\\nseveral comparative experiments towards evaluating the Glove-based\\nvectoriza-tion, MCC_RCNN-based classification methodology and feature fusion\\nstages, our proposed classification methods can obtain a higher prediction\\naccuracy than the other baseline methods.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.08969'}, {'title': 'Beyond Domain APIs: Task-oriented Conversational Modeling with Unstructured Knowledge Access Track in DSTC9. (arXiv:2101.09276v3 [cs.CL] UPDATED)', 'description': '<p>Most prior work on task-oriented dialogue systems are restricted to a limited\\ncoverage of domain APIs, while users oftentimes have domain related requests\\nthat are not covered by the APIs. This challenge track aims to expand the\\ncoverage of task-oriented dialogue systems by incorporating external\\nunstructured knowledge sources. We define three tasks: knowledge-seeking turn\\ndetection, knowledge selection, and knowledge-grounded response generation. We\\nintroduce the data sets and the neural baseline models for three tasks. The\\nchallenge track received a total of 105 entries from 24 participating teams. In\\nthe evaluation results, the ensemble methods with different large-scale\\npretrained language models achieved high performances with improved knowledge\\nselection capability and better generalization into unseen data.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.09276'}, {'title': 'Advances and Challenges in Conversational Recommender Systems: A Survey. (arXiv:2101.09459v4 [cs.IR] UPDATED)', 'description': '<p>Recommender systems exploit interaction history to estimate user preference,\\nhaving been heavily used in a wide range of industry applications. However,\\nstatic recommendation models are difficult to answer two important questions\\nwell due to inherent shortcomings: (a) What exactly does a user like? (b) Why\\ndoes a user like an item? The shortcomings are due to the way that static\\nmodels learn user preference, i.e., without explicit instructions and active\\nfeedback from users. The recent rise of conversational recommender systems\\n(CRSs) changes this situation fundamentally. In a CRS, users and the system can\\ndynamically communicate through natural language interactions, which provide\\nunprecedented opportunities to explicitly obtain the exact preference of users.\\nConsiderable efforts, spread across disparate settings and applications, have\\nbeen put into developing CRSs. Existing models, technologies, and evaluation\\nmethods for CRSs are far from mature. In this paper, we provide a systematic\\nreview of the techniques used in current CRSs. We summarize the key challenges\\nof developing CRSs into five directions: (1) Question-based user preference\\nelicitation. (2) Multi-turn conversational recommendation strategies. (3)\\nDialogue understanding and generation. (4) Exploitation-exploration trade-offs.\\n(5) Evaluation and user simulation. These research directions involve multiple\\nresearch fields like information retrieval (IR), natural language processing\\n(NLP), and human-computer interaction (HCI). Based on these research\\ndirections, we discuss some future challenges and opportunities. We provide a\\nroad map for researchers from multiple communities to get started in this area.\\nWe hope this survey helps to identify and address challenges in CRSs and\\ninspire future research.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.09459'}, {'title': 'Set Reconciliation for Blockchains with Slepian-Wolf Coding: Deletion Polar Codes. (arXiv:2101.09963v2 [cs.IT] UPDATED)', 'description': '<p>In this paper, we propose a polar coding based scheme for set reconciliation\\nbetween two network nodes. The system is modeled as a well-known Slepian-Wolf\\nsetting induced by a fixed number of deletions. The set reconciliation process\\nis divided into two phases: 1) a deletion polar code is employed to help one\\nnode to identify the possible deletion indices, which may be larger than the\\nnumber of genuine deletions; 2) a lossless compression polar code is then\\ndesigned to feedback those indices with minimum overhead. Our scheme can be\\nviewed as a generalization of polar codes to some emerging network-based\\napplications such as the package synchronization in blockchains. Some\\nconnections with the existing schemes based on the invertible Bloom lookup\\ntables (IBLTs) and network coding are also observed and briefly discussed.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.09963'}, {'title': 'Classical simulations of communication channels. (arXiv:2101.10985v2 [cs.IT] UPDATED)', 'description': '<p>We investigate whether certain non-classical communication channels can be\\nsimulated by a classical channel with a given number of states and a given\\namount of noise. It is proved that any noisy quantum channel can be simulated\\nby the corresponding noisy classical channel. General probabilistic channels\\nare also studied.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.10985'}, {'title': 'Launchers and Targets in Social Networks. (arXiv:2101.11337v2 [cs.SI] UPDATED)', 'description': \"<p>Influence propagation in social networks is a subject of growing interest. A\\nrelevant issue in those networks involves the identification of key\\ninfluencers. These players have an important role on viral marketing strategies\\nand message propagation, including political propaganda and fake news. In\\neffect, an important way to fight malicious usage on social networks is to\\nunderstand their properties, their structure and the way messages propagate.\\n</p>\\n<p>This paper proposes two new indices for analysing message propagation in\\nsocial networks, based on the network topological nature and the power of the\\nmessage. The first index involves the strength of each node as a launcher of\\nthe message, dividing the nodes into launchers and non-launchers. The second\\nindex addresses the potential of each member as a receiver (target) of the\\nmessage, dividing the nodes into targets and non-targets. Launcher individuals\\nshould indicate strong influencers and target individuals should identify the\\nbest target consumers. These indices can assist other known metrics when used\\nto select efficient influencers in a social network. For instance, instead of\\nchoosing a strong and probably expensive member according to its degree in the\\nnetwork (number of followers), we may previously select those belonging to the\\nlaunchers group and look for the lowest degree members, which are probably\\ncheaper but still guarantying almost the same influence effectiveness as the\\nlargest degree members.\\n</p>\\n<p>On a different direction, using the second index, the strong target members\\nshould characterize relevant consumers of information in the network, which may\\ninclude fake news' regular collectors.\\n</p>\\n<p>We discuss these indices using small-world randomly generated graphs and a\\nnumber of real-world social networks available in known datasets repositories.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2101.11337'}, {'title': 'SimBle: Generating privacy preserving real-world BLE traces with ground truth. (arXiv:2101.11728v2 [cs.CR] UPDATED)', 'description': \"<p>Bluetooth has become critical as many IoT devices are arriving in the market.\\nMost of the current literature focusing on Bluetooth simulation concentrates on\\nthe network protocols' performances and completely neglects the privacy\\nprotection recommendations introduced in the BLE standard. Indeed, privacy\\nprotection is one of the main issues handled in the Bluetooth standard. For\\ninstance, the current standard forces devices to change the identifier they\\nembed within the public and private packets, known as MAC address\\nrandomization. Although randomizing MAC addresses is intended to preserve\\ndevice privacy, recent literature shows many challenges that are still present.\\nOne of them is the correlation between the public packets and the emitters.\\nUnfortunately, existing evaluation tools such as NS-3 are not designed to\\nreproduce this Bluetooth standard's essential functionality. This makes it\\nimpossible to test solutions for different device-fingerprinting strategies as\\nthere is a lack of ground truth for large-scale scenarios with the majority of\\ncurrent BLE devices implementing MAC address randomization. In this paper, we\\nfirst introduce a solution of standard-compliant MAC address randomization in\\nthe NS-3 framework, capable of emulating any real BLE device in the simulation\\nand generating real-world Bluetooth traces. In addition, since the simulation\\nrun-time for trace-collection grows exponentially with the number of devices,\\nwe introduce an optimization to linearize public-packet sniffing. This made the\\nlarge-scale trace-collection practically feasible. Then, we use the generated\\ntraces and associated ground truth to do a case study on the evaluation of a\\ngeneric MAC address association available in the literature. Our case study\\nreveals that close to 90 percent of randomized addresses could be correctly\\nlinked even in highly dense and mobile scenarios.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2101.11728'}, {'title': 'Exploring Lightweight Interventions at Posting Time to Reduce the Sharing of Misinformation on Social Media. (arXiv:2101.11824v3 [cs.HC] UPDATED)', 'description': \"<p>When users on social media share content without considering its veracity,\\nthey may unwittingly be spreading misinformation. In this work, we investigate\\nthe design of lightweight interventions that nudge users to assess the accuracy\\nof information as they share it. Such assessment may deter users from posting\\nmisinformation in the first place, and their assessments may also provide\\nuseful guidance to friends aiming to assess those posts themselves. In support\\nof lightweight assessment, we first develop a taxonomy of the reasons why\\npeople believe a news claim is or is not true; this taxonomy yields a checklist\\nthat can be used at posting time. We conduct evaluations to demonstrate that\\nthe checklist is an accurate and comprehensive encapsulation of people's\\nfree-response rationales. In a second experiment, we study the effects of three\\nbehavioral nudges -- 1) checkboxes indicating whether headings are accurate, 2)\\ntagging reasons (from our taxonomy) that a post is accurate via a checklist and\\n3) providing free-text rationales for why a headline is or is not accurate --\\non people's intention of sharing the headline on social media. From an\\nexperiment with 1668 participants, we find that both providing accuracy\\nassessment and rationale reduce the sharing of false content. They also reduce\\nthe sharing of true content, but to a lesser degree that yields an overall\\ndecrease in the fraction of shared content that is false. Our findings have\\nimplications for designing social media and news sharing platforms that draw\\nfrom richer signals of content credibility contributed by users. In addition,\\nour validated taxonomy can be used by platforms and researchers as a way to\\ngather rationales in an easier fashion than free-response.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2101.11824'}, {'title': 'Modeling Context in Answer Sentence Selection Systems on a Latency Budget. (arXiv:2101.12093v2 [cs.CL] UPDATED)', 'description': '<p>Answer Sentence Selection (AS2) is an efficient approach for the design of\\nopen-domain Question Answering (QA) systems. In order to achieve low latency,\\ntraditional AS2 models score question-answer pairs individually, ignoring any\\ninformation from the document each potential answer was extracted from. In\\ncontrast, more computationally expensive models designed for machine reading\\ncomprehension tasks typically receive one or more passages as input, which\\noften results in better accuracy. In this work, we present an approach to\\nefficiently incorporate contextual information in AS2 models. For each answer\\ncandidate, we first use unsupervised similarity techniques to extract relevant\\nsentences from its source document, which we then feed into an efficient\\ntransformer architecture fine-tuned for AS2. Our best approach, which leverages\\na multi-way attention architecture to efficiently encode context, improves 6%\\nto 11% over noncontextual state of the art in AS2 with minimal impact on system\\nlatency. All experiments in this work were conducted in English.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.12093'}, {'title': 'From Geometry to Topology: Inverse Theorems for Distributed Persistence. (arXiv:2101.12288v2 [math.AT] UPDATED)', 'description': '<p>What is the \"right\" topological invariant of a large point cloud X? Prior\\nresearch has focused on estimating the full persistence diagram of X, a\\nquantity that is very expensive to compute, unstable to outliers, and far from\\na sufficient statistic. We therefore propose that the correct invariant is not\\nthe persistence diagram of X, but rather the collection of persistence diagrams\\nof many small subsets. This invariant, which we call \"distributed persistence,\"\\nis trivially parallelizable, more stable to outliers, and has a rich inverse\\ntheory. The map from the space of point clouds (with the quasi-isometry metric)\\nto the space of distributed persistence invariants (with the\\nHausdorff-Bottleneck distance) is a global quasi-isometry. This is a much\\nstronger property than simply being injective, as it implies that the inverse\\nof a small neighborhood is a small neighborhood, and is to our knowledge the\\nonly result of its kind in the TDA literature. Moreover, the quasi-isometry\\nbounds depend on the size of the subsets taken, so that as the size of these\\nsubsets goes from small to large, the invariant interpolates between a purely\\ngeometric one and a topological one. Lastly, we note that our inverse results\\ndo not actually require considering all subsets of a fixed size (an enormous\\ncollection), but a relatively small collection satisfying certain covering\\nproperties that arise with high probability when randomly sampling subsets.\\nThese theoretical results are complemented by two synthetic experiments\\ndemonstrating the use of distributed persistence in practice.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.12288'}, {'title': 'NeMo: Neural Mesh Models of Contrastive Features for Robust 3D Pose Estimation. (arXiv:2101.12378v3 [cs.CV] UPDATED)', 'description': '<p>3D pose estimation is a challenging but important task in computer vision. In\\nthis work, we show that standard deep learning approaches to 3D pose estimation\\nare not robust when objects are partially occluded or viewed from a previously\\nunseen pose. Inspired by the robustness of generative vision models to partial\\nocclusion, we propose to integrate deep neural networks with 3D generative\\nrepresentations of objects into a unified neural architecture that we term\\nNeMo. In particular, NeMo learns a generative model of neural feature\\nactivations at each vertex on a dense 3D mesh. Using differentiable rendering\\nwe estimate the 3D object pose by minimizing the reconstruction error between\\nNeMo and the feature representation of the target image. To avoid local optima\\nin the reconstruction loss, we train the feature extractor to maximize the\\ndistance between the individual feature representations on the mesh using\\ncontrastive learning. Our extensive experiments on PASCAL3D+,\\noccluded-PASCAL3D+ and ObjectNet3D show that NeMo is much more robust to\\npartial occlusion and unseen pose compared to standard deep networks, while\\nretaining competitive performance on regular data. Interestingly, our\\nexperiments also show that NeMo performs reasonably well even when the mesh\\nrepresentation only crudely approximates the true object geometry with a\\ncuboid, hence revealing that the detailed 3D geometry is not needed for\\naccurate 3D pose estimation. The code is publicly available at\\nhttps://github.com/Angtian/NeMo.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.12378'}, {'title': 'Disparate Impact Diminishes Consumer Trust Even for Advantaged Users. (arXiv:2101.12715v2 [cs.HC] UPDATED)', 'description': \"<p>Systems aiming to aid consumers in their decision-making (e.g., by\\nimplementing persuasive techniques) are more likely to be effective when\\nconsumers trust them. However, recent research has demonstrated that the\\nmachine learning algorithms that often underlie such technology can act\\nunfairly towards specific groups (e.g., by making more favorable predictions\\nfor men than for women). An undesired disparate impact resulting from this kind\\nof algorithmic unfairness could diminish consumer trust and thereby undermine\\nthe purpose of the system. We studied this effect by conducting a\\nbetween-subjects user study investigating how (gender-related) disparate impact\\naffected consumer trust in an app designed to improve consumers' financial\\ndecision-making. Our results show that disparate impact decreased consumers'\\ntrust in the system and made them less likely to use it. Moreover, we find that\\ntrust was affected to the same degree across consumer groups (i.e., advantaged\\nand disadvantaged users) despite both of these consumer groups recognizing\\ntheir respective levels of personal benefit. Our findings highlight the\\nimportance of fairness in consumer-oriented artificial intelligence systems.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2101.12715'}, {'title': 'OpenMatch: An Open-Source Package for Information Retrieval. (arXiv:2102.00166v2 [cs.IR] UPDATED)', 'description': '<p>Information Retrieval (IR) is an important task and can be used in many\\napplications. Neural IR (Neu-IR) models overcome the vocabulary mismatch\\nproblem of sparse retrievers and thrive on the ranking pipeline with semantic\\nmatching. Recent progress in IR mainly focuses on Neu-IR models, including\\nefficient dense retrieval, advanced neural architectures and robustly training\\nfor few-shot IR that lacks training data. In order to integrate these\\nadvantages for researchers and engineers to utilize and develop, OpenMatch\\nprovides various functional neural modules based on PyTorch to maintain\\nsufficient extensibility, making it easy to build customized and\\nhigher-capacity IR systems. Besides, OpenMatch consists of complicated\\noptimization tricks, various sparse/dense retrieval methods, and advanced\\nfew-shot training methods, liberating users from surplus labor in baseline\\nreimplementation and neural model finetuning. With OpenMatch, we achieve\\nreasonable performance on various ranking datasets, rank first of the automatic\\ngroup in TREC COVID (Round 2) and rank top on the MS MARCO Document Ranking\\nleaderboard. The library, experimental methodologies and results of OpenMatch\\nare all publicly available at https://github.com/thunlp/OpenMatch.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.00166'}, {'title': 'Estimating the Unique Information of Continuous Variables. (arXiv:2102.00218v2 [cs.IT] UPDATED)', 'description': '<p>Partial information decompositions (PIDs) identify different modes in which\\ninformation from multiple sources may affect a target, by isolating\\nsynergistic, redundant, and unique contributions to the mutual information.\\nWhile many works have studied aspects of PIDs for Gaussian and discrete\\ndistributions, the case of general continuous distributions is still uncharted\\nterritory. In this work we present a method for estimating the unique\\ninformation in continuous distributions, for the case of two sources and one\\ntarget. Our method solves the associated optimization problem over the space of\\ndistributions with constrained marginals by combining copula decompositions and\\ntechniques developed to optimize variational autoencoders. We illustrate our\\napproach by showing excellent agreement with known analytic results for\\nGaussians and by analyzing model systems of three coupled random variables.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.00218'}, {'title': 'Choosing the Variable Ordering for Cylindrical Algebraic Decomposition via Exploiting Chordal Structure. (arXiv:2102.00823v2 [cs.SC] UPDATED)', 'description': '<p>Cylindrical algebraic decomposition (CAD) plays an important role in the\\nfield of real algebraic geometry and many other areas. As is well-known, the\\nchoice of variable ordering while computing CAD has a great effect on the time\\nand memory use of the computation as well as the number of sample points\\ncomputed. In this paper, we indicate that typical CAD algorithms, if executed\\nwith respect to a special kind of variable orderings (called \"the perfect\\nelimination orderings\"), naturally preserve chordality, which is an important\\nproperty on sparsity of variables. Experimentation suggests that if the\\nassociated graph of the polynomial system in question is chordal (\\\\emph{resp.},\\nis nearly chordal), then a perfect elimination ordering of the associated graph\\n(\\\\emph{resp.}, of a minimal chordal completion of the associated graph) can be\\na good variable ordering for the CAD computation. That is, by using the perfect\\nelimination orderings, the CAD computation may produce a much smaller full set\\nof projection polynomials than by using other naive variable orderings. More\\nimportantly, for the complexity analysis of the CAD computation via a perfect\\nelimination ordering, a so-called $(m,d)$-property of the full set of\\nprojection polynomials obtained via such an ordering is given, through which\\nthe \"size\" of this set is characterized. This property indicates that when the\\ncorresponding perfect elimination tree has a lower height, the full set of\\nprojection polynomials also tends to have a smaller \"size\". This is well\\nconsistent with the experimental results, hence the perfect elimination\\norderings with lower elimination tree height are further recommended to be used\\nin the CAD projection.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.00823'}, {'title': 'On the dichromatic number of surfaces. (arXiv:2102.01034v2 [math.CO] UPDATED)', 'description': \"<p>In this paper, we give bounds on the dichromatic number $\\\\vec{\\\\chi}(\\\\Sigma)$\\nof a surface $\\\\Sigma$, which is the maximum dichromatic number of an oriented\\ngraph embeddable on $\\\\Sigma$. We determine the asymptotic behaviour of\\n$\\\\vec{\\\\chi}(\\\\Sigma)$ by showing that there exist constants $a_1$ and $a_2$ such\\nthat,\\n</p>\\n<p>$ a_1\\\\frac{\\\\sqrt{-c}}{\\\\log(-c)} \\\\leq \\\\vec{\\\\chi}(\\\\Sigma) \\\\leq a_2\\n\\\\frac{\\\\sqrt{-c}}{\\\\log(-c)} $ for every surface $\\\\Sigma$ with Euler\\ncharacteristic $c\\\\leq -2$. We then give more explicit bounds for some surfaces\\nwith high Euler characteristic. In particular, we show that the dichromatic\\nnumbers of the projective plane $\\\\mathbb{N}_1$, the Klein bottle\\n$\\\\mathbb{N}_2$, the torus $\\\\mathbb{S}_1$, and Dyck's surface $\\\\mathbb{N}_3$ are\\nall equal to $3$, and that the dichromatic numbers of the $5$-torus\\n$\\\\mathbb{S}_5$ and the $10$-cross surface $\\\\mathbb{N}_{10}$ are equal to $4$.\\nWe also consider the complexity of deciding whether a given digraph or oriented\\ngraph embedabble in a fixed surface is $k$-dicolourable. In particular, we show\\nthat for any surface, deciding whether a digraph embeddable on this surface is\\n$2$-dicolourable is NP-complete, and that deciding whether a planar oriented\\ngraph is $2$-dicolourable is NP-complete unless all planar oriented graphs are\\n$2$-dicolourable (which was conjectured by Neumann-Lara).\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.01034'}, {'title': 'A Statistician Teaches Deep Learning. (arXiv:2102.01194v2 [stat.ML] UPDATED)', 'description': '<p>Deep learning (DL) has gained much attention and become increasingly popular\\nin modern data science. Computer scientists led the way in developing deep\\nlearning techniques, so the ideas and perspectives can seem alien to\\nstatisticians. Nonetheless, it is important that statisticians become involved\\n-- many of our students need this expertise for their careers. In this paper,\\ndeveloped as part of a program on DL held at the Statistical and Applied\\nMathematical Sciences Institute, we address this culture gap and provide tips\\non how to teach deep learning to statistics graduate students. After some\\nbackground, we list ways in which DL and statistical perspectives differ,\\nprovide a recommended syllabus that evolved from teaching two iterations of a\\nDL graduate course, offer examples of suggested homework assignments, give an\\nannotated list of teaching resources, and discuss DL in the context of two\\nresearch areas.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.01194'}, {'title': 'T3AB: Transparent and Trustworthy Third-party Authority using Blockchain. (arXiv:2102.01249v2 [cs.CR] UPDATED)', 'description': \"<p>Increasingly, information systems rely on computational, storage, and network\\nresources deployed in third-party facilities or are supported by service\\nproviders. Such an approach further exacerbates cybersecurity concerns\\nconstantly raised by numerous incidents of security and privacy attacks\\nresulting in data leakage and identity theft, among others. These have in turn\\nforced the creation of stricter security and privacy related regulations and\\nhave eroded the trust in cyberspace. In particular, security related services\\nand infrastructures such as Certificate Authorities (CAs) that provide digital\\ncertificate service and Third-Party Authorities (TPAs) that provide\\ncryptographic key services, are critical components for establishing trust in\\nInternet enabled applications and services. To address such trust issues,\\nvarious transparency frameworks and approaches have been recently proposed in\\nthe literature. In this paper, we propose a Transparent and Trustworthy TPA\\nusing Blockchain (T3AB) to provide transparency and accountability to the\\ntrusted third-party entities, such as honest-but-curious third-party IaaS\\nservers, and coordinators in various privacy-preserving machine learning (PPML)\\napproaches. T3AB employs the Ethereum blockchain as the underlying public\\nledger and also includes a novel smart contract to automate accountability with\\nan incentive mechanism that motivates participants' to participate in auditing,\\nand punishes unintentional or malicious behaviors. We implement T3AB, and show\\nthrough experimental evaluation in the Ethereum official test network, Rinkeby,\\nthat the framework is efficient. We also formally show the security guarantee\\nprovided by T3AB, and analyze the privacy guarantee and trustworthiness it\\nprovides.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.01249'}, {'title': 'Gaussian Experts Selection using Graphical Models. (arXiv:2102.01496v2 [cs.LG] UPDATED)', 'description': \"<p>Local approximations are popular methods to scale Gaussian processes (GPs) to\\nbig data. Local approximations reduce time complexity by dividing the original\\ndataset into subsets and training a local expert on each subset. Aggregating\\nthe experts' prediction is done assuming either conditional dependence or\\nindependence between the experts. Imposing the \\\\emph{conditional independence\\nassumption} (CI) between the experts renders the aggregation of different\\nexpert predictions time efficient at the cost of poor uncertainty\\nquantification. On the other hand, modeling dependent experts can provide\\nprecise predictions and uncertainty quantification at the expense of\\nimpractically high computational costs. By eliminating weak experts via a\\ntheory-guided expert selection step, we substantially reduce the computational\\ncost of aggregating dependent experts while ensuring calibrated uncertainty\\nquantification. We leverage techniques from the literature on undirected\\ngraphical models, using sparse precision matrices that encode conditional\\ndependencies between experts to select the most important experts. Moreov\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.01496'}, {'title': 'Permute & Add Network Codes via Group Algebras. (arXiv:2102.01519v2 [cs.IT] UPDATED)', 'description': '<p>A class of network codes have been proposed in the literature where the\\nsymbols transmitted on network edges are binary vectors and the coding\\noperation performed in network nodes consists of the application of (possibly\\nseveral) permutations on each incoming vector and XOR-ing the results to obtain\\nthe outgoing vector. These network codes, which we will refer to as\\npermute-and-add network codes, involve simpler operations and are known to\\nprovide lower complexity solutions than scalar linear codes. The complexity of\\nthese codes is determined by their degree which is the number of permutations\\napplied on each incoming vector to compute an outgoing vector. Constructions of\\npermute-and-add network codes for multicast networks are known. In this paper,\\nwe provide a new framework based on group algebras to design permute-and-add\\nnetwork codes for arbitrary (not necessarily multicast) networks. Our framework\\nallows the use of any finite group of permutations (including circular shifts,\\nproposed in prior work) and admits a trade-off between coding rate and the\\ndegree of the code. Further, our technique permits elegant recovery and\\ngeneralizations of the key results on permute-and-add network codes known in\\nthe literature.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.01519'}, {'title': 'A New Design of Cache-aided Multiuser Private Information Retrieval with Uncoded Prefetching. (arXiv:2102.01643v2 [cs.IT] UPDATED)', 'description': \"<p>In the problem of cache-aided multiuser private information retrieval\\n(MuPIR), a set of $K_{\\\\rm u}$ cache-equipped users wish to privately download a\\nset of messages from $N$ distributed databases each holding a library of $K$\\nmessages. The system works in two phases: {\\\\it cache placement (prefetching)\\nphase} in which the users fill up their cache memory, and {\\\\it private delivery\\nphase} in which the users' demands are revealed and they download an answer\\nfrom each database so that the their desired messages can be recovered while\\neach individual database learns nothing about the identities of the requested\\nmessages. The goal is to design the placement and the private delivery phases\\nsuch that the \\\\emph{load}, which is defined as the total number of downloaded\\nbits normalized by the message size, is minimized given any user memory size.\\nThis paper considers the MuPIR problem with two messages, arbitrary number of\\nusers and databases where uncoded prefetching is assumed, i.e., the users\\ndirectly copy some bits from the library as their cached contents. We propose a\\nnovel MuPIR scheme inspired by the Maddah-Ali and Niesen (MAN) coded caching\\nscheme. The proposed scheme achieves lower load than any existing schemes,\\nespecially the product design (PD), and is shown to be optimal within a factor\\nof $8$ in general and exactly optimal at very high or low memory regime.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.01643'}, {'title': 'On Greedy Approaches to Hierarchical Aggregation. (arXiv:2102.01730v2 [cs.DS] UPDATED)', 'description': '<p>We analyze greedy algorithms for the Hierarchical Aggregation (HAG) problem,\\na strategy introduced in [Jia et al., KDD 2020] for speeding up learning on\\nGraph Neural Networks (GNNs). The idea of HAG is to identify and remove\\nredundancies in computations performed when training GNNs. The associated\\noptimization problem is to identify and remove the most redundancies.\\n</p>\\n<p>Previous work introduced a greedy approach for the HAG problem and claimed a\\n1-1/e approximation factor. We show by example that this is not correct, and\\none cannot hope for better than a 1/2 approximation factor. We prove that this\\ngreedy algorithm does satisfy some (weaker) approximation guarantee, by showing\\na new connection between the HAG problem and maximum matching problems in\\nhypergraphs. We also introduce a second greedy algorithm which can out-perform\\nthe first one, and we show how to implement it efficiently in some parameter\\nregimes. Finally, we introduce some greedy heuristics that are much faster than\\nthe above greedy algorithms, and we demonstrate that they perform well on\\nreal-world graphs.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.01730'}, {'title': 'Provably Secure Federated Learning against Malicious Clients. (arXiv:2102.01854v2 [cs.CR] UPDATED)', 'description': '<p>Federated learning enables clients to collaboratively learn a shared global\\nmodel without sharing their local training data with a cloud server. However,\\nmalicious clients can corrupt the global model to predict incorrect labels for\\ntesting examples. Existing defenses against malicious clients leverage\\nByzantine-robust federated learning methods. However, these methods cannot\\nprovably guarantee that the predicted label for a testing example is not\\naffected by malicious clients. We bridge this gap via ensemble federated\\nlearning. In particular, given any base federated learning algorithm, we use\\nthe algorithm to learn multiple global models, each of which is learnt using a\\nrandomly selected subset of clients. When predicting the label of a testing\\nexample, we take majority vote among the global models. We show that our\\nensemble federated learning with any base federated learning algorithm is\\nprovably secure against malicious clients. Specifically, the label predicted by\\nour ensemble global model for a testing example is provably not affected by a\\nbounded number of malicious clients. Moreover, we show that our derived bound\\nis tight. We evaluate our method on MNIST and Human Activity Recognition\\ndatasets. For instance, our method can achieve a certified accuracy of 88% on\\nMNIST when 20 out of 1,000 clients are malicious.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.01854'}, {'title': 'Causal Collaborative Filtering. (arXiv:2102.01868v2 [cs.IR] UPDATED)', 'description': '<p>Recommender systems are important and valuable tools for many personalized\\nservices. Collaborative Filtering (CF) algorithms -- among others -- are\\nfundamental algorithms driving the underlying mechanism of personalized\\nrecommendation. Many of the traditional CF algorithms are designed based on the\\nfundamental idea of mining or learning correlative patterns from data for\\nmatching, including memory-based methods such as user/item-based CF as well as\\nlearning-based methods such as matrix factorization and deep learning models.\\nHowever, advancing from correlative learning to causal learning is an important\\nproblem, because causal/counterfactual modeling can help us to think outside of\\nthe observational data for user modeling and personalization. In this paper, we\\npropose Causal Collaborative Filtering (CCF) -- a general framework for\\nmodeling causality in collaborative filtering and recommendation. We first\\nprovide a unified causal view of CF and mathematically show that many of the\\ntraditional CF algorithms are actually special cases of CCF under simplified\\ncausal graphs. We then propose a conditional intervention approach for\\n$do$-calculus so that we can estimate the causal relations based on\\nobservational data. Finally, we further propose a general counterfactual\\nconstrained learning framework for estimating the user-item preferences.\\nExperiments are conducted on two types of real-world datasets -- traditional\\nand randomized trial data -- and results show that our framework can improve\\nthe recommendation performance of many CF algorithms.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.01868'}, {'title': 'Revealing Critical Characteristics of Mobility Patterns in New York City during the Onset of COVID-19 Pandemic. (arXiv:2102.01918v2 [physics.soc-ph] UPDATED)', 'description': \"<p>New York has become one of the worst-affected COVID-19 hotspots and a\\npandemic epicenter due to the ongoing crisis. This paper identifies the impact\\nof the pandemic and the effectiveness of government policies on human mobility\\nby analyzing multiple datasets available at both macro and micro levels for the\\nNew York City. Using data sources related to population density, aggregated\\npopulation mobility, public rail transit use, vehicle use, hotspot and\\nnon-hotspot movement patterns, and human activity agglomeration, we analyzed\\nthe inter-borough and intra-borough moment for New York City by aggregating the\\ndata at the borough level. We also assessed the internodal population movement\\namongst hotspot and non-hotspot points of interest for the month of March and\\nApril 2020. Results indicate a drop of about 80% in people's mobility in the\\ncity, beginning in mid-March. The movement to and from Manhattan showed the\\nmost disruption for both public transit and road traffic. The city saw its\\nfirst case on March 1, 2020, but disruptions in mobility can be seen only after\\nthe second week of March when the shelter in place orders was put in effect.\\nOwing to people working from home and adhering to stay-at-home orders,\\nManhattan saw the largest disruption to both inter- and intra-borough movement.\\nBut the risk of spread of infection in Manhattan turned out to be high because\\nof higher hotspot-linked movements. The stay-at-home restrictions also led to\\nan increased population density in Brooklyn and Queens as people were not\\ncommuting to Manhattan. Insights obtained from this study would help\\npolicymakers better understand human behavior and their response to the news\\nand governmental policies.\\n</p>\\n\", 'link': 'http://arxiv.org/abs/2102.01918'}, {'title': 'On Query-efficient Planning in MDPs under Linear Realizability of the Optimal State-value Function. (arXiv:2102.02049v2 [cs.LG] UPDATED)', 'description': '<p>We consider the problem of local planning in fixed-horizon Markov Decision\\nProcesses (MDPs) with a generative model under the assumption that the optimal\\nvalue function lies in the span of a feature map that is accessible through the\\ngenerative model. As opposed to previous work where linear realizability of all\\npolicies was assumed, we consider the significantly relaxed assumption of a\\nsingle linearly realizable (deterministic) policy. A recent lower bound\\nestablished that the related problem when the action-value function of the\\noptimal policy is linearly realizable requires an exponential number of\\nqueries, either in H (the horizon of the MDP) or d (the dimension of the\\nfeature mapping). Their construction crucially relies on having an\\nexponentially large action set. In contrast, in this work, we establish that\\npoly$(H, d)$ learning is possible (with state value function realizability)\\nwhenever the action set is small (i.e. O(1)). In particular, we present the\\nTensorPlan algorithm which uses poly$((dH/\\\\delta)^A)$ queries to find a\\n$\\\\delta$-optimal policy relative to any deterministic policy for which the\\nvalue function is linearly realizable with a parameter from a fixed radius ball\\naround zero. This is the first algorithm to give a polynomial query complexity\\nguarantee using only linear-realizability of a single competing value function.\\nWhether the computation cost is similarly bounded remains an interesting open\\nquestion. The upper bound is complemented by a lower bound which proves that in\\nthe infinite-horizon episodic setting, planners that achieve constant\\nsuboptimality need exponentially many queries, either in the dimension or the\\nnumber of actions.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02049'}, {'title': 'Federated Learning on Non-IID Data Silos: An Experimental Study. (arXiv:2102.02079v2 [cs.LG] UPDATED)', 'description': '<p>Machine learning services have been emerging in many data-intensive\\napplications, and their effectiveness highly relies on large-volume\\nhigh-quality training data. However, due to the increasing privacy concerns and\\ndata regulations, training data have been increasingly fragmented, forming\\ndistributed databases of multiple data silos (e.g., within different\\norganizations and countries). To develop effective machine learning services,\\nthere is a must to exploit data from such distributed databases without\\nexchanging the raw data. Recently, federated learning (FL) has been a solution\\nwith growing interests, which enables multiple parties to collaboratively train\\na machine learning model without exchanging their local data. A key and common\\nchallenge on distributed databases is the heterogeneity of the data\\ndistribution (i.e., non-IID) among the parties. There have been many FL\\nalgorithms to address the learning effectiveness under non-IID data settings.\\nHowever, there lacks an experimental study on systematically understanding\\ntheir advantages and disadvantages, as previous studies have very rigid data\\npartitioning strategies among parties, which are hardly representative and\\nthorough. In this paper, to help researchers better understand and study the\\nnon-IID data setting in federated learning, we propose comprehensive data\\npartitioning strategies to cover the typical non-IID data cases. Moreover, we\\nconduct extensive experiments to evaluate state-of-the-art FL algorithms. We\\nfind that non-IID does bring significant challenges in learning accuracy of FL\\nalgorithms, and none of the existing state-of-the-art FL algorithms outperforms\\nothers in all cases. Our experiments provide insights for future studies of\\naddressing the challenges in data silos.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02079'}, {'title': 'BeFair: Addressing Fairness in the Banking Sector. (arXiv:2102.02137v2 [cs.LG] UPDATED)', 'description': '<p>Algorithmic bias mitigation has been one of the most difficult conundrums for\\nthe data science community and Machine Learning (ML) experts. Over several\\nyears, there have appeared enormous efforts in the field of fairness in ML.\\nDespite the progress toward identifying biases and designing fair algorithms,\\ntranslating them into the industry remains a major challenge. In this paper, we\\npresent the initial results of an industrial open innovation project in the\\nbanking sector: we propose a general roadmap for fairness in ML and the\\nimplementation of a toolkit called BeFair that helps to identify and mitigate\\nbias. Results show that training a model without explicit constraints may lead\\nto bias exacerbation in the predictions.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2102.02137'}, {'title': 'Circuit Complexity From Supersymmetric Quantum Field Theory With Morse Function. (arXiv:2101.12582v1 [hep-th] CROSS LISTED)', 'description': '<p>Computation of circuit complexity has gained much attention in the\\nTheoretical Physics community in recent times to gain insights about the\\nchaotic features and random fluctuations of fields in the quantum regime.\\nRecent studies of circuit complexity take inspiration from the geometric\\napproach of Nielsen, which itself is based on the idea of optimal quantum\\ncontrol in which a cost function is introduced for the various possible path to\\ndetermine the optimum circuit. In this paper, we study the relationship between\\nthe circuit complexity and Morse theory within the framework of algebraic\\ntopology using which we study circuit complexity in supersymmetric quantum\\nfield theory describing both simple and inverted harmonic oscillators up to\\nhigher orders of quantum corrections. The expression of circuit complexity in\\nquantum regime would then be given by the Hessian of the Morse function in\\nsupersymmetric quantum field theory, and try to draw conclusion from their\\ngraphical behaviour. We also provide a technical proof of the well known\\nuniversal connecting relation between quantum chaos and circuit complexity of\\nthe supersymmetric quantum field theories, using the general description of\\nMorse theory.\\n</p>\\n', 'link': 'http://arxiv.org/abs/2101.12582'}]\n"
     ]
    }
   ],
   "source": [
    "# validate news_items\n",
    "print(news_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Parametrized Quantum Circuits of Synonymous Sentences in Quantum Natural Language Processing. (arXiv:2102.02204v1 [quant-ph])',\n",
       " 'description': '<p>In this paper, we develop a compositional vector-based semantics of positive\\ntransitive sentences in quantum natural language processing for a non-English\\nlanguage, i.e. Persian, to compare the parametrized quantum circuits of two\\nsynonymous sentences in two languages, English and Persian. By considering\\ngrammar+meaning of a transitive sentence, we translate DisCoCat diagram via\\nZX-calculus into quantum circuit form. Also, we use a bigraph method to rewrite\\nDisCoCat diagram and turn into quantum circuit in the semantic side.\\n</p>\\n',\n",
       " 'link': 'http://arxiv.org/abs/2102.02204'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate first news_items\n",
    "news_items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe and CSV\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(news_items,columns=['title','link','description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parametrized Quantum Circuits of Synonymous Se...</td>\n",
       "      <td>http://arxiv.org/abs/2102.02204</td>\n",
       "      <td>&lt;p&gt;In this paper, we develop a compositional v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harvest -- An Open Source Toolkit for Extracti...</td>\n",
       "      <td>http://arxiv.org/abs/2102.02240</td>\n",
       "      <td>&lt;p&gt;Automatic extraction of forum posts and met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Information-theoretic Key Encapsulation and it...</td>\n",
       "      <td>http://arxiv.org/abs/2102.02243</td>\n",
       "      <td>&lt;p&gt;A hybrid encryption scheme is a public key ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bounds and Genericity of Sum-Rank-Metric Codes...</td>\n",
       "      <td>http://arxiv.org/abs/2102.02244</td>\n",
       "      <td>&lt;p&gt;We derive simplified sphere-packing and Gil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Forgotten Document-Oriented Database Manag...</td>\n",
       "      <td>http://arxiv.org/abs/2102.02246</td>\n",
       "      <td>&lt;p&gt;In the current context of Big Data, a multi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Parametrized Quantum Circuits of Synonymous Se...   \n",
       "1  Harvest -- An Open Source Toolkit for Extracti...   \n",
       "2  Information-theoretic Key Encapsulation and it...   \n",
       "3  Bounds and Genericity of Sum-Rank-Metric Codes...   \n",
       "4  The Forgotten Document-Oriented Database Manag...   \n",
       "\n",
       "                              link  \\\n",
       "0  http://arxiv.org/abs/2102.02204   \n",
       "1  http://arxiv.org/abs/2102.02240   \n",
       "2  http://arxiv.org/abs/2102.02243   \n",
       "3  http://arxiv.org/abs/2102.02244   \n",
       "4  http://arxiv.org/abs/2102.02246   \n",
       "\n",
       "                                         description  \n",
       "0  <p>In this paper, we develop a compositional v...  \n",
       "1  <p>Automatic extraction of forum posts and met...  \n",
       "2  <p>A hybrid encryption scheme is a public key ...  \n",
       "3  <p>We derive simplified sphere-packing and Gil...  \n",
       "4  <p>In the current context of Big Data, a multi...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show header of df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write df to csv, optional\n",
    "df.to_csv('ARXIVdata.csv',index=False, sep=',',encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write df to postgres table and create columns\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://postgres:purplerain@localhost:5432/postgres')\n",
    "df.to_sql('arxiv_rss', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to postgres DB with credentials\n",
    "conn = psycopg2.connect(host=\"localhost\", port = 5432, database=\"postgres\", user=\"postgres\", password=\"purplerain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(375,)]\n"
     ]
    }
   ],
   "source": [
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "#  # validate all data from the \"arxiv_rss\" table in the POSTGRE DB\n",
    "cur.execute(\"\"\"rollback\"\"\")\n",
    "cur.execute(\"\"\"SELECT COUNT(*) FROM arxiv_rss\"\"\")\n",
    "query_results = cur.fetchall()\n",
    "print(query_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Parametrized Quantum Circuits of Synonymous Sentences in Quantum Natural Language Processing. (arXiv:2102.02204v1 [quant-ph])', 'http://arxiv.org/abs/2102.02204', '<p>In this paper, we develop a compositional vector-based semantics of positive\\ntransitive sentences in quantum natural language processing for a non-English\\nlanguage, i.e. Persian, to compare the parametrized quantum circuits of two\\nsynonymous sentences in two languages, English and Persian. By considering\\ngrammar+meaning of a transitive sentence, we translate DisCoCat diagram via\\nZX-calculus into quantum circuit form. Also, we use a bigraph method to rewrite\\nDisCoCat diagram and turn into quantum circuit in the semantic side.\\n</p>\\n')]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"\"\"rollback\"\"\")\n",
    "cur.execute(\"\"\"SELECT * FROM arxiv_rss WHERE link='http://arxiv.org/abs/2102.02204'\"\"\")\n",
    "query_results = cur.fetchall()\n",
    "print(query_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the cursor and connection to so the server can allocate\n",
    "# bandwidth to other requests\n",
    "cur.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
